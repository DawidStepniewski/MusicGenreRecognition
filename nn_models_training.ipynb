{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqwoYuxcH3niYody269f+H"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuWi627SiP_3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "rwuNV3mVaSb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f97b630-6bf6-4a6b-f321-4722bab8bee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_linPhtZaEOJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, GlobalAveragePooling2D, Rescaling\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from skimage.transform import resize\n",
        "from keras.applications.resnet50 import preprocess_input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and compile NN Models"
      ],
      "metadata": {
        "id": "ERNPudb3b7fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_nn_model_1():\n",
        "  model = Sequential(name='Model_1')\n",
        "  model.add(Conv2D(64, 2, activation = 'relu', input_shape = (600, 300, 3)))\n",
        "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Conv2D(128, 2, activation = 'relu'))\n",
        "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Conv2D(256, 2, activation = 'relu'))\n",
        "  model.add(MaxPooling2D(pool_size = (4,4)))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Conv2D(512, 2, activation = 'relu'))\n",
        "  model.add(MaxPooling2D(pool_size = (8,8)))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(2048, activation = 'relu'))\n",
        "  model.add(Dense(1024, activation = 'relu'))\n",
        "  model.add(Dense(256, activation = 'relu'))\n",
        "  model.add(Dense(128, activation = 'relu'))\n",
        "\n",
        "  model.add(Dense(10, activation = 'softmax'))\n",
        "  # model.summary()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "zHkoaW3JabGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_nn_model_2():\n",
        "  model = Sequential(name='Model_2')\n",
        "  model.add(Conv2D(64, 2, activation = 'relu', input_shape = (600, 300, 3)))\n",
        "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Conv2D(32, 2, activation = 'relu'))\n",
        "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Conv2D(32, 2, activation = 'relu'))\n",
        "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(64, activation = 'relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(32, activation = 'relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(16, activation = 'relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(10, activation = 'softmax'))\n",
        "  # model.summary()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "iWGq56XjHlFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_1_compile(model, checkpoint_path):\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.01)\n",
        "  checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "  return model, reduce_lr, checkpoint"
      ],
      "metadata": {
        "id": "U1plC6O5aciR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_nn_model_3():\n",
        "  model = Sequential(name='Model_3')\n",
        "  model.add(Conv2D(64, (3, 3), input_shape = (600, 300, 3), padding=\"same\", activation='relu'))\n",
        "  model.add(Conv2D(64, (3, 3), strides=(4, 4), padding=\"same\", activation='relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(Conv2D(128, (3, 3), strides=(4, 4), padding='same', activation='relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(1024, activation=LeakyReLU(alpha=0.1)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(512, activation=LeakyReLU(alpha=0.1)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(256, activation=LeakyReLU(alpha=0.1)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(10, activation = 'softmax'))\n",
        "  # model.summary()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Xz5TAEm_pL9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_nn_model_4():\n",
        "  resnet = ResNet50(weights='imagenet', include_top=False, classes=10)\n",
        "  print(\"ResNet50 layers:\",len(resnet.layers))\n",
        "\n",
        "  model = resnet.output\n",
        "  model = GlobalAveragePooling2D()(model)\n",
        "  model = Dense(1024, activation = 'relu')(model)\n",
        "  model = Dense(512, activation = 'relu')(model)\n",
        "  last_layer = Dense(10, activation = 'softmax')(model)\n",
        "  model = Model(name=\"Model_ResNet50\", inputs = resnet.input, outputs = last_layer)\n",
        "\n",
        "  print(\"Combined model:\",len(model.layers),'layers')\n",
        "\n",
        "  for layer in model.layers[:175]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  for layer in model.layers[175:]:\n",
        "      layer.trainable = True\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "-M94pVYdagUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_compile(model, checkpoint_path):\n",
        "  lr_schedule = tensorflow.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.0001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=1e-6)\n",
        "\n",
        "  optimizer = RMSprop(learning_rate=lr_schedule)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "  return model, checkpoint"
      ],
      "metadata": {
        "id": "XoU1LRQRah-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio files length: original MEL"
      ],
      "metadata": {
        "id": "I06WYkqssKGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/GoogleCollab/Data/GTZAN/spectrograms/Spectrograms_with_test_train_split/spectrograms_mel.zip' -d \"/content\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "hbDMVlQk1FQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb6c4a8-1a8f-49fa-cce9-06aec4f90b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/GoogleCollab/Data/GTZAN/spectrograms/Spectrograms_with_test_train_split/spectrograms_mel.zip\n",
            "   creating: /content/test/\n",
            "   creating: /content/test/blues/\n",
            "  inflating: /content/test/blues/blues.00006.png  \n",
            "  inflating: /content/test/blues/blues.00007.png  \n",
            "  inflating: /content/test/blues/blues.00010.png  \n",
            "  inflating: /content/test/blues/blues.00011.png  \n",
            "  inflating: /content/test/blues/blues.00018.png  \n",
            "  inflating: /content/test/blues/blues.00022.png  \n",
            "  inflating: /content/test/blues/blues.00023.png  \n",
            "  inflating: /content/test/blues/blues.00031.png  \n",
            "  inflating: /content/test/blues/blues.00032.png  \n",
            "  inflating: /content/test/blues/blues.00036.png  \n",
            "  inflating: /content/test/blues/blues.00037.png  \n",
            "  inflating: /content/test/blues/blues.00047.png  \n",
            "  inflating: /content/test/blues/blues.00064.png  \n",
            "  inflating: /content/test/blues/blues.00065.png  \n",
            "  inflating: /content/test/blues/blues.00066.png  \n",
            "  inflating: /content/test/blues/blues.00069.png  \n",
            "  inflating: /content/test/blues/blues.00076.png  \n",
            "  inflating: /content/test/blues/blues.00082.png  \n",
            "  inflating: /content/test/blues/blues.00088.png  \n",
            "  inflating: /content/test/blues/blues.00091.png  \n",
            "   creating: /content/test/classical/\n",
            "  inflating: /content/test/classical/classical.00001.png  \n",
            "  inflating: /content/test/classical/classical.00004.png  \n",
            "  inflating: /content/test/classical/classical.00016.png  \n",
            "  inflating: /content/test/classical/classical.00017.png  \n",
            "  inflating: /content/test/classical/classical.00018.png  \n",
            "  inflating: /content/test/classical/classical.00027.png  \n",
            "  inflating: /content/test/classical/classical.00036.png  \n",
            "  inflating: /content/test/classical/classical.00039.png  \n",
            "  inflating: /content/test/classical/classical.00040.png  \n",
            "  inflating: /content/test/classical/classical.00041.png  \n",
            "  inflating: /content/test/classical/classical.00043.png  \n",
            "  inflating: /content/test/classical/classical.00049.png  \n",
            "  inflating: /content/test/classical/classical.00051.png  \n",
            "  inflating: /content/test/classical/classical.00066.png  \n",
            "  inflating: /content/test/classical/classical.00067.png  \n",
            "  inflating: /content/test/classical/classical.00071.png  \n",
            "  inflating: /content/test/classical/classical.00076.png  \n",
            "  inflating: /content/test/classical/classical.00078.png  \n",
            "  inflating: /content/test/classical/classical.00084.png  \n",
            "  inflating: /content/test/classical/classical.00097.png  \n",
            "   creating: /content/test/country/\n",
            "  inflating: /content/test/country/country.00000.png  \n",
            "  inflating: /content/test/country/country.00002.png  \n",
            "  inflating: /content/test/country/country.00006.png  \n",
            "  inflating: /content/test/country/country.00013.png  \n",
            "  inflating: /content/test/country/country.00023.png  \n",
            "  inflating: /content/test/country/country.00025.png  \n",
            "  inflating: /content/test/country/country.00031.png  \n",
            "  inflating: /content/test/country/country.00035.png  \n",
            "  inflating: /content/test/country/country.00038.png  \n",
            "  inflating: /content/test/country/country.00044.png  \n",
            "  inflating: /content/test/country/country.00048.png  \n",
            "  inflating: /content/test/country/country.00049.png  \n",
            "  inflating: /content/test/country/country.00065.png  \n",
            "  inflating: /content/test/country/country.00067.png  \n",
            "  inflating: /content/test/country/country.00076.png  \n",
            "  inflating: /content/test/country/country.00077.png  \n",
            "  inflating: /content/test/country/country.00078.png  \n",
            "  inflating: /content/test/country/country.00082.png  \n",
            "  inflating: /content/test/country/country.00086.png  \n",
            "  inflating: /content/test/country/country.00087.png  \n",
            "   creating: /content/test/disco/\n",
            "  inflating: /content/test/disco/disco.00000.png  \n",
            "  inflating: /content/test/disco/disco.00001.png  \n",
            "  inflating: /content/test/disco/disco.00009.png  \n",
            "  inflating: /content/test/disco/disco.00012.png  \n",
            "  inflating: /content/test/disco/disco.00015.png  \n",
            "  inflating: /content/test/disco/disco.00023.png  \n",
            "  inflating: /content/test/disco/disco.00028.png  \n",
            "  inflating: /content/test/disco/disco.00031.png  \n",
            "  inflating: /content/test/disco/disco.00035.png  \n",
            "  inflating: /content/test/disco/disco.00037.png  \n",
            "  inflating: /content/test/disco/disco.00039.png  \n",
            "  inflating: /content/test/disco/disco.00046.png  \n",
            "  inflating: /content/test/disco/disco.00052.png  \n",
            "  inflating: /content/test/disco/disco.00068.png  \n",
            "  inflating: /content/test/disco/disco.00070.png  \n",
            "  inflating: /content/test/disco/disco.00075.png  \n",
            "  inflating: /content/test/disco/disco.00081.png  \n",
            "  inflating: /content/test/disco/disco.00085.png  \n",
            "  inflating: /content/test/disco/disco.00086.png  \n",
            "  inflating: /content/test/disco/disco.00087.png  \n",
            "   creating: /content/test/hiphop/\n",
            "  inflating: /content/test/hiphop/hiphop.00002.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00004.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00012.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00013.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00014.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00015.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00028.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00029.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00031.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00035.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00047.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00052.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00058.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00067.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00074.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00075.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00077.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00079.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00084.png  \n",
            "  inflating: /content/test/hiphop/hiphop.00093.png  \n",
            "   creating: /content/test/jazz/\n",
            "  inflating: /content/test/jazz/jazz.00000.png  \n",
            "  inflating: /content/test/jazz/jazz.00001.png  \n",
            "  inflating: /content/test/jazz/jazz.00013.png  \n",
            "  inflating: /content/test/jazz/jazz.00015.png  \n",
            "  inflating: /content/test/jazz/jazz.00016.png  \n",
            "  inflating: /content/test/jazz/jazz.00020.png  \n",
            "  inflating: /content/test/jazz/jazz.00022.png  \n",
            "  inflating: /content/test/jazz/jazz.00026.png  \n",
            "  inflating: /content/test/jazz/jazz.00033.png  \n",
            "  inflating: /content/test/jazz/jazz.00043.png  \n",
            "  inflating: /content/test/jazz/jazz.00044.png  \n",
            "  inflating: /content/test/jazz/jazz.00049.png  \n",
            "  inflating: /content/test/jazz/jazz.00063.png  \n",
            "  inflating: /content/test/jazz/jazz.00064.png  \n",
            "  inflating: /content/test/jazz/jazz.00071.png  \n",
            "  inflating: /content/test/jazz/jazz.00083.png  \n",
            "  inflating: /content/test/jazz/jazz.00085.png  \n",
            "  inflating: /content/test/jazz/jazz.00087.png  \n",
            "  inflating: /content/test/jazz/jazz.00096.png  \n",
            "  inflating: /content/test/jazz/jazz.00098.png  \n",
            "   creating: /content/test/metal/\n",
            "  inflating: /content/test/metal/metal.00005.png  \n",
            "  inflating: /content/test/metal/metal.00007.png  \n",
            "  inflating: /content/test/metal/metal.00010.png  \n",
            "  inflating: /content/test/metal/metal.00015.png  \n",
            "  inflating: /content/test/metal/metal.00016.png  \n",
            "  inflating: /content/test/metal/metal.00017.png  \n",
            "  inflating: /content/test/metal/metal.00032.png  \n",
            "  inflating: /content/test/metal/metal.00033.png  \n",
            "  inflating: /content/test/metal/metal.00034.png  \n",
            "  inflating: /content/test/metal/metal.00039.png  \n",
            "  inflating: /content/test/metal/metal.00046.png  \n",
            "  inflating: /content/test/metal/metal.00049.png  \n",
            "  inflating: /content/test/metal/metal.00061.png  \n",
            "  inflating: /content/test/metal/metal.00066.png  \n",
            "  inflating: /content/test/metal/metal.00070.png  \n",
            "  inflating: /content/test/metal/metal.00071.png  \n",
            "  inflating: /content/test/metal/metal.00076.png  \n",
            "  inflating: /content/test/metal/metal.00080.png  \n",
            "  inflating: /content/test/metal/metal.00089.png  \n",
            "  inflating: /content/test/metal/metal.00091.png  \n",
            "   creating: /content/test/pop/\n",
            "  inflating: /content/test/pop/pop.00001.png  \n",
            "  inflating: /content/test/pop/pop.00003.png  \n",
            "  inflating: /content/test/pop/pop.00009.png  \n",
            "  inflating: /content/test/pop/pop.00018.png  \n",
            "  inflating: /content/test/pop/pop.00019.png  \n",
            "  inflating: /content/test/pop/pop.00027.png  \n",
            "  inflating: /content/test/pop/pop.00028.png  \n",
            "  inflating: /content/test/pop/pop.00032.png  \n",
            "  inflating: /content/test/pop/pop.00033.png  \n",
            "  inflating: /content/test/pop/pop.00036.png  \n",
            "  inflating: /content/test/pop/pop.00039.png  \n",
            "  inflating: /content/test/pop/pop.00044.png  \n",
            "  inflating: /content/test/pop/pop.00057.png  \n",
            "  inflating: /content/test/pop/pop.00063.png  \n",
            "  inflating: /content/test/pop/pop.00071.png  \n",
            "  inflating: /content/test/pop/pop.00076.png  \n",
            "  inflating: /content/test/pop/pop.00080.png  \n",
            "  inflating: /content/test/pop/pop.00084.png  \n",
            "  inflating: /content/test/pop/pop.00087.png  \n",
            "  inflating: /content/test/pop/pop.00093.png  \n",
            "   creating: /content/test/reggae/\n",
            "  inflating: /content/test/reggae/reggae.00002.png  \n",
            "  inflating: /content/test/reggae/reggae.00004.png  \n",
            "  inflating: /content/test/reggae/reggae.00015.png  \n",
            "  inflating: /content/test/reggae/reggae.00016.png  \n",
            "  inflating: /content/test/reggae/reggae.00022.png  \n",
            "  inflating: /content/test/reggae/reggae.00025.png  \n",
            "  inflating: /content/test/reggae/reggae.00028.png  \n",
            "  inflating: /content/test/reggae/reggae.00035.png  \n",
            "  inflating: /content/test/reggae/reggae.00039.png  \n",
            "  inflating: /content/test/reggae/reggae.00042.png  \n",
            "  inflating: /content/test/reggae/reggae.00045.png  \n",
            "  inflating: /content/test/reggae/reggae.00047.png  \n",
            "  inflating: /content/test/reggae/reggae.00051.png  \n",
            "  inflating: /content/test/reggae/reggae.00069.png  \n",
            "  inflating: /content/test/reggae/reggae.00071.png  \n",
            "  inflating: /content/test/reggae/reggae.00073.png  \n",
            "  inflating: /content/test/reggae/reggae.00075.png  \n",
            "  inflating: /content/test/reggae/reggae.00080.png  \n",
            "  inflating: /content/test/reggae/reggae.00084.png  \n",
            "  inflating: /content/test/reggae/reggae.00089.png  \n",
            "   creating: /content/test/rock/\n",
            "  inflating: /content/test/rock/rock.00001.png  \n",
            "  inflating: /content/test/rock/rock.00005.png  \n",
            "  inflating: /content/test/rock/rock.00011.png  \n",
            "  inflating: /content/test/rock/rock.00012.png  \n",
            "  inflating: /content/test/rock/rock.00015.png  \n",
            "  inflating: /content/test/rock/rock.00023.png  \n",
            "  inflating: /content/test/rock/rock.00024.png  \n",
            "  inflating: /content/test/rock/rock.00029.png  \n",
            "  inflating: /content/test/rock/rock.00030.png  \n",
            "  inflating: /content/test/rock/rock.00037.png  \n",
            "  inflating: /content/test/rock/rock.00041.png  \n",
            "  inflating: /content/test/rock/rock.00046.png  \n",
            "  inflating: /content/test/rock/rock.00057.png  \n",
            "  inflating: /content/test/rock/rock.00065.png  \n",
            "  inflating: /content/test/rock/rock.00069.png  \n",
            "  inflating: /content/test/rock/rock.00074.png  \n",
            "  inflating: /content/test/rock/rock.00079.png  \n",
            "  inflating: /content/test/rock/rock.00086.png  \n",
            "  inflating: /content/test/rock/rock.00087.png  \n",
            "  inflating: /content/test/rock/rock.00090.png  \n",
            "   creating: /content/train/\n",
            "   creating: /content/train/blues/\n",
            "  inflating: /content/train/blues/blues.00000.png  \n",
            "  inflating: /content/train/blues/blues.00001.png  \n",
            "  inflating: /content/train/blues/blues.00002.png  \n",
            "  inflating: /content/train/blues/blues.00003.png  \n",
            "  inflating: /content/train/blues/blues.00004.png  \n",
            "  inflating: /content/train/blues/blues.00005.png  \n",
            "  inflating: /content/train/blues/blues.00008.png  \n",
            "  inflating: /content/train/blues/blues.00009.png  \n",
            "  inflating: /content/train/blues/blues.00012.png  \n",
            "  inflating: /content/train/blues/blues.00013.png  \n",
            "  inflating: /content/train/blues/blues.00014.png  \n",
            "  inflating: /content/train/blues/blues.00015.png  \n",
            "  inflating: /content/train/blues/blues.00016.png  \n",
            "  inflating: /content/train/blues/blues.00017.png  \n",
            "  inflating: /content/train/blues/blues.00019.png  \n",
            "  inflating: /content/train/blues/blues.00020.png  \n",
            "  inflating: /content/train/blues/blues.00021.png  \n",
            "  inflating: /content/train/blues/blues.00024.png  \n",
            "  inflating: /content/train/blues/blues.00025.png  \n",
            "  inflating: /content/train/blues/blues.00026.png  \n",
            "  inflating: /content/train/blues/blues.00027.png  \n",
            "  inflating: /content/train/blues/blues.00028.png  \n",
            "  inflating: /content/train/blues/blues.00029.png  \n",
            "  inflating: /content/train/blues/blues.00030.png  \n",
            "  inflating: /content/train/blues/blues.00033.png  \n",
            "  inflating: /content/train/blues/blues.00034.png  \n",
            "  inflating: /content/train/blues/blues.00035.png  \n",
            "  inflating: /content/train/blues/blues.00038.png  \n",
            "  inflating: /content/train/blues/blues.00039.png  \n",
            "  inflating: /content/train/blues/blues.00040.png  \n",
            "  inflating: /content/train/blues/blues.00041.png  \n",
            "  inflating: /content/train/blues/blues.00042.png  \n",
            "  inflating: /content/train/blues/blues.00043.png  \n",
            "  inflating: /content/train/blues/blues.00044.png  \n",
            "  inflating: /content/train/blues/blues.00045.png  \n",
            "  inflating: /content/train/blues/blues.00046.png  \n",
            "  inflating: /content/train/blues/blues.00048.png  \n",
            "  inflating: /content/train/blues/blues.00049.png  \n",
            "  inflating: /content/train/blues/blues.00050.png  \n",
            "  inflating: /content/train/blues/blues.00051.png  \n",
            "  inflating: /content/train/blues/blues.00052.png  \n",
            "  inflating: /content/train/blues/blues.00053.png  \n",
            "  inflating: /content/train/blues/blues.00054.png  \n",
            "  inflating: /content/train/blues/blues.00055.png  \n",
            "  inflating: /content/train/blues/blues.00056.png  \n",
            "  inflating: /content/train/blues/blues.00057.png  \n",
            "  inflating: /content/train/blues/blues.00058.png  \n",
            "  inflating: /content/train/blues/blues.00059.png  \n",
            "  inflating: /content/train/blues/blues.00060.png  \n",
            "  inflating: /content/train/blues/blues.00061.png  \n",
            "  inflating: /content/train/blues/blues.00062.png  \n",
            "  inflating: /content/train/blues/blues.00063.png  \n",
            "  inflating: /content/train/blues/blues.00067.png  \n",
            "  inflating: /content/train/blues/blues.00068.png  \n",
            "  inflating: /content/train/blues/blues.00070.png  \n",
            "  inflating: /content/train/blues/blues.00071.png  \n",
            "  inflating: /content/train/blues/blues.00072.png  \n",
            "  inflating: /content/train/blues/blues.00073.png  \n",
            "  inflating: /content/train/blues/blues.00074.png  \n",
            "  inflating: /content/train/blues/blues.00075.png  \n",
            "  inflating: /content/train/blues/blues.00077.png  \n",
            "  inflating: /content/train/blues/blues.00078.png  \n",
            "  inflating: /content/train/blues/blues.00079.png  \n",
            "  inflating: /content/train/blues/blues.00080.png  \n",
            "  inflating: /content/train/blues/blues.00081.png  \n",
            "  inflating: /content/train/blues/blues.00083.png  \n",
            "  inflating: /content/train/blues/blues.00084.png  \n",
            "  inflating: /content/train/blues/blues.00085.png  \n",
            "  inflating: /content/train/blues/blues.00086.png  \n",
            "  inflating: /content/train/blues/blues.00087.png  \n",
            "  inflating: /content/train/blues/blues.00089.png  \n",
            "  inflating: /content/train/blues/blues.00090.png  \n",
            "  inflating: /content/train/blues/blues.00092.png  \n",
            "  inflating: /content/train/blues/blues.00093.png  \n",
            "  inflating: /content/train/blues/blues.00094.png  \n",
            "  inflating: /content/train/blues/blues.00095.png  \n",
            "  inflating: /content/train/blues/blues.00096.png  \n",
            "  inflating: /content/train/blues/blues.00097.png  \n",
            "  inflating: /content/train/blues/blues.00098.png  \n",
            "  inflating: /content/train/blues/blues.00099.png  \n",
            "   creating: /content/train/classical/\n",
            "  inflating: /content/train/classical/classical.00000.png  \n",
            "  inflating: /content/train/classical/classical.00002.png  \n",
            "  inflating: /content/train/classical/classical.00003.png  \n",
            "  inflating: /content/train/classical/classical.00005.png  \n",
            "  inflating: /content/train/classical/classical.00006.png  \n",
            "  inflating: /content/train/classical/classical.00007.png  \n",
            "  inflating: /content/train/classical/classical.00008.png  \n",
            "  inflating: /content/train/classical/classical.00009.png  \n",
            "  inflating: /content/train/classical/classical.00010.png  \n",
            "  inflating: /content/train/classical/classical.00011.png  \n",
            "  inflating: /content/train/classical/classical.00012.png  \n",
            "  inflating: /content/train/classical/classical.00013.png  \n",
            "  inflating: /content/train/classical/classical.00014.png  \n",
            "  inflating: /content/train/classical/classical.00015.png  \n",
            "  inflating: /content/train/classical/classical.00019.png  \n",
            "  inflating: /content/train/classical/classical.00020.png  \n",
            "  inflating: /content/train/classical/classical.00021.png  \n",
            "  inflating: /content/train/classical/classical.00022.png  \n",
            "  inflating: /content/train/classical/classical.00023.png  \n",
            "  inflating: /content/train/classical/classical.00024.png  \n",
            "  inflating: /content/train/classical/classical.00025.png  \n",
            "  inflating: /content/train/classical/classical.00026.png  \n",
            "  inflating: /content/train/classical/classical.00028.png  \n",
            "  inflating: /content/train/classical/classical.00029.png  \n",
            "  inflating: /content/train/classical/classical.00030.png  \n",
            "  inflating: /content/train/classical/classical.00031.png  \n",
            "  inflating: /content/train/classical/classical.00032.png  \n",
            "  inflating: /content/train/classical/classical.00033.png  \n",
            "  inflating: /content/train/classical/classical.00034.png  \n",
            "  inflating: /content/train/classical/classical.00035.png  \n",
            "  inflating: /content/train/classical/classical.00037.png  \n",
            "  inflating: /content/train/classical/classical.00038.png  \n",
            "  inflating: /content/train/classical/classical.00042.png  \n",
            "  inflating: /content/train/classical/classical.00044.png  \n",
            "  inflating: /content/train/classical/classical.00045.png  \n",
            "  inflating: /content/train/classical/classical.00046.png  \n",
            "  inflating: /content/train/classical/classical.00047.png  \n",
            "  inflating: /content/train/classical/classical.00048.png  \n",
            "  inflating: /content/train/classical/classical.00050.png  \n",
            "  inflating: /content/train/classical/classical.00052.png  \n",
            "  inflating: /content/train/classical/classical.00053.png  \n",
            "  inflating: /content/train/classical/classical.00054.png  \n",
            "  inflating: /content/train/classical/classical.00055.png  \n",
            "  inflating: /content/train/classical/classical.00056.png  \n",
            "  inflating: /content/train/classical/classical.00057.png  \n",
            "  inflating: /content/train/classical/classical.00058.png  \n",
            "  inflating: /content/train/classical/classical.00059.png  \n",
            "  inflating: /content/train/classical/classical.00060.png  \n",
            "  inflating: /content/train/classical/classical.00061.png  \n",
            "  inflating: /content/train/classical/classical.00062.png  \n",
            "  inflating: /content/train/classical/classical.00063.png  \n",
            "  inflating: /content/train/classical/classical.00064.png  \n",
            "  inflating: /content/train/classical/classical.00065.png  \n",
            "  inflating: /content/train/classical/classical.00068.png  \n",
            "  inflating: /content/train/classical/classical.00069.png  \n",
            "  inflating: /content/train/classical/classical.00070.png  \n",
            "  inflating: /content/train/classical/classical.00072.png  \n",
            "  inflating: /content/train/classical/classical.00073.png  \n",
            "  inflating: /content/train/classical/classical.00074.png  \n",
            "  inflating: /content/train/classical/classical.00075.png  \n",
            "  inflating: /content/train/classical/classical.00077.png  \n",
            "  inflating: /content/train/classical/classical.00079.png  \n",
            "  inflating: /content/train/classical/classical.00080.png  \n",
            "  inflating: /content/train/classical/classical.00081.png  \n",
            "  inflating: /content/train/classical/classical.00082.png  \n",
            "  inflating: /content/train/classical/classical.00083.png  \n",
            "  inflating: /content/train/classical/classical.00085.png  \n",
            "  inflating: /content/train/classical/classical.00086.png  \n",
            "  inflating: /content/train/classical/classical.00088.png  \n",
            "  inflating: /content/train/classical/classical.00089.png  \n",
            "  inflating: /content/train/classical/classical.00090.png  \n",
            "  inflating: /content/train/classical/classical.00091.png  \n",
            "  inflating: /content/train/classical/classical.00092.png  \n",
            "  inflating: /content/train/classical/classical.00093.png  \n",
            "  inflating: /content/train/classical/classical.00094.png  \n",
            "  inflating: /content/train/classical/classical.00095.png  \n",
            "  inflating: /content/train/classical/classical.00096.png  \n",
            "  inflating: /content/train/classical/classical.00098.png  \n",
            "  inflating: /content/train/classical/classical.00099.png  \n",
            "   creating: /content/train/country/\n",
            "  inflating: /content/train/country/country.00001.png  \n",
            "  inflating: /content/train/country/country.00003.png  \n",
            "  inflating: /content/train/country/country.00004.png  \n",
            "  inflating: /content/train/country/country.00005.png  \n",
            "  inflating: /content/train/country/country.00007.png  \n",
            "  inflating: /content/train/country/country.00008.png  \n",
            "  inflating: /content/train/country/country.00009.png  \n",
            "  inflating: /content/train/country/country.00010.png  \n",
            "  inflating: /content/train/country/country.00011.png  \n",
            "  inflating: /content/train/country/country.00012.png  \n",
            "  inflating: /content/train/country/country.00014.png  \n",
            "  inflating: /content/train/country/country.00015.png  \n",
            "  inflating: /content/train/country/country.00016.png  \n",
            "  inflating: /content/train/country/country.00017.png  \n",
            "  inflating: /content/train/country/country.00018.png  \n",
            "  inflating: /content/train/country/country.00019.png  \n",
            "  inflating: /content/train/country/country.00020.png  \n",
            "  inflating: /content/train/country/country.00021.png  \n",
            "  inflating: /content/train/country/country.00022.png  \n",
            "  inflating: /content/train/country/country.00024.png  \n",
            "  inflating: /content/train/country/country.00026.png  \n",
            "  inflating: /content/train/country/country.00027.png  \n",
            "  inflating: /content/train/country/country.00028.png  \n",
            "  inflating: /content/train/country/country.00029.png  \n",
            "  inflating: /content/train/country/country.00030.png  \n",
            "  inflating: /content/train/country/country.00032.png  \n",
            "  inflating: /content/train/country/country.00033.png  \n",
            "  inflating: /content/train/country/country.00034.png  \n",
            "  inflating: /content/train/country/country.00036.png  \n",
            "  inflating: /content/train/country/country.00037.png  \n",
            "  inflating: /content/train/country/country.00039.png  \n",
            "  inflating: /content/train/country/country.00040.png  \n",
            "  inflating: /content/train/country/country.00041.png  \n",
            "  inflating: /content/train/country/country.00042.png  \n",
            "  inflating: /content/train/country/country.00043.png  \n",
            "  inflating: /content/train/country/country.00045.png  \n",
            "  inflating: /content/train/country/country.00046.png  \n",
            "  inflating: /content/train/country/country.00047.png  \n",
            "  inflating: /content/train/country/country.00050.png  \n",
            "  inflating: /content/train/country/country.00051.png  \n",
            "  inflating: /content/train/country/country.00052.png  \n",
            "  inflating: /content/train/country/country.00053.png  \n",
            "  inflating: /content/train/country/country.00054.png  \n",
            "  inflating: /content/train/country/country.00055.png  \n",
            "  inflating: /content/train/country/country.00056.png  \n",
            "  inflating: /content/train/country/country.00057.png  \n",
            "  inflating: /content/train/country/country.00058.png  \n",
            "  inflating: /content/train/country/country.00059.png  \n",
            "  inflating: /content/train/country/country.00060.png  \n",
            "  inflating: /content/train/country/country.00061.png  \n",
            "  inflating: /content/train/country/country.00062.png  \n",
            "  inflating: /content/train/country/country.00063.png  \n",
            "  inflating: /content/train/country/country.00064.png  \n",
            "  inflating: /content/train/country/country.00066.png  \n",
            "  inflating: /content/train/country/country.00068.png  \n",
            "  inflating: /content/train/country/country.00069.png  \n",
            "  inflating: /content/train/country/country.00070.png  \n",
            "  inflating: /content/train/country/country.00071.png  \n",
            "  inflating: /content/train/country/country.00072.png  \n",
            "  inflating: /content/train/country/country.00073.png  \n",
            "  inflating: /content/train/country/country.00074.png  \n",
            "  inflating: /content/train/country/country.00075.png  \n",
            "  inflating: /content/train/country/country.00079.png  \n",
            "  inflating: /content/train/country/country.00080.png  \n",
            "  inflating: /content/train/country/country.00081.png  \n",
            "  inflating: /content/train/country/country.00083.png  \n",
            "  inflating: /content/train/country/country.00084.png  \n",
            "  inflating: /content/train/country/country.00085.png  \n",
            "  inflating: /content/train/country/country.00088.png  \n",
            "  inflating: /content/train/country/country.00089.png  \n",
            "  inflating: /content/train/country/country.00090.png  \n",
            "  inflating: /content/train/country/country.00091.png  \n",
            "  inflating: /content/train/country/country.00092.png  \n",
            "  inflating: /content/train/country/country.00093.png  \n",
            "  inflating: /content/train/country/country.00094.png  \n",
            "  inflating: /content/train/country/country.00095.png  \n",
            "  inflating: /content/train/country/country.00096.png  \n",
            "  inflating: /content/train/country/country.00097.png  \n",
            "  inflating: /content/train/country/country.00098.png  \n",
            "  inflating: /content/train/country/country.00099.png  \n",
            "   creating: /content/train/disco/\n",
            "  inflating: /content/train/disco/disco.00002.png  \n",
            "  inflating: /content/train/disco/disco.00003.png  \n",
            "  inflating: /content/train/disco/disco.00004.png  \n",
            "  inflating: /content/train/disco/disco.00005.png  \n",
            "  inflating: /content/train/disco/disco.00006.png  \n",
            "  inflating: /content/train/disco/disco.00007.png  \n",
            "  inflating: /content/train/disco/disco.00008.png  \n",
            "  inflating: /content/train/disco/disco.00010.png  \n",
            "  inflating: /content/train/disco/disco.00011.png  \n",
            "  inflating: /content/train/disco/disco.00013.png  \n",
            "  inflating: /content/train/disco/disco.00014.png  \n",
            "  inflating: /content/train/disco/disco.00016.png  \n",
            "  inflating: /content/train/disco/disco.00017.png  \n",
            "  inflating: /content/train/disco/disco.00018.png  \n",
            "  inflating: /content/train/disco/disco.00019.png  \n",
            "  inflating: /content/train/disco/disco.00020.png  \n",
            "  inflating: /content/train/disco/disco.00021.png  \n",
            "  inflating: /content/train/disco/disco.00022.png  \n",
            "  inflating: /content/train/disco/disco.00024.png  \n",
            "  inflating: /content/train/disco/disco.00025.png  \n",
            "  inflating: /content/train/disco/disco.00026.png  \n",
            "  inflating: /content/train/disco/disco.00027.png  \n",
            "  inflating: /content/train/disco/disco.00029.png  \n",
            "  inflating: /content/train/disco/disco.00030.png  \n",
            "  inflating: /content/train/disco/disco.00032.png  \n",
            "  inflating: /content/train/disco/disco.00033.png  \n",
            "  inflating: /content/train/disco/disco.00034.png  \n",
            "  inflating: /content/train/disco/disco.00036.png  \n",
            "  inflating: /content/train/disco/disco.00038.png  \n",
            "  inflating: /content/train/disco/disco.00040.png  \n",
            "  inflating: /content/train/disco/disco.00041.png  \n",
            "  inflating: /content/train/disco/disco.00042.png  \n",
            "  inflating: /content/train/disco/disco.00043.png  \n",
            "  inflating: /content/train/disco/disco.00044.png  \n",
            "  inflating: /content/train/disco/disco.00045.png  \n",
            "  inflating: /content/train/disco/disco.00047.png  \n",
            "  inflating: /content/train/disco/disco.00048.png  \n",
            "  inflating: /content/train/disco/disco.00049.png  \n",
            "  inflating: /content/train/disco/disco.00050.png  \n",
            "  inflating: /content/train/disco/disco.00051.png  \n",
            "  inflating: /content/train/disco/disco.00053.png  \n",
            "  inflating: /content/train/disco/disco.00054.png  \n",
            "  inflating: /content/train/disco/disco.00055.png  \n",
            "  inflating: /content/train/disco/disco.00056.png  \n",
            "  inflating: /content/train/disco/disco.00057.png  \n",
            "  inflating: /content/train/disco/disco.00058.png  \n",
            "  inflating: /content/train/disco/disco.00059.png  \n",
            "  inflating: /content/train/disco/disco.00060.png  \n",
            "  inflating: /content/train/disco/disco.00061.png  \n",
            "  inflating: /content/train/disco/disco.00062.png  \n",
            "  inflating: /content/train/disco/disco.00063.png  \n",
            "  inflating: /content/train/disco/disco.00064.png  \n",
            "  inflating: /content/train/disco/disco.00065.png  \n",
            "  inflating: /content/train/disco/disco.00066.png  \n",
            "  inflating: /content/train/disco/disco.00067.png  \n",
            "  inflating: /content/train/disco/disco.00069.png  \n",
            "  inflating: /content/train/disco/disco.00071.png  \n",
            "  inflating: /content/train/disco/disco.00072.png  \n",
            "  inflating: /content/train/disco/disco.00073.png  \n",
            "  inflating: /content/train/disco/disco.00074.png  \n",
            "  inflating: /content/train/disco/disco.00076.png  \n",
            "  inflating: /content/train/disco/disco.00077.png  \n",
            "  inflating: /content/train/disco/disco.00078.png  \n",
            "  inflating: /content/train/disco/disco.00079.png  \n",
            "  inflating: /content/train/disco/disco.00080.png  \n",
            "  inflating: /content/train/disco/disco.00082.png  \n",
            "  inflating: /content/train/disco/disco.00083.png  \n",
            "  inflating: /content/train/disco/disco.00084.png  \n",
            "  inflating: /content/train/disco/disco.00088.png  \n",
            "  inflating: /content/train/disco/disco.00089.png  \n",
            "  inflating: /content/train/disco/disco.00090.png  \n",
            "  inflating: /content/train/disco/disco.00091.png  \n",
            "  inflating: /content/train/disco/disco.00092.png  \n",
            "  inflating: /content/train/disco/disco.00093.png  \n",
            "  inflating: /content/train/disco/disco.00094.png  \n",
            "  inflating: /content/train/disco/disco.00095.png  \n",
            "  inflating: /content/train/disco/disco.00096.png  \n",
            "  inflating: /content/train/disco/disco.00097.png  \n",
            "  inflating: /content/train/disco/disco.00098.png  \n",
            "  inflating: /content/train/disco/disco.00099.png  \n",
            "   creating: /content/train/hiphop/\n",
            "  inflating: /content/train/hiphop/hiphop.00000.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00001.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00003.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00005.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00006.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00007.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00008.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00009.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00010.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00011.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00016.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00017.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00018.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00019.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00020.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00021.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00022.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00023.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00024.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00025.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00026.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00027.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00030.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00032.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00033.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00034.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00036.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00037.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00038.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00039.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00040.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00041.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00042.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00043.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00044.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00045.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00046.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00048.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00049.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00050.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00051.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00053.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00054.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00055.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00056.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00057.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00059.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00060.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00061.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00062.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00063.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00064.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00065.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00066.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00068.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00069.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00070.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00071.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00072.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00073.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00076.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00078.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00080.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00081.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00082.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00083.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00085.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00086.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00087.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00088.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00089.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00090.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00091.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00092.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00094.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00095.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00096.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00097.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00098.png  \n",
            "  inflating: /content/train/hiphop/hiphop.00099.png  \n",
            "   creating: /content/train/jazz/\n",
            "  inflating: /content/train/jazz/jazz.00002.png  \n",
            "  inflating: /content/train/jazz/jazz.00003.png  \n",
            "  inflating: /content/train/jazz/jazz.00004.png  \n",
            "  inflating: /content/train/jazz/jazz.00005.png  \n",
            "  inflating: /content/train/jazz/jazz.00006.png  \n",
            "  inflating: /content/train/jazz/jazz.00007.png  \n",
            "  inflating: /content/train/jazz/jazz.00008.png  \n",
            "  inflating: /content/train/jazz/jazz.00009.png  \n",
            "  inflating: /content/train/jazz/jazz.00010.png  \n",
            "  inflating: /content/train/jazz/jazz.00011.png  \n",
            "  inflating: /content/train/jazz/jazz.00012.png  \n",
            "  inflating: /content/train/jazz/jazz.00014.png  \n",
            "  inflating: /content/train/jazz/jazz.00017.png  \n",
            "  inflating: /content/train/jazz/jazz.00018.png  \n",
            "  inflating: /content/train/jazz/jazz.00019.png  \n",
            "  inflating: /content/train/jazz/jazz.00021.png  \n",
            "  inflating: /content/train/jazz/jazz.00023.png  \n",
            "  inflating: /content/train/jazz/jazz.00024.png  \n",
            "  inflating: /content/train/jazz/jazz.00025.png  \n",
            "  inflating: /content/train/jazz/jazz.00027.png  \n",
            "  inflating: /content/train/jazz/jazz.00028.png  \n",
            "  inflating: /content/train/jazz/jazz.00029.png  \n",
            "  inflating: /content/train/jazz/jazz.00030.png  \n",
            "  inflating: /content/train/jazz/jazz.00031.png  \n",
            "  inflating: /content/train/jazz/jazz.00032.png  \n",
            "  inflating: /content/train/jazz/jazz.00034.png  \n",
            "  inflating: /content/train/jazz/jazz.00035.png  \n",
            "  inflating: /content/train/jazz/jazz.00036.png  \n",
            "  inflating: /content/train/jazz/jazz.00037.png  \n",
            "  inflating: /content/train/jazz/jazz.00038.png  \n",
            "  inflating: /content/train/jazz/jazz.00039.png  \n",
            "  inflating: /content/train/jazz/jazz.00040.png  \n",
            "  inflating: /content/train/jazz/jazz.00041.png  \n",
            "  inflating: /content/train/jazz/jazz.00042.png  \n",
            "  inflating: /content/train/jazz/jazz.00045.png  \n",
            "  inflating: /content/train/jazz/jazz.00046.png  \n",
            "  inflating: /content/train/jazz/jazz.00047.png  \n",
            "  inflating: /content/train/jazz/jazz.00048.png  \n",
            "  inflating: /content/train/jazz/jazz.00050.png  \n",
            "  inflating: /content/train/jazz/jazz.00051.png  \n",
            "  inflating: /content/train/jazz/jazz.00052.png  \n",
            "  inflating: /content/train/jazz/jazz.00053.png  \n",
            "  inflating: /content/train/jazz/jazz.00055.png  \n",
            "  inflating: /content/train/jazz/jazz.00056.png  \n",
            "  inflating: /content/train/jazz/jazz.00057.png  \n",
            "  inflating: /content/train/jazz/jazz.00058.png  \n",
            "  inflating: /content/train/jazz/jazz.00059.png  \n",
            "  inflating: /content/train/jazz/jazz.00060.png  \n",
            "  inflating: /content/train/jazz/jazz.00061.png  \n",
            "  inflating: /content/train/jazz/jazz.00062.png  \n",
            "  inflating: /content/train/jazz/jazz.00065.png  \n",
            "  inflating: /content/train/jazz/jazz.00066.png  \n",
            "  inflating: /content/train/jazz/jazz.00067.png  \n",
            "  inflating: /content/train/jazz/jazz.00068.png  \n",
            "  inflating: /content/train/jazz/jazz.00069.png  \n",
            "  inflating: /content/train/jazz/jazz.00070.png  \n",
            "  inflating: /content/train/jazz/jazz.00072.png  \n",
            "  inflating: /content/train/jazz/jazz.00073.png  \n",
            "  inflating: /content/train/jazz/jazz.00074.png  \n",
            "  inflating: /content/train/jazz/jazz.00075.png  \n",
            "  inflating: /content/train/jazz/jazz.00076.png  \n",
            "  inflating: /content/train/jazz/jazz.00077.png  \n",
            "  inflating: /content/train/jazz/jazz.00078.png  \n",
            "  inflating: /content/train/jazz/jazz.00079.png  \n",
            "  inflating: /content/train/jazz/jazz.00080.png  \n",
            "  inflating: /content/train/jazz/jazz.00081.png  \n",
            "  inflating: /content/train/jazz/jazz.00082.png  \n",
            "  inflating: /content/train/jazz/jazz.00084.png  \n",
            "  inflating: /content/train/jazz/jazz.00086.png  \n",
            "  inflating: /content/train/jazz/jazz.00088.png  \n",
            "  inflating: /content/train/jazz/jazz.00089.png  \n",
            "  inflating: /content/train/jazz/jazz.00090.png  \n",
            "  inflating: /content/train/jazz/jazz.00091.png  \n",
            "  inflating: /content/train/jazz/jazz.00092.png  \n",
            "  inflating: /content/train/jazz/jazz.00093.png  \n",
            "  inflating: /content/train/jazz/jazz.00094.png  \n",
            "  inflating: /content/train/jazz/jazz.00095.png  \n",
            "  inflating: /content/train/jazz/jazz.00097.png  \n",
            "  inflating: /content/train/jazz/jazz.00099.png  \n",
            "   creating: /content/train/metal/\n",
            "  inflating: /content/train/metal/metal.00000.png  \n",
            "  inflating: /content/train/metal/metal.00001.png  \n",
            "  inflating: /content/train/metal/metal.00002.png  \n",
            "  inflating: /content/train/metal/metal.00003.png  \n",
            "  inflating: /content/train/metal/metal.00004.png  \n",
            "  inflating: /content/train/metal/metal.00006.png  \n",
            "  inflating: /content/train/metal/metal.00008.png  \n",
            "  inflating: /content/train/metal/metal.00009.png  \n",
            "  inflating: /content/train/metal/metal.00011.png  \n",
            "  inflating: /content/train/metal/metal.00012.png  \n",
            "  inflating: /content/train/metal/metal.00013.png  \n",
            "  inflating: /content/train/metal/metal.00014.png  \n",
            "  inflating: /content/train/metal/metal.00018.png  \n",
            "  inflating: /content/train/metal/metal.00019.png  \n",
            "  inflating: /content/train/metal/metal.00020.png  \n",
            "  inflating: /content/train/metal/metal.00021.png  \n",
            "  inflating: /content/train/metal/metal.00022.png  \n",
            "  inflating: /content/train/metal/metal.00023.png  \n",
            "  inflating: /content/train/metal/metal.00024.png  \n",
            "  inflating: /content/train/metal/metal.00025.png  \n",
            "  inflating: /content/train/metal/metal.00026.png  \n",
            "  inflating: /content/train/metal/metal.00027.png  \n",
            "  inflating: /content/train/metal/metal.00028.png  \n",
            "  inflating: /content/train/metal/metal.00029.png  \n",
            "  inflating: /content/train/metal/metal.00030.png  \n",
            "  inflating: /content/train/metal/metal.00031.png  \n",
            "  inflating: /content/train/metal/metal.00035.png  \n",
            "  inflating: /content/train/metal/metal.00036.png  \n",
            "  inflating: /content/train/metal/metal.00037.png  \n",
            "  inflating: /content/train/metal/metal.00038.png  \n",
            "  inflating: /content/train/metal/metal.00040.png  \n",
            "  inflating: /content/train/metal/metal.00041.png  \n",
            "  inflating: /content/train/metal/metal.00042.png  \n",
            "  inflating: /content/train/metal/metal.00043.png  \n",
            "  inflating: /content/train/metal/metal.00044.png  \n",
            "  inflating: /content/train/metal/metal.00045.png  \n",
            "  inflating: /content/train/metal/metal.00047.png  \n",
            "  inflating: /content/train/metal/metal.00048.png  \n",
            "  inflating: /content/train/metal/metal.00050.png  \n",
            "  inflating: /content/train/metal/metal.00051.png  \n",
            "  inflating: /content/train/metal/metal.00052.png  \n",
            "  inflating: /content/train/metal/metal.00053.png  \n",
            "  inflating: /content/train/metal/metal.00054.png  \n",
            "  inflating: /content/train/metal/metal.00055.png  \n",
            "  inflating: /content/train/metal/metal.00056.png  \n",
            "  inflating: /content/train/metal/metal.00057.png  \n",
            "  inflating: /content/train/metal/metal.00058.png  \n",
            "  inflating: /content/train/metal/metal.00059.png  \n",
            "  inflating: /content/train/metal/metal.00060.png  \n",
            "  inflating: /content/train/metal/metal.00062.png  \n",
            "  inflating: /content/train/metal/metal.00063.png  \n",
            "  inflating: /content/train/metal/metal.00064.png  \n",
            "  inflating: /content/train/metal/metal.00065.png  \n",
            "  inflating: /content/train/metal/metal.00067.png  \n",
            "  inflating: /content/train/metal/metal.00068.png  \n",
            "  inflating: /content/train/metal/metal.00069.png  \n",
            "  inflating: /content/train/metal/metal.00072.png  \n",
            "  inflating: /content/train/metal/metal.00073.png  \n",
            "  inflating: /content/train/metal/metal.00074.png  \n",
            "  inflating: /content/train/metal/metal.00075.png  \n",
            "  inflating: /content/train/metal/metal.00077.png  \n",
            "  inflating: /content/train/metal/metal.00078.png  \n",
            "  inflating: /content/train/metal/metal.00079.png  \n",
            "  inflating: /content/train/metal/metal.00081.png  \n",
            "  inflating: /content/train/metal/metal.00082.png  \n",
            "  inflating: /content/train/metal/metal.00083.png  \n",
            "  inflating: /content/train/metal/metal.00084.png  \n",
            "  inflating: /content/train/metal/metal.00085.png  \n",
            "  inflating: /content/train/metal/metal.00086.png  \n",
            "  inflating: /content/train/metal/metal.00087.png  \n",
            "  inflating: /content/train/metal/metal.00088.png  \n",
            "  inflating: /content/train/metal/metal.00090.png  \n",
            "  inflating: /content/train/metal/metal.00092.png  \n",
            "  inflating: /content/train/metal/metal.00093.png  \n",
            "  inflating: /content/train/metal/metal.00094.png  \n",
            "  inflating: /content/train/metal/metal.00095.png  \n",
            "  inflating: /content/train/metal/metal.00096.png  \n",
            "  inflating: /content/train/metal/metal.00097.png  \n",
            "  inflating: /content/train/metal/metal.00098.png  \n",
            "  inflating: /content/train/metal/metal.00099.png  \n",
            "   creating: /content/train/pop/\n",
            "  inflating: /content/train/pop/pop.00000.png  \n",
            "  inflating: /content/train/pop/pop.00002.png  \n",
            "  inflating: /content/train/pop/pop.00004.png  \n",
            "  inflating: /content/train/pop/pop.00005.png  \n",
            "  inflating: /content/train/pop/pop.00006.png  \n",
            "  inflating: /content/train/pop/pop.00007.png  \n",
            "  inflating: /content/train/pop/pop.00008.png  \n",
            "  inflating: /content/train/pop/pop.00010.png  \n",
            "  inflating: /content/train/pop/pop.00011.png  \n",
            "  inflating: /content/train/pop/pop.00012.png  \n",
            "  inflating: /content/train/pop/pop.00013.png  \n",
            "  inflating: /content/train/pop/pop.00014.png  \n",
            "  inflating: /content/train/pop/pop.00015.png  \n",
            "  inflating: /content/train/pop/pop.00016.png  \n",
            "  inflating: /content/train/pop/pop.00017.png  \n",
            "  inflating: /content/train/pop/pop.00020.png  \n",
            "  inflating: /content/train/pop/pop.00021.png  \n",
            "  inflating: /content/train/pop/pop.00022.png  \n",
            "  inflating: /content/train/pop/pop.00023.png  \n",
            "  inflating: /content/train/pop/pop.00024.png  \n",
            "  inflating: /content/train/pop/pop.00025.png  \n",
            "  inflating: /content/train/pop/pop.00026.png  \n",
            "  inflating: /content/train/pop/pop.00029.png  \n",
            "  inflating: /content/train/pop/pop.00030.png  \n",
            "  inflating: /content/train/pop/pop.00031.png  \n",
            "  inflating: /content/train/pop/pop.00034.png  \n",
            "  inflating: /content/train/pop/pop.00035.png  \n",
            "  inflating: /content/train/pop/pop.00037.png  \n",
            "  inflating: /content/train/pop/pop.00038.png  \n",
            "  inflating: /content/train/pop/pop.00040.png  \n",
            "  inflating: /content/train/pop/pop.00041.png  \n",
            "  inflating: /content/train/pop/pop.00042.png  \n",
            "  inflating: /content/train/pop/pop.00043.png  \n",
            "  inflating: /content/train/pop/pop.00045.png  \n",
            "  inflating: /content/train/pop/pop.00046.png  \n",
            "  inflating: /content/train/pop/pop.00047.png  \n",
            "  inflating: /content/train/pop/pop.00048.png  \n",
            "  inflating: /content/train/pop/pop.00049.png  \n",
            "  inflating: /content/train/pop/pop.00050.png  \n",
            "  inflating: /content/train/pop/pop.00051.png  \n",
            "  inflating: /content/train/pop/pop.00052.png  \n",
            "  inflating: /content/train/pop/pop.00053.png  \n",
            "  inflating: /content/train/pop/pop.00054.png  \n",
            "  inflating: /content/train/pop/pop.00055.png  \n",
            "  inflating: /content/train/pop/pop.00056.png  \n",
            "  inflating: /content/train/pop/pop.00058.png  \n",
            "  inflating: /content/train/pop/pop.00059.png  \n",
            "  inflating: /content/train/pop/pop.00060.png  \n",
            "  inflating: /content/train/pop/pop.00061.png  \n",
            "  inflating: /content/train/pop/pop.00062.png  \n",
            "  inflating: /content/train/pop/pop.00064.png  \n",
            "  inflating: /content/train/pop/pop.00065.png  \n",
            "  inflating: /content/train/pop/pop.00066.png  \n",
            "  inflating: /content/train/pop/pop.00067.png  \n",
            "  inflating: /content/train/pop/pop.00068.png  \n",
            "  inflating: /content/train/pop/pop.00069.png  \n",
            "  inflating: /content/train/pop/pop.00070.png  \n",
            "  inflating: /content/train/pop/pop.00072.png  \n",
            "  inflating: /content/train/pop/pop.00073.png  \n",
            "  inflating: /content/train/pop/pop.00074.png  \n",
            "  inflating: /content/train/pop/pop.00075.png  \n",
            "  inflating: /content/train/pop/pop.00077.png  \n",
            "  inflating: /content/train/pop/pop.00078.png  \n",
            "  inflating: /content/train/pop/pop.00079.png  \n",
            "  inflating: /content/train/pop/pop.00081.png  \n",
            "  inflating: /content/train/pop/pop.00082.png  \n",
            "  inflating: /content/train/pop/pop.00083.png  \n",
            "  inflating: /content/train/pop/pop.00085.png  \n",
            "  inflating: /content/train/pop/pop.00086.png  \n",
            "  inflating: /content/train/pop/pop.00088.png  \n",
            "  inflating: /content/train/pop/pop.00089.png  \n",
            "  inflating: /content/train/pop/pop.00090.png  \n",
            "  inflating: /content/train/pop/pop.00091.png  \n",
            "  inflating: /content/train/pop/pop.00092.png  \n",
            "  inflating: /content/train/pop/pop.00094.png  \n",
            "  inflating: /content/train/pop/pop.00095.png  \n",
            "  inflating: /content/train/pop/pop.00096.png  \n",
            "  inflating: /content/train/pop/pop.00097.png  \n",
            "  inflating: /content/train/pop/pop.00098.png  \n",
            "  inflating: /content/train/pop/pop.00099.png  \n",
            "   creating: /content/train/reggae/\n",
            "  inflating: /content/train/reggae/reggae.00000.png  \n",
            "  inflating: /content/train/reggae/reggae.00001.png  \n",
            "  inflating: /content/train/reggae/reggae.00003.png  \n",
            "  inflating: /content/train/reggae/reggae.00005.png  \n",
            "  inflating: /content/train/reggae/reggae.00006.png  \n",
            "  inflating: /content/train/reggae/reggae.00007.png  \n",
            "  inflating: /content/train/reggae/reggae.00008.png  \n",
            "  inflating: /content/train/reggae/reggae.00009.png  \n",
            "  inflating: /content/train/reggae/reggae.00010.png  \n",
            "  inflating: /content/train/reggae/reggae.00011.png  \n",
            "  inflating: /content/train/reggae/reggae.00012.png  \n",
            "  inflating: /content/train/reggae/reggae.00013.png  \n",
            "  inflating: /content/train/reggae/reggae.00014.png  \n",
            "  inflating: /content/train/reggae/reggae.00017.png  \n",
            "  inflating: /content/train/reggae/reggae.00018.png  \n",
            "  inflating: /content/train/reggae/reggae.00019.png  \n",
            "  inflating: /content/train/reggae/reggae.00020.png  \n",
            "  inflating: /content/train/reggae/reggae.00021.png  \n",
            "  inflating: /content/train/reggae/reggae.00023.png  \n",
            "  inflating: /content/train/reggae/reggae.00024.png  \n",
            "  inflating: /content/train/reggae/reggae.00026.png  \n",
            "  inflating: /content/train/reggae/reggae.00027.png  \n",
            "  inflating: /content/train/reggae/reggae.00029.png  \n",
            "  inflating: /content/train/reggae/reggae.00030.png  \n",
            "  inflating: /content/train/reggae/reggae.00031.png  \n",
            "  inflating: /content/train/reggae/reggae.00032.png  \n",
            "  inflating: /content/train/reggae/reggae.00033.png  \n",
            "  inflating: /content/train/reggae/reggae.00034.png  \n",
            "  inflating: /content/train/reggae/reggae.00036.png  \n",
            "  inflating: /content/train/reggae/reggae.00037.png  \n",
            "  inflating: /content/train/reggae/reggae.00038.png  \n",
            "  inflating: /content/train/reggae/reggae.00040.png  \n",
            "  inflating: /content/train/reggae/reggae.00041.png  \n",
            "  inflating: /content/train/reggae/reggae.00043.png  \n",
            "  inflating: /content/train/reggae/reggae.00044.png  \n",
            "  inflating: /content/train/reggae/reggae.00046.png  \n",
            "  inflating: /content/train/reggae/reggae.00048.png  \n",
            "  inflating: /content/train/reggae/reggae.00049.png  \n",
            "  inflating: /content/train/reggae/reggae.00050.png  \n",
            "  inflating: /content/train/reggae/reggae.00052.png  \n",
            "  inflating: /content/train/reggae/reggae.00053.png  \n",
            "  inflating: /content/train/reggae/reggae.00054.png  \n",
            "  inflating: /content/train/reggae/reggae.00055.png  \n",
            "  inflating: /content/train/reggae/reggae.00056.png  \n",
            "  inflating: /content/train/reggae/reggae.00057.png  \n",
            "  inflating: /content/train/reggae/reggae.00058.png  \n",
            "  inflating: /content/train/reggae/reggae.00059.png  \n",
            "  inflating: /content/train/reggae/reggae.00060.png  \n",
            "  inflating: /content/train/reggae/reggae.00061.png  \n",
            "  inflating: /content/train/reggae/reggae.00062.png  \n",
            "  inflating: /content/train/reggae/reggae.00063.png  \n",
            "  inflating: /content/train/reggae/reggae.00064.png  \n",
            "  inflating: /content/train/reggae/reggae.00065.png  \n",
            "  inflating: /content/train/reggae/reggae.00066.png  \n",
            "  inflating: /content/train/reggae/reggae.00067.png  \n",
            "  inflating: /content/train/reggae/reggae.00068.png  \n",
            "  inflating: /content/train/reggae/reggae.00070.png  \n",
            "  inflating: /content/train/reggae/reggae.00072.png  \n",
            "  inflating: /content/train/reggae/reggae.00074.png  \n",
            "  inflating: /content/train/reggae/reggae.00076.png  \n",
            "  inflating: /content/train/reggae/reggae.00077.png  \n",
            "  inflating: /content/train/reggae/reggae.00078.png  \n",
            "  inflating: /content/train/reggae/reggae.00079.png  \n",
            "  inflating: /content/train/reggae/reggae.00081.png  \n",
            "  inflating: /content/train/reggae/reggae.00082.png  \n",
            "  inflating: /content/train/reggae/reggae.00083.png  \n",
            "  inflating: /content/train/reggae/reggae.00085.png  \n",
            "  inflating: /content/train/reggae/reggae.00086.png  \n",
            "  inflating: /content/train/reggae/reggae.00087.png  \n",
            "  inflating: /content/train/reggae/reggae.00088.png  \n",
            "  inflating: /content/train/reggae/reggae.00090.png  \n",
            "  inflating: /content/train/reggae/reggae.00091.png  \n",
            "  inflating: /content/train/reggae/reggae.00092.png  \n",
            "  inflating: /content/train/reggae/reggae.00093.png  \n",
            "  inflating: /content/train/reggae/reggae.00094.png  \n",
            "  inflating: /content/train/reggae/reggae.00095.png  \n",
            "  inflating: /content/train/reggae/reggae.00096.png  \n",
            "  inflating: /content/train/reggae/reggae.00097.png  \n",
            "  inflating: /content/train/reggae/reggae.00098.png  \n",
            "  inflating: /content/train/reggae/reggae.00099.png  \n",
            "   creating: /content/train/rock/\n",
            "  inflating: /content/train/rock/rock.00000.png  \n",
            "  inflating: /content/train/rock/rock.00002.png  \n",
            "  inflating: /content/train/rock/rock.00003.png  \n",
            "  inflating: /content/train/rock/rock.00004.png  \n",
            "  inflating: /content/train/rock/rock.00006.png  \n",
            "  inflating: /content/train/rock/rock.00007.png  \n",
            "  inflating: /content/train/rock/rock.00008.png  \n",
            "  inflating: /content/train/rock/rock.00009.png  \n",
            "  inflating: /content/train/rock/rock.00010.png  \n",
            "  inflating: /content/train/rock/rock.00013.png  \n",
            "  inflating: /content/train/rock/rock.00014.png  \n",
            "  inflating: /content/train/rock/rock.00016.png  \n",
            "  inflating: /content/train/rock/rock.00017.png  \n",
            "  inflating: /content/train/rock/rock.00018.png  \n",
            "  inflating: /content/train/rock/rock.00019.png  \n",
            "  inflating: /content/train/rock/rock.00020.png  \n",
            "  inflating: /content/train/rock/rock.00021.png  \n",
            "  inflating: /content/train/rock/rock.00022.png  \n",
            "  inflating: /content/train/rock/rock.00025.png  \n",
            "  inflating: /content/train/rock/rock.00026.png  \n",
            "  inflating: /content/train/rock/rock.00027.png  \n",
            "  inflating: /content/train/rock/rock.00028.png  \n",
            "  inflating: /content/train/rock/rock.00031.png  \n",
            "  inflating: /content/train/rock/rock.00032.png  \n",
            "  inflating: /content/train/rock/rock.00033.png  \n",
            "  inflating: /content/train/rock/rock.00034.png  \n",
            "  inflating: /content/train/rock/rock.00035.png  \n",
            "  inflating: /content/train/rock/rock.00036.png  \n",
            "  inflating: /content/train/rock/rock.00038.png  \n",
            "  inflating: /content/train/rock/rock.00039.png  \n",
            "  inflating: /content/train/rock/rock.00040.png  \n",
            "  inflating: /content/train/rock/rock.00042.png  \n",
            "  inflating: /content/train/rock/rock.00043.png  \n",
            "  inflating: /content/train/rock/rock.00044.png  \n",
            "  inflating: /content/train/rock/rock.00045.png  \n",
            "  inflating: /content/train/rock/rock.00047.png  \n",
            "  inflating: /content/train/rock/rock.00048.png  \n",
            "  inflating: /content/train/rock/rock.00049.png  \n",
            "  inflating: /content/train/rock/rock.00050.png  \n",
            "  inflating: /content/train/rock/rock.00051.png  \n",
            "  inflating: /content/train/rock/rock.00052.png  \n",
            "  inflating: /content/train/rock/rock.00053.png  \n",
            "  inflating: /content/train/rock/rock.00054.png  \n",
            "  inflating: /content/train/rock/rock.00055.png  \n",
            "  inflating: /content/train/rock/rock.00056.png  \n",
            "  inflating: /content/train/rock/rock.00058.png  \n",
            "  inflating: /content/train/rock/rock.00059.png  \n",
            "  inflating: /content/train/rock/rock.00060.png  \n",
            "  inflating: /content/train/rock/rock.00061.png  \n",
            "  inflating: /content/train/rock/rock.00062.png  \n",
            "  inflating: /content/train/rock/rock.00063.png  \n",
            "  inflating: /content/train/rock/rock.00064.png  \n",
            "  inflating: /content/train/rock/rock.00066.png  \n",
            "  inflating: /content/train/rock/rock.00067.png  \n",
            "  inflating: /content/train/rock/rock.00068.png  \n",
            "  inflating: /content/train/rock/rock.00070.png  \n",
            "  inflating: /content/train/rock/rock.00071.png  \n",
            "  inflating: /content/train/rock/rock.00072.png  \n",
            "  inflating: /content/train/rock/rock.00073.png  \n",
            "  inflating: /content/train/rock/rock.00075.png  \n",
            "  inflating: /content/train/rock/rock.00076.png  \n",
            "  inflating: /content/train/rock/rock.00077.png  \n",
            "  inflating: /content/train/rock/rock.00078.png  \n",
            "  inflating: /content/train/rock/rock.00080.png  \n",
            "  inflating: /content/train/rock/rock.00081.png  \n",
            "  inflating: /content/train/rock/rock.00082.png  \n",
            "  inflating: /content/train/rock/rock.00083.png  \n",
            "  inflating: /content/train/rock/rock.00084.png  \n",
            "  inflating: /content/train/rock/rock.00085.png  \n",
            "  inflating: /content/train/rock/rock.00088.png  \n",
            "  inflating: /content/train/rock/rock.00089.png  \n",
            "  inflating: /content/train/rock/rock.00091.png  \n",
            "  inflating: /content/train/rock/rock.00092.png  \n",
            "  inflating: /content/train/rock/rock.00093.png  \n",
            "  inflating: /content/train/rock/rock.00094.png  \n",
            "  inflating: /content/train/rock/rock.00095.png  \n",
            "  inflating: /content/train/rock/rock.00096.png  \n",
            "  inflating: /content/train/rock/rock.00097.png  \n",
            "  inflating: /content/train/rock/rock.00098.png  \n",
            "  inflating: /content/train/rock/rock.00099.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data"
      ],
      "metadata": {
        "id": "pm6PhXPeneJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spectrograms_test_dir = '/content/spectrograms_mel/test'\n",
        "spectrograms_train_dir = '/content/spectrograms_mel/train'\n",
        "\n",
        "train_ds = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "  spectrograms_train_dir,\n",
        "  label_mode='categorical',\n",
        "  seed=123,\n",
        "  image_size=(600, 300))\n",
        "\n",
        "test_ds = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "  spectrograms_test_dir,\n",
        "  label_mode='categorical',\n",
        "  seed=123,\n",
        "  image_size=(600, 300))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwOCeFsxDgg3",
        "outputId": "335dabfc-4783-4c7a-9980-3b8f21a4ea2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 798 files belonging to 10 classes.\n",
            "Found 200 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(images, labels):\n",
        "  return tensorflow.keras.applications.resnet50.preprocess_input(images), labels\n",
        "\n",
        "train_ds = train_ds.map(preprocess)"
      ],
      "metadata": {
        "id": "4-HNgfzpbus4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = create_nn_model_1()\n",
        "# model = create_nn_model_4()\n",
        "# model = create_nn_model_3()\n",
        "model = create_nn_model_2()"
      ],
      "metadata": {
        "id": "50Ay9dSubFog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad258726-f617-4dd0-9475-a6e33203a821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = \"/content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/\"\n",
        "checkpoint_subdir = os.path.join(checkpoint_dir, model.name)\n",
        "if not os.path.exists(checkpoint_subdir):\n",
        "  os.makedirs(checkpoint_subdir)\n",
        "\n",
        "checkpoint_path = os.path.join(checkpoint_subdir, f\"best_model_original_mel.keras\")"
      ],
      "metadata": {
        "id": "ZmvV5ZbXbDP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model, checkpoint = resnet_compile(model, checkpoint_path)\n",
        "model, reduce_lr, checkpoint = model_1_compile(model, checkpoint_path)"
      ],
      "metadata": {
        "id": "zx348HM1bG53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train models"
      ],
      "metadata": {
        "id": "7NYe78AE9GSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def save_history(history):\n",
        "  filename = f'{model.name}_history_original_mel.npy'\n",
        "  np.save(filename, H.history)\n",
        "  content_dir = \"/content/\" + filename\n",
        "  checkpoint_dir = \"/content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/\" + model.name\n",
        "  shutil.copy(content_dir, checkpoint_dir)"
      ],
      "metadata": {
        "id": "b48_UaiT7D_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet model"
      ],
      "metadata": {
        "id": "EgVKtWWVAqfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H = model.fit(train_ds, epochs=75, validation_data=test_ds, callbacks=[checkpoint])\n",
        "save_history(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Trk3Rsrc9In3",
        "outputId": "0a012741-8ff8-427a-bdbf-5a8974285dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.9113 - accuracy: 0.3484\n",
            "Epoch 1: val_accuracy improved from -inf to 0.42500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mel.h5\n",
            "25/25 [==============================] - 20s 642ms/step - loss: 1.9113 - accuracy: 0.3484 - val_loss: 1.5788 - val_accuracy: 0.4250\n",
            "Epoch 2/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4803 - accuracy: 0.4950\n",
            "Epoch 2: val_accuracy improved from 0.42500 to 0.53500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mel.h5\n",
            "25/25 [==============================] - 16s 605ms/step - loss: 1.4803 - accuracy: 0.4950 - val_loss: 1.3855 - val_accuracy: 0.5350\n",
            "Epoch 3/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2989 - accuracy: 0.5789\n",
            "Epoch 3: val_accuracy improved from 0.53500 to 0.57500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mel.h5\n",
            "25/25 [==============================] - 16s 600ms/step - loss: 1.2989 - accuracy: 0.5789 - val_loss: 1.3020 - val_accuracy: 0.5750\n",
            "Epoch 4/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1934 - accuracy: 0.6266\n",
            "Epoch 4: val_accuracy improved from 0.57500 to 0.59500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mel.h5\n",
            "25/25 [==============================] - 18s 660ms/step - loss: 1.1934 - accuracy: 0.6266 - val_loss: 1.2374 - val_accuracy: 0.5950\n",
            "Epoch 5/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1457 - accuracy: 0.6178\n",
            "Epoch 5: val_accuracy did not improve from 0.59500\n",
            "25/25 [==============================] - 13s 495ms/step - loss: 1.1457 - accuracy: 0.6178 - val_loss: 1.2614 - val_accuracy: 0.5750\n",
            "Epoch 6/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0754 - accuracy: 0.6529\n",
            "Epoch 6: val_accuracy did not improve from 0.59500\n",
            "25/25 [==============================] - 14s 480ms/step - loss: 1.0754 - accuracy: 0.6529 - val_loss: 1.1887 - val_accuracy: 0.5950\n",
            "Epoch 7/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0137 - accuracy: 0.6591\n",
            "Epoch 7: val_accuracy improved from 0.59500 to 0.60000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mel.h5\n",
            "25/25 [==============================] - 16s 597ms/step - loss: 1.0137 - accuracy: 0.6591 - val_loss: 1.1976 - val_accuracy: 0.6000\n",
            "Epoch 8/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9651 - accuracy: 0.6955\n",
            "Epoch 8: val_accuracy did not improve from 0.60000\n",
            "25/25 [==============================] - 13s 503ms/step - loss: 0.9651 - accuracy: 0.6955 - val_loss: 1.2006 - val_accuracy: 0.5850\n",
            "Epoch 9/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9235 - accuracy: 0.7080\n",
            "Epoch 9: val_accuracy did not improve from 0.60000\n",
            "25/25 [==============================] - 14s 508ms/step - loss: 0.9235 - accuracy: 0.7080 - val_loss: 1.2007 - val_accuracy: 0.5750\n",
            "Epoch 10/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8889 - accuracy: 0.7093\n",
            "Epoch 10: val_accuracy improved from 0.60000 to 0.63500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mel.h5\n",
            "25/25 [==============================] - 15s 581ms/step - loss: 0.8889 - accuracy: 0.7093 - val_loss: 1.1028 - val_accuracy: 0.6350\n",
            "Epoch 11/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8460 - accuracy: 0.7368\n",
            "Epoch 11: val_accuracy did not improve from 0.63500\n",
            "25/25 [==============================] - 15s 579ms/step - loss: 0.8460 - accuracy: 0.7368 - val_loss: 1.1546 - val_accuracy: 0.6000\n",
            "Epoch 12/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8150 - accuracy: 0.7456\n",
            "Epoch 12: val_accuracy did not improve from 0.63500\n",
            "25/25 [==============================] - 13s 485ms/step - loss: 0.8150 - accuracy: 0.7456 - val_loss: 1.1268 - val_accuracy: 0.6200\n",
            "Epoch 13/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7949 - accuracy: 0.7544\n",
            "Epoch 13: val_accuracy did not improve from 0.63500\n",
            "25/25 [==============================] - 14s 488ms/step - loss: 0.7949 - accuracy: 0.7544 - val_loss: 1.0837 - val_accuracy: 0.6150\n",
            "Epoch 14/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7711 - accuracy: 0.7569\n",
            "Epoch 14: val_accuracy improved from 0.63500 to 0.66500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mel.h5\n",
            "25/25 [==============================] - 16s 593ms/step - loss: 0.7711 - accuracy: 0.7569 - val_loss: 1.0943 - val_accuracy: 0.6650\n",
            "Epoch 15/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7460 - accuracy: 0.7644\n",
            "Epoch 15: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 14s 510ms/step - loss: 0.7460 - accuracy: 0.7644 - val_loss: 1.0500 - val_accuracy: 0.6350\n",
            "Epoch 16/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7260 - accuracy: 0.7769\n",
            "Epoch 16: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 491ms/step - loss: 0.7260 - accuracy: 0.7769 - val_loss: 1.0775 - val_accuracy: 0.6500\n",
            "Epoch 17/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7051 - accuracy: 0.7832\n",
            "Epoch 17: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 493ms/step - loss: 0.7051 - accuracy: 0.7832 - val_loss: 1.0541 - val_accuracy: 0.6650\n",
            "Epoch 18/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6737 - accuracy: 0.7820\n",
            "Epoch 18: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 486ms/step - loss: 0.6737 - accuracy: 0.7820 - val_loss: 1.1260 - val_accuracy: 0.5900\n",
            "Epoch 19/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6570 - accuracy: 0.7832\n",
            "Epoch 19: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 482ms/step - loss: 0.6570 - accuracy: 0.7832 - val_loss: 1.0254 - val_accuracy: 0.6450\n",
            "Epoch 20/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6442 - accuracy: 0.8120\n",
            "Epoch 20: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 491ms/step - loss: 0.6442 - accuracy: 0.8120 - val_loss: 1.0158 - val_accuracy: 0.6550\n",
            "Epoch 21/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.8083\n",
            "Epoch 21: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 493ms/step - loss: 0.6238 - accuracy: 0.8083 - val_loss: 1.0239 - val_accuracy: 0.6550\n",
            "Epoch 22/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.8246\n",
            "Epoch 22: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 496ms/step - loss: 0.6023 - accuracy: 0.8246 - val_loss: 1.0067 - val_accuracy: 0.6650\n",
            "Epoch 23/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.8296\n",
            "Epoch 23: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 500ms/step - loss: 0.5992 - accuracy: 0.8296 - val_loss: 1.0702 - val_accuracy: 0.6350\n",
            "Epoch 24/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5755 - accuracy: 0.8308\n",
            "Epoch 24: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 487ms/step - loss: 0.5755 - accuracy: 0.8308 - val_loss: 1.0191 - val_accuracy: 0.6650\n",
            "Epoch 25/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.8396\n",
            "Epoch 25: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 14s 507ms/step - loss: 0.5734 - accuracy: 0.8396 - val_loss: 1.0088 - val_accuracy: 0.6500\n",
            "Epoch 26/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.8396\n",
            "Epoch 26: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 14s 525ms/step - loss: 0.5472 - accuracy: 0.8396 - val_loss: 1.0342 - val_accuracy: 0.6650\n",
            "Epoch 27/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.8308\n",
            "Epoch 27: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 14s 513ms/step - loss: 0.5528 - accuracy: 0.8308 - val_loss: 0.9850 - val_accuracy: 0.6650\n",
            "Epoch 28/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5288 - accuracy: 0.8446\n",
            "Epoch 28: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 499ms/step - loss: 0.5288 - accuracy: 0.8446 - val_loss: 0.9944 - val_accuracy: 0.6450\n",
            "Epoch 29/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5225 - accuracy: 0.8446\n",
            "Epoch 29: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 492ms/step - loss: 0.5225 - accuracy: 0.8446 - val_loss: 0.9808 - val_accuracy: 0.6500\n",
            "Epoch 30/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5125 - accuracy: 0.8521\n",
            "Epoch 30: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 16s 570ms/step - loss: 0.5125 - accuracy: 0.8521 - val_loss: 0.9818 - val_accuracy: 0.6550\n",
            "Epoch 31/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5016 - accuracy: 0.8596\n",
            "Epoch 31: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 489ms/step - loss: 0.5016 - accuracy: 0.8596 - val_loss: 1.0053 - val_accuracy: 0.6550\n",
            "Epoch 32/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.8697\n",
            "Epoch 32: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 14s 504ms/step - loss: 0.4838 - accuracy: 0.8697 - val_loss: 1.0088 - val_accuracy: 0.6500\n",
            "Epoch 33/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.8697\n",
            "Epoch 33: val_accuracy did not improve from 0.66500\n",
            "25/25 [==============================] - 13s 504ms/step - loss: 0.4761 - accuracy: 0.8697 - val_loss: 1.0067 - val_accuracy: 0.6450\n",
            "Epoch 34/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.8709\n",
            "Epoch 34: val_accuracy improved from 0.66500 to 0.67500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mel.h5\n",
            "25/25 [==============================] - 16s 593ms/step - loss: 0.4768 - accuracy: 0.8709 - val_loss: 0.9992 - val_accuracy: 0.6750\n",
            "Epoch 35/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.8747\n",
            "Epoch 35: val_accuracy did not improve from 0.67500\n",
            "25/25 [==============================] - 13s 494ms/step - loss: 0.4679 - accuracy: 0.8747 - val_loss: 0.9765 - val_accuracy: 0.6700\n",
            "Epoch 36/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.8747\n",
            "Epoch 36: val_accuracy did not improve from 0.67500\n",
            "25/25 [==============================] - 13s 497ms/step - loss: 0.4525 - accuracy: 0.8747 - val_loss: 0.9949 - val_accuracy: 0.6650\n",
            "Epoch 37/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.8885\n",
            "Epoch 37: val_accuracy did not improve from 0.67500\n",
            "25/25 [==============================] - 13s 501ms/step - loss: 0.4490 - accuracy: 0.8885 - val_loss: 0.9670 - val_accuracy: 0.6700\n",
            "Epoch 38/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.8847\n",
            "Epoch 38: val_accuracy did not improve from 0.67500\n",
            "25/25 [==============================] - 13s 498ms/step - loss: 0.4346 - accuracy: 0.8847 - val_loss: 0.9753 - val_accuracy: 0.6650\n",
            "Epoch 39/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.8897\n",
            "Epoch 39: val_accuracy did not improve from 0.67500\n",
            "25/25 [==============================] - 13s 496ms/step - loss: 0.4311 - accuracy: 0.8897 - val_loss: 0.9637 - val_accuracy: 0.6750\n",
            "Epoch 40/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.8872\n",
            "Epoch 40: val_accuracy did not improve from 0.67500\n",
            "25/25 [==============================] - 13s 489ms/step - loss: 0.4237 - accuracy: 0.8872 - val_loss: 0.9614 - val_accuracy: 0.6650\n",
            "Epoch 41/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.8922\n",
            "Epoch 41: val_accuracy did not improve from 0.67500\n",
            "25/25 [==============================] - 13s 499ms/step - loss: 0.4192 - accuracy: 0.8922 - val_loss: 0.9636 - val_accuracy: 0.6700\n",
            "Epoch 42/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.8860\n",
            "Epoch 42: val_accuracy did not improve from 0.67500\n",
            "25/25 [==============================] - 14s 526ms/step - loss: 0.4240 - accuracy: 0.8860 - val_loss: 0.9591 - val_accuracy: 0.6650\n",
            "Epoch 43/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4026 - accuracy: 0.9023\n",
            "Epoch 43: val_accuracy did not improve from 0.67500\n",
            "25/25 [==============================] - 13s 492ms/step - loss: 0.4026 - accuracy: 0.9023 - val_loss: 0.9771 - val_accuracy: 0.6700\n",
            "Epoch 44/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3986 - accuracy: 0.9048\n",
            "Epoch 44: val_accuracy did not improve from 0.67500\n",
            "25/25 [==============================] - 13s 491ms/step - loss: 0.3986 - accuracy: 0.9048 - val_loss: 0.9874 - val_accuracy: 0.6700\n",
            "Epoch 45/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4012 - accuracy: 0.8897\n",
            "Epoch 45: val_accuracy improved from 0.67500 to 0.68000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mel.h5\n",
            "25/25 [==============================] - 16s 575ms/step - loss: 0.4012 - accuracy: 0.8897 - val_loss: 0.9503 - val_accuracy: 0.6800\n",
            "Epoch 46/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.9035\n",
            "Epoch 46: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 13s 504ms/step - loss: 0.3894 - accuracy: 0.9035 - val_loss: 0.9595 - val_accuracy: 0.6700\n",
            "Epoch 47/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.9135\n",
            "Epoch 47: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 510ms/step - loss: 0.3854 - accuracy: 0.9135 - val_loss: 0.9559 - val_accuracy: 0.6700\n",
            "Epoch 48/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.9073\n",
            "Epoch 48: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 514ms/step - loss: 0.3847 - accuracy: 0.9073 - val_loss: 0.9563 - val_accuracy: 0.6750\n",
            "Epoch 49/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.9073\n",
            "Epoch 49: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 512ms/step - loss: 0.3766 - accuracy: 0.9073 - val_loss: 0.9600 - val_accuracy: 0.6600\n",
            "Epoch 50/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3747 - accuracy: 0.9073\n",
            "Epoch 50: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 511ms/step - loss: 0.3747 - accuracy: 0.9073 - val_loss: 0.9597 - val_accuracy: 0.6750\n",
            "Epoch 51/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3652 - accuracy: 0.9085\n",
            "Epoch 51: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 510ms/step - loss: 0.3652 - accuracy: 0.9085 - val_loss: 0.9573 - val_accuracy: 0.6750\n",
            "Epoch 52/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3652 - accuracy: 0.9110\n",
            "Epoch 52: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 511ms/step - loss: 0.3652 - accuracy: 0.9110 - val_loss: 0.9590 - val_accuracy: 0.6600\n",
            "Epoch 53/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.9148\n",
            "Epoch 53: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 515ms/step - loss: 0.3586 - accuracy: 0.9148 - val_loss: 0.9616 - val_accuracy: 0.6800\n",
            "Epoch 54/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.9198\n",
            "Epoch 54: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 509ms/step - loss: 0.3563 - accuracy: 0.9198 - val_loss: 0.9561 - val_accuracy: 0.6800\n",
            "Epoch 55/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.9223\n",
            "Epoch 55: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 13s 486ms/step - loss: 0.3514 - accuracy: 0.9223 - val_loss: 0.9521 - val_accuracy: 0.6700\n",
            "Epoch 56/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3484 - accuracy: 0.9173\n",
            "Epoch 56: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 13s 494ms/step - loss: 0.3484 - accuracy: 0.9173 - val_loss: 0.9532 - val_accuracy: 0.6700\n",
            "Epoch 57/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.9261\n",
            "Epoch 57: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 13s 504ms/step - loss: 0.3438 - accuracy: 0.9261 - val_loss: 0.9532 - val_accuracy: 0.6500\n",
            "Epoch 58/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3442 - accuracy: 0.9211\n",
            "Epoch 58: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 489ms/step - loss: 0.3442 - accuracy: 0.9211 - val_loss: 0.9551 - val_accuracy: 0.6750\n",
            "Epoch 59/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3413 - accuracy: 0.9261\n",
            "Epoch 59: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 493ms/step - loss: 0.3413 - accuracy: 0.9261 - val_loss: 0.9535 - val_accuracy: 0.6650\n",
            "Epoch 60/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3362 - accuracy: 0.9261\n",
            "Epoch 60: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 13s 487ms/step - loss: 0.3362 - accuracy: 0.9261 - val_loss: 0.9550 - val_accuracy: 0.6650\n",
            "Epoch 61/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3360 - accuracy: 0.9286\n",
            "Epoch 61: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 511ms/step - loss: 0.3360 - accuracy: 0.9286 - val_loss: 0.9552 - val_accuracy: 0.6750\n",
            "Epoch 62/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3283 - accuracy: 0.9298\n",
            "Epoch 62: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 527ms/step - loss: 0.3283 - accuracy: 0.9298 - val_loss: 0.9634 - val_accuracy: 0.6650\n",
            "Epoch 63/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.9261\n",
            "Epoch 63: val_accuracy did not improve from 0.68000\n",
            "25/25 [==============================] - 14s 523ms/step - loss: 0.3300 - accuracy: 0.9261 - val_loss: 0.9444 - val_accuracy: 0.6750\n",
            "Epoch 64/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3238 - accuracy: 0.9311\n",
            "Epoch 64: val_accuracy improved from 0.68000 to 0.68500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mel.h5\n",
            "25/25 [==============================] - 21s 813ms/step - loss: 0.3238 - accuracy: 0.9311 - val_loss: 0.9562 - val_accuracy: 0.6850\n",
            "Epoch 65/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.9348\n",
            "Epoch 65: val_accuracy did not improve from 0.68500\n",
            "25/25 [==============================] - 14s 482ms/step - loss: 0.3218 - accuracy: 0.9348 - val_loss: 0.9571 - val_accuracy: 0.6750\n",
            "Epoch 66/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.9248\n",
            "Epoch 66: val_accuracy did not improve from 0.68500\n",
            "25/25 [==============================] - 13s 491ms/step - loss: 0.3235 - accuracy: 0.9248 - val_loss: 0.9576 - val_accuracy: 0.6700\n",
            "Epoch 67/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3187 - accuracy: 0.9336\n",
            "Epoch 67: val_accuracy did not improve from 0.68500\n",
            "25/25 [==============================] - 13s 503ms/step - loss: 0.3187 - accuracy: 0.9336 - val_loss: 0.9495 - val_accuracy: 0.6650\n",
            "Epoch 68/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.9336\n",
            "Epoch 68: val_accuracy did not improve from 0.68500\n",
            "25/25 [==============================] - 14s 498ms/step - loss: 0.3177 - accuracy: 0.9336 - val_loss: 0.9493 - val_accuracy: 0.6800\n",
            "Epoch 69/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3139 - accuracy: 0.9398\n",
            "Epoch 69: val_accuracy did not improve from 0.68500\n",
            "25/25 [==============================] - 13s 486ms/step - loss: 0.3139 - accuracy: 0.9398 - val_loss: 0.9501 - val_accuracy: 0.6700\n",
            "Epoch 70/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.9348\n",
            "Epoch 70: val_accuracy did not improve from 0.68500\n",
            "25/25 [==============================] - 13s 493ms/step - loss: 0.3144 - accuracy: 0.9348 - val_loss: 0.9491 - val_accuracy: 0.6800\n",
            "Epoch 71/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3102 - accuracy: 0.9373\n",
            "Epoch 71: val_accuracy did not improve from 0.68500\n",
            "25/25 [==============================] - 14s 486ms/step - loss: 0.3102 - accuracy: 0.9373 - val_loss: 0.9494 - val_accuracy: 0.6750\n",
            "Epoch 72/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3095 - accuracy: 0.9386\n",
            "Epoch 72: val_accuracy did not improve from 0.68500\n",
            "25/25 [==============================] - 14s 499ms/step - loss: 0.3095 - accuracy: 0.9386 - val_loss: 0.9491 - val_accuracy: 0.6750\n",
            "Epoch 73/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.9336\n",
            "Epoch 73: val_accuracy did not improve from 0.68500\n",
            "25/25 [==============================] - 13s 497ms/step - loss: 0.3072 - accuracy: 0.9336 - val_loss: 0.9482 - val_accuracy: 0.6800\n",
            "Epoch 74/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.9449\n",
            "Epoch 74: val_accuracy did not improve from 0.68500\n",
            "25/25 [==============================] - 13s 496ms/step - loss: 0.3060 - accuracy: 0.9449 - val_loss: 0.9469 - val_accuracy: 0.6800\n",
            "Epoch 75/75\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.9436\n",
            "Epoch 75: val_accuracy did not improve from 0.68500\n",
            "25/25 [==============================] - 14s 515ms/step - loss: 0.3036 - accuracy: 0.9436 - val_loss: 0.9474 - val_accuracy: 0.6700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Model_1"
      ],
      "metadata": {
        "id": "rk97zIIEAwlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H = model.fit(train_ds, epochs=50, validation_data=test_ds, callbacks=[checkpoint, reduce_lr])\n",
        "save_history(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NU8Yf-yNA7Yo",
        "outputId": "484d3eb6-07f2-4681-912d-be0435df6078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 37.8100 - accuracy: 0.1015\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 40s 1s/step - loss: 37.8100 - accuracy: 0.1015 - val_loss: 2.2590 - val_accuracy: 0.1550 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.1766 - accuracy: 0.1792\n",
            "Epoch 2: val_accuracy improved from 0.15500 to 0.22000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 21s 816ms/step - loss: 2.1766 - accuracy: 0.1792 - val_loss: 2.1355 - val_accuracy: 0.2200 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.0346 - accuracy: 0.2419\n",
            "Epoch 3: val_accuracy improved from 0.22000 to 0.26500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 23s 889ms/step - loss: 2.0346 - accuracy: 0.2419 - val_loss: 2.0643 - val_accuracy: 0.2650 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8987 - accuracy: 0.3145\n",
            "Epoch 4: val_accuracy improved from 0.26500 to 0.38000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 22s 823ms/step - loss: 1.8987 - accuracy: 0.3145 - val_loss: 1.8254 - val_accuracy: 0.3800 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6936 - accuracy: 0.3935\n",
            "Epoch 5: val_accuracy did not improve from 0.38000\n",
            "25/25 [==============================] - 20s 769ms/step - loss: 1.6936 - accuracy: 0.3935 - val_loss: 1.7140 - val_accuracy: 0.3800 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5693 - accuracy: 0.4173\n",
            "Epoch 6: val_accuracy improved from 0.38000 to 0.39500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 22s 835ms/step - loss: 1.5693 - accuracy: 0.4173 - val_loss: 1.6795 - val_accuracy: 0.3950 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5382 - accuracy: 0.4236\n",
            "Epoch 7: val_accuracy did not improve from 0.39500\n",
            "25/25 [==============================] - 20s 755ms/step - loss: 1.5382 - accuracy: 0.4236 - val_loss: 1.7261 - val_accuracy: 0.3550 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4233 - accuracy: 0.4762\n",
            "Epoch 8: val_accuracy did not improve from 0.39500\n",
            "25/25 [==============================] - 19s 738ms/step - loss: 1.4233 - accuracy: 0.4762 - val_loss: 1.6185 - val_accuracy: 0.3950 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3830 - accuracy: 0.4875\n",
            "Epoch 9: val_accuracy improved from 0.39500 to 0.43000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 23s 877ms/step - loss: 1.3830 - accuracy: 0.4875 - val_loss: 1.5316 - val_accuracy: 0.4300 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3307 - accuracy: 0.4987\n",
            "Epoch 10: val_accuracy improved from 0.43000 to 0.44000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 23s 876ms/step - loss: 1.3307 - accuracy: 0.4987 - val_loss: 1.6348 - val_accuracy: 0.4400 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2853 - accuracy: 0.5113\n",
            "Epoch 11: val_accuracy improved from 0.44000 to 0.55000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 22s 852ms/step - loss: 1.2853 - accuracy: 0.5113 - val_loss: 1.3897 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1749 - accuracy: 0.5777\n",
            "Epoch 12: val_accuracy did not improve from 0.55000\n",
            "25/25 [==============================] - 19s 732ms/step - loss: 1.1749 - accuracy: 0.5777 - val_loss: 1.4805 - val_accuracy: 0.5450 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1676 - accuracy: 0.5514\n",
            "Epoch 13: val_accuracy did not improve from 0.55000\n",
            "25/25 [==============================] - 20s 735ms/step - loss: 1.1676 - accuracy: 0.5514 - val_loss: 1.6524 - val_accuracy: 0.4600 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1546 - accuracy: 0.5551\n",
            "Epoch 14: val_accuracy improved from 0.55000 to 0.55500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 22s 855ms/step - loss: 1.1546 - accuracy: 0.5551 - val_loss: 1.4000 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0451 - accuracy: 0.6216\n",
            "Epoch 15: val_accuracy did not improve from 0.55500\n",
            "25/25 [==============================] - 19s 736ms/step - loss: 1.0451 - accuracy: 0.6216 - val_loss: 1.4466 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0710 - accuracy: 0.6053\n",
            "Epoch 16: val_accuracy did not improve from 0.55500\n",
            "25/25 [==============================] - 21s 745ms/step - loss: 1.0710 - accuracy: 0.6053 - val_loss: 1.2973 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9409 - accuracy: 0.6704\n",
            "Epoch 17: val_accuracy did not improve from 0.55500\n",
            "25/25 [==============================] - 20s 741ms/step - loss: 0.9409 - accuracy: 0.6704 - val_loss: 1.3739 - val_accuracy: 0.5350 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0203 - accuracy: 0.6128\n",
            "Epoch 18: val_accuracy did not improve from 0.55500\n",
            "25/25 [==============================] - 20s 769ms/step - loss: 1.0203 - accuracy: 0.6128 - val_loss: 1.2956 - val_accuracy: 0.5250 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9240 - accuracy: 0.6591\n",
            "Epoch 19: val_accuracy improved from 0.55500 to 0.56000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 23s 863ms/step - loss: 0.9240 - accuracy: 0.6591 - val_loss: 1.3065 - val_accuracy: 0.5600 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0221 - accuracy: 0.6228\n",
            "Epoch 20: val_accuracy did not improve from 0.56000\n",
            "25/25 [==============================] - 20s 744ms/step - loss: 1.0221 - accuracy: 0.6228 - val_loss: 1.4847 - val_accuracy: 0.5050 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7634 - accuracy: 0.7218\n",
            "Epoch 21: val_accuracy improved from 0.56000 to 0.57000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 23s 890ms/step - loss: 0.7634 - accuracy: 0.7218 - val_loss: 1.3411 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7795 - accuracy: 0.6967\n",
            "Epoch 22: val_accuracy did not improve from 0.57000\n",
            "25/25 [==============================] - 20s 769ms/step - loss: 0.7795 - accuracy: 0.6967 - val_loss: 1.6201 - val_accuracy: 0.5300 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7337 - accuracy: 0.7318\n",
            "Epoch 23: val_accuracy improved from 0.57000 to 0.58000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 22s 838ms/step - loss: 0.7337 - accuracy: 0.7318 - val_loss: 1.5496 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6821 - accuracy: 0.7318\n",
            "Epoch 24: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 20s 741ms/step - loss: 0.6821 - accuracy: 0.7318 - val_loss: 1.5401 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7128 - accuracy: 0.7381\n",
            "Epoch 25: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 20s 744ms/step - loss: 0.7128 - accuracy: 0.7381 - val_loss: 1.7354 - val_accuracy: 0.4650 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5639 - accuracy: 0.7870\n",
            "Epoch 26: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 20s 742ms/step - loss: 0.5639 - accuracy: 0.7870 - val_loss: 1.5029 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6113 - accuracy: 0.7769\n",
            "Epoch 27: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 21s 793ms/step - loss: 0.6113 - accuracy: 0.7769 - val_loss: 1.6863 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.8058\n",
            "Epoch 28: val_accuracy improved from 0.58000 to 0.60000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 22s 852ms/step - loss: 0.5249 - accuracy: 0.8058 - val_loss: 1.5946 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4755 - accuracy: 0.8308\n",
            "Epoch 29: val_accuracy did not improve from 0.60000\n",
            "25/25 [==============================] - 19s 742ms/step - loss: 0.4755 - accuracy: 0.8308 - val_loss: 1.7607 - val_accuracy: 0.5650 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.8546\n",
            "Epoch 30: val_accuracy did not improve from 0.60000\n",
            "25/25 [==============================] - 21s 754ms/step - loss: 0.4208 - accuracy: 0.8546 - val_loss: 2.2460 - val_accuracy: 0.5100 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6170 - accuracy: 0.7832\n",
            "Epoch 31: val_accuracy did not improve from 0.60000\n",
            "25/25 [==============================] - 20s 735ms/step - loss: 0.6170 - accuracy: 0.7832 - val_loss: 1.6239 - val_accuracy: 0.5100 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5105 - accuracy: 0.8233\n",
            "Epoch 32: val_accuracy did not improve from 0.60000\n",
            "25/25 [==============================] - 20s 748ms/step - loss: 0.5105 - accuracy: 0.8233 - val_loss: 1.9785 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.8521\n",
            "Epoch 33: val_accuracy did not improve from 0.60000\n",
            "25/25 [==============================] - 20s 738ms/step - loss: 0.4270 - accuracy: 0.8521 - val_loss: 1.7924 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4153 - accuracy: 0.8546\n",
            "Epoch 34: val_accuracy did not improve from 0.60000\n",
            "25/25 [==============================] - 19s 729ms/step - loss: 0.4153 - accuracy: 0.8546 - val_loss: 2.1478 - val_accuracy: 0.4850 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8810\n",
            "Epoch 35: val_accuracy improved from 0.60000 to 0.61000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mel.h5\n",
            "25/25 [==============================] - 23s 847ms/step - loss: 0.3548 - accuracy: 0.8810 - val_loss: 1.8026 - val_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.9060\n",
            "Epoch 36: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 20s 735ms/step - loss: 0.3117 - accuracy: 0.9060 - val_loss: 2.0774 - val_accuracy: 0.4900 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.8684\n",
            "Epoch 37: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 20s 750ms/step - loss: 0.3749 - accuracy: 0.8684 - val_loss: 1.8038 - val_accuracy: 0.5150 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.8784\n",
            "Epoch 38: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 21s 793ms/step - loss: 0.3574 - accuracy: 0.8784 - val_loss: 1.8846 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8885\n",
            "Epoch 39: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 20s 754ms/step - loss: 0.3312 - accuracy: 0.8885 - val_loss: 2.0484 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2773 - accuracy: 0.9098\n",
            "Epoch 40: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 21s 760ms/step - loss: 0.2773 - accuracy: 0.9098 - val_loss: 2.2676 - val_accuracy: 0.5250 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.8985\n",
            "Epoch 41: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 20s 766ms/step - loss: 0.3700 - accuracy: 0.8985 - val_loss: 2.8997 - val_accuracy: 0.4350 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5106 - accuracy: 0.8383\n",
            "Epoch 42: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 19s 739ms/step - loss: 0.5106 - accuracy: 0.8383 - val_loss: 2.3201 - val_accuracy: 0.4700 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.9085\n",
            "Epoch 43: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 20s 757ms/step - loss: 0.2687 - accuracy: 0.9085 - val_loss: 2.2262 - val_accuracy: 0.4900 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9348\n",
            "Epoch 44: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 20s 730ms/step - loss: 0.2152 - accuracy: 0.9348 - val_loss: 2.1751 - val_accuracy: 0.5600 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.9323\n",
            "Epoch 45: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 19s 741ms/step - loss: 0.1903 - accuracy: 0.9323 - val_loss: 2.1326 - val_accuracy: 0.5650 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.9135\n",
            "Epoch 46: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 20s 732ms/step - loss: 0.2834 - accuracy: 0.9135 - val_loss: 2.2818 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.9386\n",
            "Epoch 47: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 19s 734ms/step - loss: 0.2117 - accuracy: 0.9386 - val_loss: 2.1792 - val_accuracy: 0.5650 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.9524\n",
            "Epoch 48: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 21s 791ms/step - loss: 0.1506 - accuracy: 0.9524 - val_loss: 2.2814 - val_accuracy: 0.6050 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.9398\n",
            "Epoch 49: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 19s 738ms/step - loss: 0.1857 - accuracy: 0.9398 - val_loss: 2.5742 - val_accuracy: 0.5250 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1507 - accuracy: 0.9549\n",
            "Epoch 50: val_accuracy did not improve from 0.61000\n",
            "25/25 [==============================] - 19s 735ms/step - loss: 0.1507 - accuracy: 0.9549 - val_loss: 2.2606 - val_accuracy: 0.5200 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Model_2"
      ],
      "metadata": {
        "id": "wV6NPduZH4H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H = model.fit(train_ds, epochs=200, validation_data=test_ds, callbacks=[checkpoint, reduce_lr])\n",
        "save_history(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zJFthWbUH3lj",
        "outputId": "d579c38a-88e0-464f-95a3-9ff7e2d0d38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - accuracy: 0.1844 - loss: 2.5155\n",
            "Epoch 1: val_accuracy improved from -inf to 0.13500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 963ms/step - accuracy: 0.1864 - loss: 2.5094 - val_accuracy: 0.1350 - val_loss: 2.2613 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.3538 - loss: 1.8908\n",
            "Epoch 2: val_accuracy did not improve from 0.13500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 246ms/step - accuracy: 0.3541 - loss: 1.8897 - val_accuracy: 0.1050 - val_loss: 3.5002 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.4008 - loss: 1.7263\n",
            "Epoch 3: val_accuracy did not improve from 0.13500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.4017 - loss: 1.7234 - val_accuracy: 0.1000 - val_loss: 6.9595 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.4655 - loss: 1.4997\n",
            "Epoch 4: val_accuracy did not improve from 0.13500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.4670 - loss: 1.4982 - val_accuracy: 0.1000 - val_loss: 9.2415 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.5517 - loss: 1.3807\n",
            "Epoch 5: val_accuracy did not improve from 0.13500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 261ms/step - accuracy: 0.5523 - loss: 1.3793 - val_accuracy: 0.1000 - val_loss: 9.9713 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.6559 - loss: 1.1809\n",
            "Epoch 6: val_accuracy did not improve from 0.13500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 303ms/step - accuracy: 0.6566 - loss: 1.1790 - val_accuracy: 0.1000 - val_loss: 12.9601 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7303 - loss: 1.0165\n",
            "Epoch 7: val_accuracy did not improve from 0.13500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 189ms/step - accuracy: 0.7311 - loss: 1.0141 - val_accuracy: 0.1000 - val_loss: 15.2579 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.7785 - loss: 0.8594\n",
            "Epoch 8: val_accuracy did not improve from 0.13500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 250ms/step - accuracy: 0.7800 - loss: 0.8568 - val_accuracy: 0.1000 - val_loss: 16.8414 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8408 - loss: 0.7067\n",
            "Epoch 9: val_accuracy did not improve from 0.13500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 193ms/step - accuracy: 0.8416 - loss: 0.7050 - val_accuracy: 0.0850 - val_loss: 18.4102 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.8876 - loss: 0.5715\n",
            "Epoch 10: val_accuracy did not improve from 0.13500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 266ms/step - accuracy: 0.8881 - loss: 0.5700 - val_accuracy: 0.1050 - val_loss: 17.4151 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9323 - loss: 0.4511\n",
            "Epoch 11: val_accuracy did not improve from 0.13500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 187ms/step - accuracy: 0.9324 - loss: 0.4500 - val_accuracy: 0.1100 - val_loss: 16.8984 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9653 - loss: 0.3713\n",
            "Epoch 12: val_accuracy did not improve from 0.13500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - accuracy: 0.9653 - loss: 0.3711 - val_accuracy: 0.0950 - val_loss: 15.9693 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9509 - loss: 0.3298\n",
            "Epoch 13: val_accuracy improved from 0.13500 to 0.16500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 256ms/step - accuracy: 0.9514 - loss: 0.3290 - val_accuracy: 0.1650 - val_loss: 15.3855 - learning_rate: 0.0010\n",
            "Epoch 14/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9643 - loss: 0.2799\n",
            "Epoch 14: val_accuracy improved from 0.16500 to 0.18000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 348ms/step - accuracy: 0.9645 - loss: 0.2793 - val_accuracy: 0.1800 - val_loss: 15.3613 - learning_rate: 0.0010\n",
            "Epoch 15/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9880 - loss: 0.1896\n",
            "Epoch 15: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 390ms/step - accuracy: 0.9878 - loss: 0.1897 - val_accuracy: 0.1200 - val_loss: 15.3359 - learning_rate: 0.0010\n",
            "Epoch 16/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9863 - loss: 0.1788\n",
            "Epoch 16: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - accuracy: 0.9864 - loss: 0.1783 - val_accuracy: 0.1350 - val_loss: 15.0157 - learning_rate: 0.0010\n",
            "Epoch 17/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9756 - loss: 0.1564\n",
            "Epoch 17: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.9760 - loss: 0.1559 - val_accuracy: 0.1050 - val_loss: 14.9176 - learning_rate: 0.0010\n",
            "Epoch 18/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9884 - loss: 0.1377\n",
            "Epoch 18: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 248ms/step - accuracy: 0.9884 - loss: 0.1375 - val_accuracy: 0.1100 - val_loss: 14.5426 - learning_rate: 0.0010\n",
            "Epoch 19/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9903 - loss: 0.1191\n",
            "Epoch 19: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.9904 - loss: 0.1190 - val_accuracy: 0.1100 - val_loss: 13.3897 - learning_rate: 0.0010\n",
            "Epoch 20/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9896 - loss: 0.1186\n",
            "Epoch 20: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 189ms/step - accuracy: 0.9898 - loss: 0.1183 - val_accuracy: 0.1500 - val_loss: 12.0630 - learning_rate: 0.0010\n",
            "Epoch 21/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9881 - loss: 0.1204\n",
            "Epoch 21: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 311ms/step - accuracy: 0.9881 - loss: 0.1203 - val_accuracy: 0.1150 - val_loss: 11.1179 - learning_rate: 0.0010\n",
            "Epoch 22/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9914 - loss: 0.1024\n",
            "Epoch 22: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - accuracy: 0.9915 - loss: 0.1018 - val_accuracy: 0.1100 - val_loss: 10.8424 - learning_rate: 0.0010\n",
            "Epoch 23/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9919 - loss: 0.0894\n",
            "Epoch 23: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 264ms/step - accuracy: 0.9919 - loss: 0.0889 - val_accuracy: 0.1050 - val_loss: 11.7223 - learning_rate: 0.0010\n",
            "Epoch 24/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9933 - loss: 0.0790\n",
            "Epoch 24: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - accuracy: 0.9933 - loss: 0.0789 - val_accuracy: 0.1050 - val_loss: 11.2242 - learning_rate: 0.0010\n",
            "Epoch 25/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9939 - loss: 0.0645\n",
            "Epoch 25: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - accuracy: 0.9940 - loss: 0.0641 - val_accuracy: 0.1050 - val_loss: 11.0430 - learning_rate: 0.0010\n",
            "Epoch 26/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9987 - loss: 0.0580\n",
            "Epoch 26: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.9986 - loss: 0.0581 - val_accuracy: 0.1150 - val_loss: 10.5278 - learning_rate: 0.0010\n",
            "Epoch 27/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9952 - loss: 0.0505\n",
            "Epoch 27: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - accuracy: 0.9953 - loss: 0.0505 - val_accuracy: 0.1450 - val_loss: 9.8065 - learning_rate: 0.0010\n",
            "Epoch 28/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9955 - loss: 0.0604\n",
            "Epoch 28: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 191ms/step - accuracy: 0.9955 - loss: 0.0603 - val_accuracy: 0.1050 - val_loss: 9.9511 - learning_rate: 0.0010\n",
            "Epoch 29/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9891 - loss: 0.0584\n",
            "Epoch 29: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 0.9894 - loss: 0.0579 - val_accuracy: 0.1050 - val_loss: 9.9271 - learning_rate: 0.0010\n",
            "Epoch 30/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9912 - loss: 0.0460\n",
            "Epoch 30: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - accuracy: 0.9914 - loss: 0.0459 - val_accuracy: 0.1050 - val_loss: 10.8220 - learning_rate: 0.0010\n",
            "Epoch 31/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9985 - loss: 0.0351\n",
            "Epoch 31: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 269ms/step - accuracy: 0.9985 - loss: 0.0353 - val_accuracy: 0.1050 - val_loss: 11.2015 - learning_rate: 0.0010\n",
            "Epoch 32/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9966 - loss: 0.0554\n",
            "Epoch 32: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.9966 - loss: 0.0552 - val_accuracy: 0.1050 - val_loss: 10.8502 - learning_rate: 0.0010\n",
            "Epoch 33/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9954 - loss: 0.0343\n",
            "Epoch 33: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 271ms/step - accuracy: 0.9955 - loss: 0.0342 - val_accuracy: 0.1050 - val_loss: 10.7435 - learning_rate: 0.0010\n",
            "Epoch 34/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9952 - loss: 0.0347\n",
            "Epoch 34: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - accuracy: 0.9954 - loss: 0.0344 - val_accuracy: 0.1050 - val_loss: 10.4517 - learning_rate: 0.0010\n",
            "Epoch 35/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9972 - loss: 0.0293\n",
            "Epoch 35: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 290ms/step - accuracy: 0.9972 - loss: 0.0295 - val_accuracy: 0.1000 - val_loss: 11.9392 - learning_rate: 0.0010\n",
            "Epoch 36/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9971 - loss: 0.0327\n",
            "Epoch 36: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9971 - loss: 0.0327 - val_accuracy: 0.1050 - val_loss: 9.6955 - learning_rate: 0.0010\n",
            "Epoch 37/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9969 - loss: 0.0306\n",
            "Epoch 37: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 277ms/step - accuracy: 0.9969 - loss: 0.0306 - val_accuracy: 0.1050 - val_loss: 9.6199 - learning_rate: 0.0010\n",
            "Epoch 38/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9982 - loss: 0.0225\n",
            "Epoch 38: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - accuracy: 0.9981 - loss: 0.0228 - val_accuracy: 0.1150 - val_loss: 9.1811 - learning_rate: 0.0010\n",
            "Epoch 39/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9956 - loss: 0.0229\n",
            "Epoch 39: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 257ms/step - accuracy: 0.9957 - loss: 0.0230 - val_accuracy: 0.1050 - val_loss: 9.3487 - learning_rate: 0.0010\n",
            "Epoch 40/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9994 - loss: 0.0221\n",
            "Epoch 40: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 230ms/step - accuracy: 0.9993 - loss: 0.0223 - val_accuracy: 0.1100 - val_loss: 9.1067 - learning_rate: 0.0010\n",
            "Epoch 41/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9941 - loss: 0.0281\n",
            "Epoch 41: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - accuracy: 0.9942 - loss: 0.0281 - val_accuracy: 0.1050 - val_loss: 9.2888 - learning_rate: 0.0010\n",
            "Epoch 42/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9966 - loss: 0.0352\n",
            "Epoch 42: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 254ms/step - accuracy: 0.9966 - loss: 0.0350 - val_accuracy: 0.1050 - val_loss: 10.1662 - learning_rate: 0.0010\n",
            "Epoch 43/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9989 - loss: 0.0229\n",
            "Epoch 43: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 192ms/step - accuracy: 0.9988 - loss: 0.0229 - val_accuracy: 0.1000 - val_loss: 8.6377 - learning_rate: 0.0010\n",
            "Epoch 44/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9964 - loss: 0.0279\n",
            "Epoch 44: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 270ms/step - accuracy: 0.9964 - loss: 0.0277 - val_accuracy: 0.1100 - val_loss: 9.8985 - learning_rate: 0.0010\n",
            "Epoch 45/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9990 - loss: 0.0172\n",
            "Epoch 45: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - accuracy: 0.9990 - loss: 0.0172 - val_accuracy: 0.1300 - val_loss: 9.1041 - learning_rate: 0.0010\n",
            "Epoch 46/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9978 - loss: 0.0199\n",
            "Epoch 46: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 260ms/step - accuracy: 0.9978 - loss: 0.0199 - val_accuracy: 0.1250 - val_loss: 8.5852 - learning_rate: 0.0010\n",
            "Epoch 47/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9907 - loss: 0.0263\n",
            "Epoch 47: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - accuracy: 0.9908 - loss: 0.0263 - val_accuracy: 0.1100 - val_loss: 10.2772 - learning_rate: 0.0010\n",
            "Epoch 48/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9956 - loss: 0.0377\n",
            "Epoch 48: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 0.9955 - loss: 0.0377 - val_accuracy: 0.1100 - val_loss: 9.7969 - learning_rate: 0.0010\n",
            "Epoch 49/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9817 - loss: 0.0606\n",
            "Epoch 49: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 190ms/step - accuracy: 0.9819 - loss: 0.0603 - val_accuracy: 0.1500 - val_loss: 7.7541 - learning_rate: 0.0010\n",
            "Epoch 50/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9998 - loss: 0.0274\n",
            "Epoch 50: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 258ms/step - accuracy: 0.9998 - loss: 0.0274 - val_accuracy: 0.1400 - val_loss: 8.1691 - learning_rate: 0.0010\n",
            "Epoch 51/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9896 - loss: 0.0350\n",
            "Epoch 51: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - accuracy: 0.9898 - loss: 0.0348 - val_accuracy: 0.1250 - val_loss: 8.9870 - learning_rate: 0.0010\n",
            "Epoch 52/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9939 - loss: 0.0313\n",
            "Epoch 52: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - accuracy: 0.9937 - loss: 0.0321 - val_accuracy: 0.1350 - val_loss: 8.8239 - learning_rate: 0.0010\n",
            "Epoch 53/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9860 - loss: 0.0571\n",
            "Epoch 53: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 0.9862 - loss: 0.0567 - val_accuracy: 0.1150 - val_loss: 9.0543 - learning_rate: 0.0010\n",
            "Epoch 54/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9915 - loss: 0.0425\n",
            "Epoch 54: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.9915 - loss: 0.0424 - val_accuracy: 0.1050 - val_loss: 10.6491 - learning_rate: 0.0010\n",
            "Epoch 55/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9943 - loss: 0.0346\n",
            "Epoch 55: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.9943 - loss: 0.0347 - val_accuracy: 0.1450 - val_loss: 10.3116 - learning_rate: 0.0010\n",
            "Epoch 56/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9934 - loss: 0.0372\n",
            "Epoch 56: val_accuracy improved from 0.18000 to 0.19000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 401ms/step - accuracy: 0.9933 - loss: 0.0374 - val_accuracy: 0.1900 - val_loss: 8.7641 - learning_rate: 0.0010\n",
            "Epoch 57/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9880 - loss: 0.0473\n",
            "Epoch 57: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - accuracy: 0.9882 - loss: 0.0470 - val_accuracy: 0.1500 - val_loss: 8.9896 - learning_rate: 0.0010\n",
            "Epoch 58/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9985 - loss: 0.0312\n",
            "Epoch 58: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 248ms/step - accuracy: 0.9985 - loss: 0.0311 - val_accuracy: 0.1350 - val_loss: 9.0668 - learning_rate: 0.0010\n",
            "Epoch 59/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9950 - loss: 0.0292\n",
            "Epoch 59: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 0.9951 - loss: 0.0288 - val_accuracy: 0.1750 - val_loss: 8.9649 - learning_rate: 0.0010\n",
            "Epoch 60/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 0.0188\n",
            "Epoch 60: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.1700 - val_loss: 9.0024 - learning_rate: 0.0010\n",
            "Epoch 61/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9971 - loss: 0.0148\n",
            "Epoch 61: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - accuracy: 0.9972 - loss: 0.0147 - val_accuracy: 0.1450 - val_loss: 8.4582 - learning_rate: 0.0010\n",
            "Epoch 62/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9977 - loss: 0.0121\n",
            "Epoch 62: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.9977 - loss: 0.0121 - val_accuracy: 0.1150 - val_loss: 8.6489 - learning_rate: 0.0010\n",
            "Epoch 63/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9949 - loss: 0.0140\n",
            "Epoch 63: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 189ms/step - accuracy: 0.9950 - loss: 0.0139 - val_accuracy: 0.1250 - val_loss: 8.3975 - learning_rate: 0.0010\n",
            "Epoch 64/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0147\n",
            "Epoch 64: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.1150 - val_loss: 8.7772 - learning_rate: 0.0010\n",
            "Epoch 65/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9979 - loss: 0.0177\n",
            "Epoch 65: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - accuracy: 0.9979 - loss: 0.0176 - val_accuracy: 0.1550 - val_loss: 7.7869 - learning_rate: 0.0010\n",
            "Epoch 66/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9978 - loss: 0.0126\n",
            "Epoch 66: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 280ms/step - accuracy: 0.9979 - loss: 0.0126 - val_accuracy: 0.1150 - val_loss: 8.6015 - learning_rate: 0.0010\n",
            "Epoch 67/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9932 - loss: 0.0155\n",
            "Epoch 67: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.9933 - loss: 0.0155 - val_accuracy: 0.1100 - val_loss: 8.3838 - learning_rate: 0.0010\n",
            "Epoch 68/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9961 - loss: 0.0138\n",
            "Epoch 68: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - accuracy: 0.9961 - loss: 0.0139 - val_accuracy: 0.1050 - val_loss: 8.9012 - learning_rate: 0.0010\n",
            "Epoch 69/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 0.0086\n",
            "Epoch 69: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.1150 - val_loss: 8.5238 - learning_rate: 0.0010\n",
            "Epoch 70/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9969 - loss: 0.0134\n",
            "Epoch 70: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 237ms/step - accuracy: 0.9969 - loss: 0.0134 - val_accuracy: 0.1200 - val_loss: 7.7407 - learning_rate: 0.0010\n",
            "Epoch 71/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9989 - loss: 0.0099\n",
            "Epoch 71: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - accuracy: 0.9989 - loss: 0.0099 - val_accuracy: 0.1250 - val_loss: 8.0780 - learning_rate: 0.0010\n",
            "Epoch 72/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9930 - loss: 0.0249\n",
            "Epoch 72: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 278ms/step - accuracy: 0.9931 - loss: 0.0245 - val_accuracy: 0.1200 - val_loss: 8.4719 - learning_rate: 0.0010\n",
            "Epoch 73/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9959 - loss: 0.0136\n",
            "Epoch 73: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.9960 - loss: 0.0135 - val_accuracy: 0.1350 - val_loss: 7.9645 - learning_rate: 0.0010\n",
            "Epoch 74/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0077\n",
            "Epoch 74: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 267ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.1350 - val_loss: 9.2171 - learning_rate: 0.0010\n",
            "Epoch 75/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9998 - loss: 0.0125\n",
            "Epoch 75: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - accuracy: 0.9997 - loss: 0.0125 - val_accuracy: 0.1450 - val_loss: 8.6808 - learning_rate: 0.0010\n",
            "Epoch 76/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9988 - loss: 0.0118\n",
            "Epoch 76: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 354ms/step - accuracy: 0.9988 - loss: 0.0118 - val_accuracy: 0.1150 - val_loss: 9.6572 - learning_rate: 0.0010\n",
            "Epoch 77/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.0052\n",
            "Epoch 77: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.1050 - val_loss: 9.8415 - learning_rate: 0.0010\n",
            "Epoch 78/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9922 - loss: 0.0143\n",
            "Epoch 78: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 273ms/step - accuracy: 0.9924 - loss: 0.0142 - val_accuracy: 0.1000 - val_loss: 10.2373 - learning_rate: 0.0010\n",
            "Epoch 79/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9857 - loss: 0.0266\n",
            "Epoch 79: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - accuracy: 0.9858 - loss: 0.0265 - val_accuracy: 0.1150 - val_loss: 9.0145 - learning_rate: 0.0010\n",
            "Epoch 80/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9849 - loss: 0.0473\n",
            "Epoch 80: val_accuracy improved from 0.19000 to 0.23500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 255ms/step - accuracy: 0.9851 - loss: 0.0470 - val_accuracy: 0.2350 - val_loss: 6.6935 - learning_rate: 0.0010\n",
            "Epoch 81/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.9943 - loss: 0.0208\n",
            "Epoch 81: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 262ms/step - accuracy: 0.9944 - loss: 0.0206 - val_accuracy: 0.1300 - val_loss: 8.9105 - learning_rate: 0.0010\n",
            "Epoch 82/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9950 - loss: 0.0215\n",
            "Epoch 82: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - accuracy: 0.9950 - loss: 0.0215 - val_accuracy: 0.1450 - val_loss: 10.0206 - learning_rate: 0.0010\n",
            "Epoch 83/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9917 - loss: 0.0203\n",
            "Epoch 83: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.9919 - loss: 0.0200 - val_accuracy: 0.1550 - val_loss: 11.3259 - learning_rate: 0.0010\n",
            "Epoch 84/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9981 - loss: 0.0112\n",
            "Epoch 84: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - accuracy: 0.9981 - loss: 0.0111 - val_accuracy: 0.1550 - val_loss: 11.6394 - learning_rate: 0.0010\n",
            "Epoch 85/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9969 - loss: 0.0106\n",
            "Epoch 85: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 234ms/step - accuracy: 0.9970 - loss: 0.0107 - val_accuracy: 0.1400 - val_loss: 10.8400 - learning_rate: 0.0010\n",
            "Epoch 86/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9985 - loss: 0.0099\n",
            "Epoch 86: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 237ms/step - accuracy: 0.9984 - loss: 0.0100 - val_accuracy: 0.1150 - val_loss: 9.7319 - learning_rate: 0.0010\n",
            "Epoch 87/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9935 - loss: 0.0156\n",
            "Epoch 87: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9936 - loss: 0.0155 - val_accuracy: 0.1500 - val_loss: 11.7722 - learning_rate: 0.0010\n",
            "Epoch 88/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0110\n",
            "Epoch 88: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.1400 - val_loss: 9.9476 - learning_rate: 0.0010\n",
            "Epoch 89/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9994 - loss: 0.0091\n",
            "Epoch 89: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - accuracy: 0.9994 - loss: 0.0091 - val_accuracy: 0.1050 - val_loss: 10.3163 - learning_rate: 0.0010\n",
            "Epoch 90/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9978 - loss: 0.0083\n",
            "Epoch 90: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 300ms/step - accuracy: 0.9979 - loss: 0.0083 - val_accuracy: 0.1200 - val_loss: 10.0217 - learning_rate: 0.0010\n",
            "Epoch 91/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0078\n",
            "Epoch 91: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.1150 - val_loss: 9.5603 - learning_rate: 0.0010\n",
            "Epoch 92/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9975 - loss: 0.0087\n",
            "Epoch 92: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 193ms/step - accuracy: 0.9975 - loss: 0.0086 - val_accuracy: 0.1200 - val_loss: 8.6682 - learning_rate: 0.0010\n",
            "Epoch 93/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9916 - loss: 0.0181\n",
            "Epoch 93: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - accuracy: 0.9918 - loss: 0.0179 - val_accuracy: 0.1100 - val_loss: 8.7610 - learning_rate: 0.0010\n",
            "Epoch 94/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9937 - loss: 0.0149\n",
            "Epoch 94: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 257ms/step - accuracy: 0.9938 - loss: 0.0148 - val_accuracy: 0.1200 - val_loss: 9.6455 - learning_rate: 0.0010\n",
            "Epoch 95/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9988 - loss: 0.0097\n",
            "Epoch 95: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 281ms/step - accuracy: 0.9988 - loss: 0.0098 - val_accuracy: 0.1400 - val_loss: 8.6593 - learning_rate: 0.0010\n",
            "Epoch 96/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9986 - loss: 0.0085\n",
            "Epoch 96: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 308ms/step - accuracy: 0.9986 - loss: 0.0085 - val_accuracy: 0.2050 - val_loss: 7.0198 - learning_rate: 0.0010\n",
            "Epoch 97/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 1.0000 - loss: 0.0121\n",
            "Epoch 97: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 292ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.2150 - val_loss: 7.1522 - learning_rate: 0.0010\n",
            "Epoch 98/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9952 - loss: 0.0112\n",
            "Epoch 98: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 212ms/step - accuracy: 0.9953 - loss: 0.0111 - val_accuracy: 0.2150 - val_loss: 6.0248 - learning_rate: 0.0010\n",
            "Epoch 99/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0054\n",
            "Epoch 99: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.2350 - val_loss: 5.5292 - learning_rate: 0.0010\n",
            "Epoch 100/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9974 - loss: 0.0088\n",
            "Epoch 100: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 267ms/step - accuracy: 0.9974 - loss: 0.0088 - val_accuracy: 0.2000 - val_loss: 6.3478 - learning_rate: 0.0010\n",
            "Epoch 101/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9995 - loss: 0.0056\n",
            "Epoch 101: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 192ms/step - accuracy: 0.9993 - loss: 0.0058 - val_accuracy: 0.2150 - val_loss: 7.0374 - learning_rate: 0.0010\n",
            "Epoch 102/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0087\n",
            "Epoch 102: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.1850 - val_loss: 6.8460 - learning_rate: 0.0010\n",
            "Epoch 103/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9958 - loss: 0.0130\n",
            "Epoch 103: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 0.9959 - loss: 0.0129 - val_accuracy: 0.1650 - val_loss: 7.6433 - learning_rate: 0.0010\n",
            "Epoch 104/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9978 - loss: 0.0099\n",
            "Epoch 104: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - accuracy: 0.9978 - loss: 0.0098 - val_accuracy: 0.1500 - val_loss: 8.7498 - learning_rate: 0.0010\n",
            "Epoch 105/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9959 - loss: 0.0099\n",
            "Epoch 105: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 214ms/step - accuracy: 0.9960 - loss: 0.0098 - val_accuracy: 0.1550 - val_loss: 8.3788 - learning_rate: 0.0010\n",
            "Epoch 106/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.9995 - loss: 0.0047\n",
            "Epoch 106: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.1450 - val_loss: 8.1443 - learning_rate: 0.0010\n",
            "Epoch 107/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9990 - loss: 0.0035\n",
            "Epoch 107: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.1500 - val_loss: 8.2754 - learning_rate: 0.0010\n",
            "Epoch 108/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 0.0117\n",
            "Epoch 108: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.1350 - val_loss: 8.5012 - learning_rate: 0.0010\n",
            "Epoch 109/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 1.0000 - loss: 0.0045\n",
            "Epoch 109: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.1350 - val_loss: 8.4201 - learning_rate: 0.0010\n",
            "Epoch 110/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9980 - loss: 0.0060\n",
            "Epoch 110: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.1400 - val_loss: 9.0666 - learning_rate: 0.0010\n",
            "Epoch 111/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9952 - loss: 0.0162\n",
            "Epoch 111: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 265ms/step - accuracy: 0.9954 - loss: 0.0159 - val_accuracy: 0.1700 - val_loss: 8.5326 - learning_rate: 0.0010\n",
            "Epoch 112/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9943 - loss: 0.0102\n",
            "Epoch 112: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - accuracy: 0.9944 - loss: 0.0100 - val_accuracy: 0.1600 - val_loss: 8.6893 - learning_rate: 0.0010\n",
            "Epoch 113/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9991 - loss: 0.0054\n",
            "Epoch 113: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 245ms/step - accuracy: 0.9991 - loss: 0.0054 - val_accuracy: 0.1500 - val_loss: 8.1758 - learning_rate: 0.0010\n",
            "Epoch 114/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9952 - loss: 0.0152\n",
            "Epoch 114: val_accuracy did not improve from 0.23500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.9954 - loss: 0.0148 - val_accuracy: 0.1300 - val_loss: 8.6904 - learning_rate: 0.0010\n",
            "Epoch 115/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9935 - loss: 0.0147\n",
            "Epoch 115: val_accuracy improved from 0.23500 to 0.26500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 266ms/step - accuracy: 0.9936 - loss: 0.0145 - val_accuracy: 0.2650 - val_loss: 6.0047 - learning_rate: 0.0010\n",
            "Epoch 116/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9846 - loss: 0.0376\n",
            "Epoch 116: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 412ms/step - accuracy: 0.9845 - loss: 0.0377 - val_accuracy: 0.1600 - val_loss: 7.9010 - learning_rate: 0.0010\n",
            "Epoch 117/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9668 - loss: 0.0743\n",
            "Epoch 117: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - accuracy: 0.9669 - loss: 0.0741 - val_accuracy: 0.1950 - val_loss: 8.5369 - learning_rate: 0.0010\n",
            "Epoch 118/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9759 - loss: 0.0872\n",
            "Epoch 118: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9758 - loss: 0.0876 - val_accuracy: 0.1900 - val_loss: 9.9124 - learning_rate: 0.0010\n",
            "Epoch 119/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9755 - loss: 0.0855\n",
            "Epoch 119: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.9754 - loss: 0.0854 - val_accuracy: 0.1000 - val_loss: 12.2453 - learning_rate: 0.0010\n",
            "Epoch 120/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9810 - loss: 0.0529\n",
            "Epoch 120: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.9805 - loss: 0.0541 - val_accuracy: 0.1050 - val_loss: 12.1089 - learning_rate: 0.0010\n",
            "Epoch 121/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9834 - loss: 0.0708\n",
            "Epoch 121: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9834 - loss: 0.0706 - val_accuracy: 0.1850 - val_loss: 9.3420 - learning_rate: 0.0010\n",
            "Epoch 122/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9709 - loss: 0.0863\n",
            "Epoch 122: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.9712 - loss: 0.0854 - val_accuracy: 0.1650 - val_loss: 11.0936 - learning_rate: 0.0010\n",
            "Epoch 123/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.9810 - loss: 0.0489\n",
            "Epoch 123: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 316ms/step - accuracy: 0.9811 - loss: 0.0492 - val_accuracy: 0.1700 - val_loss: 11.3359 - learning_rate: 0.0010\n",
            "Epoch 124/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9868 - loss: 0.0399\n",
            "Epoch 124: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.9868 - loss: 0.0398 - val_accuracy: 0.2100 - val_loss: 9.5770 - learning_rate: 0.0010\n",
            "Epoch 125/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9807 - loss: 0.0593\n",
            "Epoch 125: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9809 - loss: 0.0588 - val_accuracy: 0.1600 - val_loss: 10.0131 - learning_rate: 0.0010\n",
            "Epoch 126/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9948 - loss: 0.0253\n",
            "Epoch 126: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - accuracy: 0.9949 - loss: 0.0253 - val_accuracy: 0.1900 - val_loss: 11.2245 - learning_rate: 0.0010\n",
            "Epoch 127/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9998 - loss: 0.0100\n",
            "Epoch 127: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - accuracy: 0.9997 - loss: 0.0101 - val_accuracy: 0.1650 - val_loss: 11.4301 - learning_rate: 0.0010\n",
            "Epoch 128/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9961 - loss: 0.0138\n",
            "Epoch 128: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 289ms/step - accuracy: 0.9961 - loss: 0.0138 - val_accuracy: 0.1600 - val_loss: 11.6654 - learning_rate: 0.0010\n",
            "Epoch 129/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0097\n",
            "Epoch 129: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 209ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.1600 - val_loss: 11.6289 - learning_rate: 0.0010\n",
            "Epoch 130/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9971 - loss: 0.0106\n",
            "Epoch 130: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.9972 - loss: 0.0105 - val_accuracy: 0.1500 - val_loss: 11.5727 - learning_rate: 0.0010\n",
            "Epoch 131/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9946 - loss: 0.0150\n",
            "Epoch 131: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - accuracy: 0.9947 - loss: 0.0149 - val_accuracy: 0.1200 - val_loss: 12.6753 - learning_rate: 0.0010\n",
            "Epoch 132/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9974 - loss: 0.0122\n",
            "Epoch 132: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 250ms/step - accuracy: 0.9974 - loss: 0.0121 - val_accuracy: 0.1200 - val_loss: 12.7361 - learning_rate: 0.0010\n",
            "Epoch 133/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9996 - loss: 0.0073\n",
            "Epoch 133: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.9996 - loss: 0.0073 - val_accuracy: 0.1150 - val_loss: 12.0524 - learning_rate: 0.0010\n",
            "Epoch 134/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9992 - loss: 0.0069\n",
            "Epoch 134: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 285ms/step - accuracy: 0.9992 - loss: 0.0069 - val_accuracy: 0.1150 - val_loss: 12.5159 - learning_rate: 0.0010\n",
            "Epoch 135/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9992 - loss: 0.0071\n",
            "Epoch 135: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.9992 - loss: 0.0071 - val_accuracy: 0.1200 - val_loss: 12.1724 - learning_rate: 0.0010\n",
            "Epoch 136/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9958 - loss: 0.0069\n",
            "Epoch 136: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 204ms/step - accuracy: 0.9958 - loss: 0.0070 - val_accuracy: 0.1350 - val_loss: 10.4596 - learning_rate: 0.0010\n",
            "Epoch 137/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9986 - loss: 0.0093\n",
            "Epoch 137: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 216ms/step - accuracy: 0.9986 - loss: 0.0093 - val_accuracy: 0.1200 - val_loss: 11.1126 - learning_rate: 0.0010\n",
            "Epoch 138/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9974 - loss: 0.0076\n",
            "Epoch 138: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.9974 - loss: 0.0076 - val_accuracy: 0.1300 - val_loss: 10.7930 - learning_rate: 0.0010\n",
            "Epoch 139/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9980 - loss: 0.0124\n",
            "Epoch 139: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - accuracy: 0.9979 - loss: 0.0125 - val_accuracy: 0.1150 - val_loss: 10.9187 - learning_rate: 0.0010\n",
            "Epoch 140/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9943 - loss: 0.0151\n",
            "Epoch 140: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 248ms/step - accuracy: 0.9944 - loss: 0.0151 - val_accuracy: 0.1100 - val_loss: 12.6806 - learning_rate: 0.0010\n",
            "Epoch 141/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9946 - loss: 0.0135\n",
            "Epoch 141: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.9946 - loss: 0.0134 - val_accuracy: 0.1100 - val_loss: 11.7240 - learning_rate: 0.0010\n",
            "Epoch 142/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9828 - loss: 0.0306\n",
            "Epoch 142: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 282ms/step - accuracy: 0.9833 - loss: 0.0300 - val_accuracy: 0.1150 - val_loss: 11.6539 - learning_rate: 0.0010\n",
            "Epoch 143/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9971 - loss: 0.0072\n",
            "Epoch 143: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 192ms/step - accuracy: 0.9972 - loss: 0.0071 - val_accuracy: 0.1250 - val_loss: 10.6875 - learning_rate: 0.0010\n",
            "Epoch 144/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9956 - loss: 0.0093\n",
            "Epoch 144: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 292ms/step - accuracy: 0.9956 - loss: 0.0093 - val_accuracy: 0.1300 - val_loss: 11.0937 - learning_rate: 0.0010\n",
            "Epoch 145/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9952 - loss: 0.0293\n",
            "Epoch 145: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 195ms/step - accuracy: 0.9954 - loss: 0.0287 - val_accuracy: 0.1950 - val_loss: 8.8095 - learning_rate: 0.0010\n",
            "Epoch 146/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9997 - loss: 0.0078\n",
            "Epoch 146: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 270ms/step - accuracy: 0.9996 - loss: 0.0078 - val_accuracy: 0.2000 - val_loss: 8.2156 - learning_rate: 0.0010\n",
            "Epoch 147/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9938 - loss: 0.0167\n",
            "Epoch 147: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - accuracy: 0.9938 - loss: 0.0166 - val_accuracy: 0.1550 - val_loss: 9.5805 - learning_rate: 0.0010\n",
            "Epoch 148/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9987 - loss: 0.0065\n",
            "Epoch 148: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 229ms/step - accuracy: 0.9986 - loss: 0.0066 - val_accuracy: 0.1600 - val_loss: 8.7018 - learning_rate: 0.0010\n",
            "Epoch 149/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9918 - loss: 0.0122\n",
            "Epoch 149: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 246ms/step - accuracy: 0.9920 - loss: 0.0121 - val_accuracy: 0.1750 - val_loss: 7.8328 - learning_rate: 0.0010\n",
            "Epoch 150/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9964 - loss: 0.0063\n",
            "Epoch 150: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 0.9964 - loss: 0.0063 - val_accuracy: 0.1550 - val_loss: 9.1389 - learning_rate: 0.0010\n",
            "Epoch 151/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9971 - loss: 0.0077\n",
            "Epoch 151: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - accuracy: 0.9972 - loss: 0.0076 - val_accuracy: 0.1400 - val_loss: 10.0666 - learning_rate: 0.0010\n",
            "Epoch 152/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9972 - loss: 0.0052\n",
            "Epoch 152: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 293ms/step - accuracy: 0.9972 - loss: 0.0052 - val_accuracy: 0.1350 - val_loss: 9.6378 - learning_rate: 0.0010\n",
            "Epoch 153/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9995 - loss: 0.0053\n",
            "Epoch 153: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - accuracy: 0.9994 - loss: 0.0053 - val_accuracy: 0.1200 - val_loss: 9.7241 - learning_rate: 0.0010\n",
            "Epoch 154/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9975 - loss: 0.0064\n",
            "Epoch 154: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 360ms/step - accuracy: 0.9976 - loss: 0.0064 - val_accuracy: 0.1250 - val_loss: 10.3004 - learning_rate: 0.0010\n",
            "Epoch 155/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0033\n",
            "Epoch 155: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.1300 - val_loss: 10.7366 - learning_rate: 0.0010\n",
            "Epoch 156/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9974 - loss: 0.0051\n",
            "Epoch 156: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - accuracy: 0.9974 - loss: 0.0051 - val_accuracy: 0.1350 - val_loss: 10.5767 - learning_rate: 0.0010\n",
            "Epoch 157/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9930 - loss: 0.0100\n",
            "Epoch 157: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 191ms/step - accuracy: 0.9931 - loss: 0.0100 - val_accuracy: 0.1400 - val_loss: 10.0380 - learning_rate: 0.0010\n",
            "Epoch 158/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9999 - loss: 0.0041\n",
            "Epoch 158: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 311ms/step - accuracy: 0.9999 - loss: 0.0041 - val_accuracy: 0.1400 - val_loss: 10.1389 - learning_rate: 0.0010\n",
            "Epoch 159/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9991 - loss: 0.0025\n",
            "Epoch 159: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 193ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 0.1450 - val_loss: 9.8814 - learning_rate: 0.0010\n",
            "Epoch 160/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9995 - loss: 0.0026\n",
            "Epoch 160: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 323ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.1400 - val_loss: 9.7894 - learning_rate: 0.0010\n",
            "Epoch 161/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9983 - loss: 0.0058\n",
            "Epoch 161: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.9983 - loss: 0.0058 - val_accuracy: 0.1350 - val_loss: 9.8178 - learning_rate: 0.0010\n",
            "Epoch 162/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9991 - loss: 0.0042\n",
            "Epoch 162: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 225ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 0.1550 - val_loss: 9.5743 - learning_rate: 0.0010\n",
            "Epoch 163/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9954 - loss: 0.0055\n",
            "Epoch 163: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 192ms/step - accuracy: 0.9954 - loss: 0.0054 - val_accuracy: 0.1600 - val_loss: 9.6395 - learning_rate: 0.0010\n",
            "Epoch 164/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9997 - loss: 0.0019\n",
            "Epoch 164: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 311ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.1500 - val_loss: 9.9630 - learning_rate: 0.0010\n",
            "Epoch 165/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9992 - loss: 0.0043\n",
            "Epoch 165: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 193ms/step - accuracy: 0.9992 - loss: 0.0044 - val_accuracy: 0.1600 - val_loss: 10.0771 - learning_rate: 0.0010\n",
            "Epoch 166/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9952 - loss: 0.0082\n",
            "Epoch 166: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 262ms/step - accuracy: 0.9954 - loss: 0.0080 - val_accuracy: 0.1500 - val_loss: 9.9863 - learning_rate: 0.0010\n",
            "Epoch 167/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9949 - loss: 0.0080\n",
            "Epoch 167: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.9950 - loss: 0.0078 - val_accuracy: 0.1400 - val_loss: 10.0506 - learning_rate: 0.0010\n",
            "Epoch 168/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9961 - loss: 0.0095\n",
            "Epoch 168: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.9962 - loss: 0.0094 - val_accuracy: 0.1350 - val_loss: 10.2448 - learning_rate: 0.0010\n",
            "Epoch 169/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9944 - loss: 0.0078\n",
            "Epoch 169: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - accuracy: 0.9946 - loss: 0.0076 - val_accuracy: 0.1350 - val_loss: 10.4918 - learning_rate: 0.0010\n",
            "Epoch 170/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9944 - loss: 0.0108\n",
            "Epoch 170: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.9946 - loss: 0.0106 - val_accuracy: 0.1350 - val_loss: 10.7177 - learning_rate: 0.0010\n",
            "Epoch 171/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9876 - loss: 0.0150\n",
            "Epoch 171: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 272ms/step - accuracy: 0.9879 - loss: 0.0146 - val_accuracy: 0.1250 - val_loss: 10.3316 - learning_rate: 0.0010\n",
            "Epoch 172/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9965 - loss: 0.0043\n",
            "Epoch 172: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 196ms/step - accuracy: 0.9966 - loss: 0.0042 - val_accuracy: 0.1250 - val_loss: 10.0657 - learning_rate: 0.0010\n",
            "Epoch 173/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9993 - loss: 0.0030\n",
            "Epoch 173: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 269ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.1250 - val_loss: 10.0346 - learning_rate: 0.0010\n",
            "Epoch 174/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9939 - loss: 0.0114\n",
            "Epoch 174: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 336ms/step - accuracy: 0.9940 - loss: 0.0112 - val_accuracy: 0.1300 - val_loss: 10.2970 - learning_rate: 0.0010\n",
            "Epoch 175/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9966 - loss: 0.0075\n",
            "Epoch 175: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.9966 - loss: 0.0075 - val_accuracy: 0.1600 - val_loss: 9.6585 - learning_rate: 0.0010\n",
            "Epoch 176/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9975 - loss: 0.0081\n",
            "Epoch 176: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.1400 - val_loss: 9.7781 - learning_rate: 0.0010\n",
            "Epoch 177/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.9951 - loss: 0.0150\n",
            "Epoch 177: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9952 - loss: 0.0147 - val_accuracy: 0.1300 - val_loss: 10.3170 - learning_rate: 0.0010\n",
            "Epoch 178/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9940 - loss: 0.0080\n",
            "Epoch 178: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.9941 - loss: 0.0079 - val_accuracy: 0.1350 - val_loss: 10.0139 - learning_rate: 0.0010\n",
            "Epoch 179/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9998 - loss: 0.0014\n",
            "Epoch 179: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 250ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.1350 - val_loss: 10.0681 - learning_rate: 0.0010\n",
            "Epoch 180/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9992 - loss: 0.0045\n",
            "Epoch 180: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 272ms/step - accuracy: 0.9992 - loss: 0.0046 - val_accuracy: 0.1250 - val_loss: 10.8101 - learning_rate: 0.0010\n",
            "Epoch 181/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9957 - loss: 0.0120\n",
            "Epoch 181: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.9957 - loss: 0.0121 - val_accuracy: 0.1200 - val_loss: 11.3629 - learning_rate: 0.0010\n",
            "Epoch 182/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9990 - loss: 0.0047\n",
            "Epoch 182: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - accuracy: 0.9990 - loss: 0.0048 - val_accuracy: 0.1250 - val_loss: 12.6220 - learning_rate: 0.0010\n",
            "Epoch 183/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9983 - loss: 0.0066\n",
            "Epoch 183: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 295ms/step - accuracy: 0.9983 - loss: 0.0066 - val_accuracy: 0.1700 - val_loss: 8.5414 - learning_rate: 0.0010\n",
            "Epoch 184/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9965 - loss: 0.0088\n",
            "Epoch 184: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 195ms/step - accuracy: 0.9966 - loss: 0.0087 - val_accuracy: 0.1750 - val_loss: 8.3730 - learning_rate: 0.0010\n",
            "Epoch 185/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9970 - loss: 0.0047\n",
            "Epoch 185: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 289ms/step - accuracy: 0.9971 - loss: 0.0047 - val_accuracy: 0.1950 - val_loss: 8.2637 - learning_rate: 0.0010\n",
            "Epoch 186/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0034\n",
            "Epoch 186: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.1400 - val_loss: 9.9563 - learning_rate: 0.0010\n",
            "Epoch 187/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9909 - loss: 0.0109\n",
            "Epoch 187: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9911 - loss: 0.0108 - val_accuracy: 0.2600 - val_loss: 6.8663 - learning_rate: 0.0010\n",
            "Epoch 188/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9940 - loss: 0.0083\n",
            "Epoch 188: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 198ms/step - accuracy: 0.9941 - loss: 0.0082 - val_accuracy: 0.2500 - val_loss: 7.2167 - learning_rate: 0.0010\n",
            "Epoch 189/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9917 - loss: 0.0163\n",
            "Epoch 189: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 273ms/step - accuracy: 0.9918 - loss: 0.0161 - val_accuracy: 0.1150 - val_loss: 10.9991 - learning_rate: 0.0010\n",
            "Epoch 190/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9991 - loss: 0.0072\n",
            "Epoch 190: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - accuracy: 0.9991 - loss: 0.0072 - val_accuracy: 0.1600 - val_loss: 8.6468 - learning_rate: 0.0010\n",
            "Epoch 191/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9928 - loss: 0.0090\n",
            "Epoch 191: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - accuracy: 0.9929 - loss: 0.0089 - val_accuracy: 0.1600 - val_loss: 8.5847 - learning_rate: 0.0010\n",
            "Epoch 192/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9965 - loss: 0.0137\n",
            "Epoch 192: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - accuracy: 0.9964 - loss: 0.0137 - val_accuracy: 0.1600 - val_loss: 8.4670 - learning_rate: 0.0010\n",
            "Epoch 193/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.9939 - loss: 0.0145\n",
            "Epoch 193: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 266ms/step - accuracy: 0.9940 - loss: 0.0143 - val_accuracy: 0.1250 - val_loss: 11.2209 - learning_rate: 0.0010\n",
            "Epoch 194/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9952 - loss: 0.0081\n",
            "Epoch 194: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - accuracy: 0.9952 - loss: 0.0081 - val_accuracy: 0.1300 - val_loss: 18.0532 - learning_rate: 0.0010\n",
            "Epoch 195/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.9946 - loss: 0.0104\n",
            "Epoch 195: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 361ms/step - accuracy: 0.9947 - loss: 0.0103 - val_accuracy: 0.1700 - val_loss: 11.0250 - learning_rate: 0.0010\n",
            "Epoch 196/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9928 - loss: 0.0202\n",
            "Epoch 196: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.9929 - loss: 0.0198 - val_accuracy: 0.1600 - val_loss: 9.4266 - learning_rate: 0.0010\n",
            "Epoch 197/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9975 - loss: 0.0076\n",
            "Epoch 197: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 267ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 0.1950 - val_loss: 9.0732 - learning_rate: 0.0010\n",
            "Epoch 198/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9988 - loss: 0.0055\n",
            "Epoch 198: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.9987 - loss: 0.0056 - val_accuracy: 0.1950 - val_loss: 8.3024 - learning_rate: 0.0010\n",
            "Epoch 199/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9928 - loss: 0.0122\n",
            "Epoch 199: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 215ms/step - accuracy: 0.9929 - loss: 0.0121 - val_accuracy: 0.1950 - val_loss: 8.8584 - learning_rate: 0.0010\n",
            "Epoch 200/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9941 - loss: 0.0131\n",
            "Epoch 200: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 245ms/step - accuracy: 0.9942 - loss: 0.0131 - val_accuracy: 0.1600 - val_loss: 43.9487 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/model_2_mel.h5 /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/"
      ],
      "metadata": {
        "id": "unZSF_HDPl8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Model_3"
      ],
      "metadata": {
        "id": "Haj2qeurpdlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H = model.fit(train_ds, epochs=200, validation_data=test_ds, callbacks=[checkpoint, reduce_lr])\n",
        "save_history(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "RIZyvtwYpc-x",
        "outputId": "baadbd84-7a08-4a25-e13c-45e52d4cb0fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848ms/step - accuracy: 0.2684 - loss: 2.5486\n",
            "Epoch 1: val_accuracy improved from -inf to 0.16500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.2702 - loss: 2.5366 - val_accuracy: 0.1650 - val_loss: 43.1497 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.4184 - loss: 1.6275\n",
            "Epoch 2: val_accuracy did not improve from 0.16500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 340ms/step - accuracy: 0.4196 - loss: 1.6247 - val_accuracy: 0.1250 - val_loss: 11.8138 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.5094 - loss: 1.3361\n",
            "Epoch 3: val_accuracy improved from 0.16500 to 0.18000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.5105 - loss: 1.3336 - val_accuracy: 0.1800 - val_loss: 7.1145 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.6511 - loss: 0.9837\n",
            "Epoch 4: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 254ms/step - accuracy: 0.6529 - loss: 0.9790 - val_accuracy: 0.1350 - val_loss: 13.1548 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.8665 - loss: 0.4540\n",
            "Epoch 5: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - accuracy: 0.8659 - loss: 0.4551 - val_accuracy: 0.1200 - val_loss: 8.8617 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.9473 - loss: 0.2355\n",
            "Epoch 6: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 314ms/step - accuracy: 0.9472 - loss: 0.2348 - val_accuracy: 0.1600 - val_loss: 8.0129 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9705 - loss: 0.1194\n",
            "Epoch 7: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - accuracy: 0.9699 - loss: 0.1205 - val_accuracy: 0.0950 - val_loss: 7.0787 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9429 - loss: 0.1525\n",
            "Epoch 8: val_accuracy did not improve from 0.18000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 236ms/step - accuracy: 0.9435 - loss: 0.1515 - val_accuracy: 0.1150 - val_loss: 5.7431 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9610 - loss: 0.0980\n",
            "Epoch 9: val_accuracy improved from 0.18000 to 0.18500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.9610 - loss: 0.0982 - val_accuracy: 0.1850 - val_loss: 3.7644 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9746 - loss: 0.1046\n",
            "Epoch 10: val_accuracy did not improve from 0.18500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 213ms/step - accuracy: 0.9746 - loss: 0.1038 - val_accuracy: 0.1500 - val_loss: 5.4990 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9850 - loss: 0.0537\n",
            "Epoch 11: val_accuracy improved from 0.18500 to 0.30000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.9849 - loss: 0.0542 - val_accuracy: 0.3000 - val_loss: 3.3490 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9814 - loss: 0.0763\n",
            "Epoch 12: val_accuracy did not improve from 0.30000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 247ms/step - accuracy: 0.9814 - loss: 0.0759 - val_accuracy: 0.2500 - val_loss: 4.3249 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9859 - loss: 0.0489\n",
            "Epoch 13: val_accuracy did not improve from 0.30000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9860 - loss: 0.0487 - val_accuracy: 0.2650 - val_loss: 3.8062 - learning_rate: 0.0010\n",
            "Epoch 14/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9800 - loss: 0.0622\n",
            "Epoch 14: val_accuracy improved from 0.30000 to 0.44000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.9801 - loss: 0.0617 - val_accuracy: 0.4400 - val_loss: 2.4567 - learning_rate: 0.0010\n",
            "Epoch 15/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9892 - loss: 0.0553\n",
            "Epoch 15: val_accuracy did not improve from 0.44000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 209ms/step - accuracy: 0.9892 - loss: 0.0549 - val_accuracy: 0.4000 - val_loss: 2.7723 - learning_rate: 0.0010\n",
            "Epoch 16/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9837 - loss: 0.0881\n",
            "Epoch 16: val_accuracy did not improve from 0.44000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 269ms/step - accuracy: 0.9839 - loss: 0.0871 - val_accuracy: 0.3000 - val_loss: 4.6777 - learning_rate: 0.0010\n",
            "Epoch 17/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9903 - loss: 0.0328\n",
            "Epoch 17: val_accuracy did not improve from 0.44000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.9904 - loss: 0.0325 - val_accuracy: 0.3250 - val_loss: 5.0988 - learning_rate: 0.0010\n",
            "Epoch 18/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9862 - loss: 0.0345\n",
            "Epoch 18: val_accuracy did not improve from 0.44000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 272ms/step - accuracy: 0.9863 - loss: 0.0346 - val_accuracy: 0.4350 - val_loss: 2.9396 - learning_rate: 0.0010\n",
            "Epoch 19/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9884 - loss: 0.0414\n",
            "Epoch 19: val_accuracy did not improve from 0.44000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 230ms/step - accuracy: 0.9883 - loss: 0.0413 - val_accuracy: 0.4000 - val_loss: 3.3124 - learning_rate: 0.0010\n",
            "Epoch 20/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9954 - loss: 0.0216\n",
            "Epoch 20: val_accuracy did not improve from 0.44000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 256ms/step - accuracy: 0.9954 - loss: 0.0218 - val_accuracy: 0.4400 - val_loss: 2.7552 - learning_rate: 0.0010\n",
            "Epoch 21/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9942 - loss: 0.0362\n",
            "Epoch 21: val_accuracy improved from 0.44000 to 0.46000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.9941 - loss: 0.0362 - val_accuracy: 0.4600 - val_loss: 2.8051 - learning_rate: 0.0010\n",
            "Epoch 22/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.9954 - loss: 0.0176\n",
            "Epoch 22: val_accuracy improved from 0.46000 to 0.48000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.9954 - loss: 0.0175 - val_accuracy: 0.4800 - val_loss: 2.2898 - learning_rate: 0.0010\n",
            "Epoch 23/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.9923 - loss: 0.0319\n",
            "Epoch 23: val_accuracy improved from 0.48000 to 0.50500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9924 - loss: 0.0316 - val_accuracy: 0.5050 - val_loss: 2.2131 - learning_rate: 0.0010\n",
            "Epoch 24/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9979 - loss: 0.0133\n",
            "Epoch 24: val_accuracy did not improve from 0.50500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 280ms/step - accuracy: 0.9978 - loss: 0.0137 - val_accuracy: 0.4650 - val_loss: 2.4080 - learning_rate: 0.0010\n",
            "Epoch 25/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9987 - loss: 0.0098\n",
            "Epoch 25: val_accuracy improved from 0.50500 to 0.53000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 885ms/step - accuracy: 0.9986 - loss: 0.0099 - val_accuracy: 0.5300 - val_loss: 1.9838 - learning_rate: 0.0010\n",
            "Epoch 26/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9849 - loss: 0.0362\n",
            "Epoch 26: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 251ms/step - accuracy: 0.9849 - loss: 0.0363 - val_accuracy: 0.5050 - val_loss: 2.2240 - learning_rate: 0.0010\n",
            "Epoch 27/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9892 - loss: 0.0288\n",
            "Epoch 27: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 248ms/step - accuracy: 0.9890 - loss: 0.0293 - val_accuracy: 0.4300 - val_loss: 3.1220 - learning_rate: 0.0010\n",
            "Epoch 28/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9859 - loss: 0.0540\n",
            "Epoch 28: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 269ms/step - accuracy: 0.9859 - loss: 0.0542 - val_accuracy: 0.4600 - val_loss: 2.7486 - learning_rate: 0.0010\n",
            "Epoch 29/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9844 - loss: 0.0526\n",
            "Epoch 29: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 0.9845 - loss: 0.0521 - val_accuracy: 0.5050 - val_loss: 2.3684 - learning_rate: 0.0010\n",
            "Epoch 30/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9940 - loss: 0.0308\n",
            "Epoch 30: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 259ms/step - accuracy: 0.9940 - loss: 0.0306 - val_accuracy: 0.5150 - val_loss: 3.3158 - learning_rate: 0.0010\n",
            "Epoch 31/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9936 - loss: 0.0220\n",
            "Epoch 31: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 233ms/step - accuracy: 0.9936 - loss: 0.0222 - val_accuracy: 0.4500 - val_loss: 3.4761 - learning_rate: 0.0010\n",
            "Epoch 32/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9939 - loss: 0.0342\n",
            "Epoch 32: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.9938 - loss: 0.0344 - val_accuracy: 0.4750 - val_loss: 2.8692 - learning_rate: 0.0010\n",
            "Epoch 33/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9864 - loss: 0.0304\n",
            "Epoch 33: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 349ms/step - accuracy: 0.9865 - loss: 0.0303 - val_accuracy: 0.3300 - val_loss: 3.9491 - learning_rate: 0.0010\n",
            "Epoch 34/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.9847 - loss: 0.0246\n",
            "Epoch 34: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 461ms/step - accuracy: 0.9850 - loss: 0.0246 - val_accuracy: 0.4800 - val_loss: 2.4998 - learning_rate: 0.0010\n",
            "Epoch 35/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9897 - loss: 0.0245\n",
            "Epoch 35: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 310ms/step - accuracy: 0.9896 - loss: 0.0249 - val_accuracy: 0.5200 - val_loss: 2.3350 - learning_rate: 0.0010\n",
            "Epoch 36/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9900 - loss: 0.0281\n",
            "Epoch 36: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 306ms/step - accuracy: 0.9900 - loss: 0.0281 - val_accuracy: 0.5150 - val_loss: 2.0733 - learning_rate: 0.0010\n",
            "Epoch 37/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.9977 - loss: 0.0155\n",
            "Epoch 37: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 387ms/step - accuracy: 0.9977 - loss: 0.0156 - val_accuracy: 0.4700 - val_loss: 2.6337 - learning_rate: 0.0010\n",
            "Epoch 38/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9980 - loss: 0.0082\n",
            "Epoch 38: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 254ms/step - accuracy: 0.9979 - loss: 0.0084 - val_accuracy: 0.4750 - val_loss: 2.6787 - learning_rate: 0.0010\n",
            "Epoch 39/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 1.0000 - loss: 0.0083\n",
            "Epoch 39: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.4700 - val_loss: 2.5009 - learning_rate: 0.0010\n",
            "Epoch 40/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.9994 - loss: 0.0037\n",
            "Epoch 40: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 420ms/step - accuracy: 0.9993 - loss: 0.0039 - val_accuracy: 0.5000 - val_loss: 2.2494 - learning_rate: 0.0010\n",
            "Epoch 41/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9979 - loss: 0.0074\n",
            "Epoch 41: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 269ms/step - accuracy: 0.9978 - loss: 0.0074 - val_accuracy: 0.5100 - val_loss: 2.1502 - learning_rate: 0.0010\n",
            "Epoch 42/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9966 - loss: 0.0249\n",
            "Epoch 42: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.9966 - loss: 0.0246 - val_accuracy: 0.4950 - val_loss: 2.1617 - learning_rate: 0.0010\n",
            "Epoch 43/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9999 - loss: 0.0045\n",
            "Epoch 43: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - accuracy: 0.9999 - loss: 0.0048 - val_accuracy: 0.5150 - val_loss: 2.1992 - learning_rate: 0.0010\n",
            "Epoch 44/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9964 - loss: 0.0242\n",
            "Epoch 44: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.9964 - loss: 0.0239 - val_accuracy: 0.4850 - val_loss: 2.4549 - learning_rate: 0.0010\n",
            "Epoch 45/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9990 - loss: 0.0033\n",
            "Epoch 45: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.5000 - val_loss: 2.2113 - learning_rate: 0.0010\n",
            "Epoch 46/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9978 - loss: 0.0056\n",
            "Epoch 46: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - accuracy: 0.9979 - loss: 0.0055 - val_accuracy: 0.5050 - val_loss: 2.2282 - learning_rate: 0.0010\n",
            "Epoch 47/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9939 - loss: 0.0128\n",
            "Epoch 47: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 258ms/step - accuracy: 0.9940 - loss: 0.0125 - val_accuracy: 0.5100 - val_loss: 2.1481 - learning_rate: 0.0010\n",
            "Epoch 48/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9970 - loss: 0.0066\n",
            "Epoch 48: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 308ms/step - accuracy: 0.9971 - loss: 0.0066 - val_accuracy: 0.5100 - val_loss: 2.1557 - learning_rate: 0.0010\n",
            "Epoch 49/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9965 - loss: 0.0127\n",
            "Epoch 49: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.9966 - loss: 0.0125 - val_accuracy: 0.5200 - val_loss: 2.2307 - learning_rate: 0.0010\n",
            "Epoch 50/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9978 - loss: 0.0056\n",
            "Epoch 50: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - accuracy: 0.9979 - loss: 0.0055 - val_accuracy: 0.5150 - val_loss: 2.2370 - learning_rate: 0.0010\n",
            "Epoch 51/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9971 - loss: 0.0063\n",
            "Epoch 51: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 233ms/step - accuracy: 0.9972 - loss: 0.0062 - val_accuracy: 0.5100 - val_loss: 2.1321 - learning_rate: 0.0010\n",
            "Epoch 52/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9997 - loss: 0.0036\n",
            "Epoch 52: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - accuracy: 0.9997 - loss: 0.0038 - val_accuracy: 0.4850 - val_loss: 2.4325 - learning_rate: 0.0010\n",
            "Epoch 53/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9952 - loss: 0.0077\n",
            "Epoch 53: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 242ms/step - accuracy: 0.9954 - loss: 0.0076 - val_accuracy: 0.4150 - val_loss: 3.4379 - learning_rate: 0.0010\n",
            "Epoch 54/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9973 - loss: 0.0081\n",
            "Epoch 54: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 249ms/step - accuracy: 0.9973 - loss: 0.0081 - val_accuracy: 0.5300 - val_loss: 2.3299 - learning_rate: 0.0010\n",
            "Epoch 55/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9971 - loss: 0.0070\n",
            "Epoch 55: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.9972 - loss: 0.0069 - val_accuracy: 0.5250 - val_loss: 2.2025 - learning_rate: 0.0010\n",
            "Epoch 56/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9996 - loss: 0.0038\n",
            "Epoch 56: val_accuracy improved from 0.53000 to 0.54000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9996 - loss: 0.0041 - val_accuracy: 0.5400 - val_loss: 2.2157 - learning_rate: 0.0010\n",
            "Epoch 57/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9935 - loss: 0.0092\n",
            "Epoch 57: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - accuracy: 0.9937 - loss: 0.0090 - val_accuracy: 0.5400 - val_loss: 2.1690 - learning_rate: 0.0010\n",
            "Epoch 58/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 1.0000 - loss: 0.0037\n",
            "Epoch 58: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.5400 - val_loss: 2.2228 - learning_rate: 0.0010\n",
            "Epoch 59/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9971 - loss: 0.0060\n",
            "Epoch 59: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 0.9972 - loss: 0.0059 - val_accuracy: 0.5350 - val_loss: 2.1980 - learning_rate: 0.0010\n",
            "Epoch 60/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 60: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5400 - val_loss: 2.2144 - learning_rate: 0.0010\n",
            "Epoch 61/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9956 - loss: 0.0077\n",
            "Epoch 61: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.9956 - loss: 0.0076 - val_accuracy: 0.5200 - val_loss: 2.3612 - learning_rate: 0.0010\n",
            "Epoch 62/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9999 - loss: 0.0022\n",
            "Epoch 62: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - accuracy: 0.9999 - loss: 0.0023 - val_accuracy: 0.5100 - val_loss: 2.2566 - learning_rate: 0.0010\n",
            "Epoch 63/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9978 - loss: 0.0052\n",
            "Epoch 63: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 231ms/step - accuracy: 0.9979 - loss: 0.0052 - val_accuracy: 0.5000 - val_loss: 2.5371 - learning_rate: 0.0010\n",
            "Epoch 64/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9952 - loss: 0.0308\n",
            "Epoch 64: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9954 - loss: 0.0299 - val_accuracy: 0.4850 - val_loss: 2.5827 - learning_rate: 0.0010\n",
            "Epoch 65/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9941 - loss: 0.0112\n",
            "Epoch 65: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.9940 - loss: 0.0113 - val_accuracy: 0.4750 - val_loss: 2.7859 - learning_rate: 0.0010\n",
            "Epoch 66/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9904 - loss: 0.0191\n",
            "Epoch 66: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.9904 - loss: 0.0191 - val_accuracy: 0.5200 - val_loss: 2.5374 - learning_rate: 0.0010\n",
            "Epoch 67/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9796 - loss: 0.0561\n",
            "Epoch 67: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 241ms/step - accuracy: 0.9796 - loss: 0.0561 - val_accuracy: 0.1200 - val_loss: 18.0971 - learning_rate: 0.0010\n",
            "Epoch 68/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9807 - loss: 0.0696\n",
            "Epoch 68: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 256ms/step - accuracy: 0.9806 - loss: 0.0698 - val_accuracy: 0.4150 - val_loss: 3.7119 - learning_rate: 0.0010\n",
            "Epoch 69/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9715 - loss: 0.0879\n",
            "Epoch 69: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.9715 - loss: 0.0878 - val_accuracy: 0.2800 - val_loss: 9.3345 - learning_rate: 0.0010\n",
            "Epoch 70/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9462 - loss: 0.1580\n",
            "Epoch 70: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 298ms/step - accuracy: 0.9465 - loss: 0.1577 - val_accuracy: 0.3800 - val_loss: 5.3590 - learning_rate: 0.0010\n",
            "Epoch 71/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9514 - loss: 0.1297\n",
            "Epoch 71: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - accuracy: 0.9516 - loss: 0.1296 - val_accuracy: 0.3400 - val_loss: 6.5448 - learning_rate: 0.0010\n",
            "Epoch 72/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9360 - loss: 0.1719\n",
            "Epoch 72: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 298ms/step - accuracy: 0.9365 - loss: 0.1708 - val_accuracy: 0.3400 - val_loss: 6.9532 - learning_rate: 0.0010\n",
            "Epoch 73/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9731 - loss: 0.1093\n",
            "Epoch 73: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 256ms/step - accuracy: 0.9731 - loss: 0.1090 - val_accuracy: 0.4250 - val_loss: 4.8019 - learning_rate: 0.0010\n",
            "Epoch 74/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9833 - loss: 0.0504\n",
            "Epoch 74: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9834 - loss: 0.0500 - val_accuracy: 0.4450 - val_loss: 3.3038 - learning_rate: 0.0010\n",
            "Epoch 75/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9884 - loss: 0.0367\n",
            "Epoch 75: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 264ms/step - accuracy: 0.9885 - loss: 0.0368 - val_accuracy: 0.5100 - val_loss: 3.2809 - learning_rate: 0.0010\n",
            "Epoch 76/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9870 - loss: 0.0316\n",
            "Epoch 76: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 285ms/step - accuracy: 0.9870 - loss: 0.0316 - val_accuracy: 0.5050 - val_loss: 2.9727 - learning_rate: 0.0010\n",
            "Epoch 77/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9952 - loss: 0.0124\n",
            "Epoch 77: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - accuracy: 0.9950 - loss: 0.0128 - val_accuracy: 0.5150 - val_loss: 2.3546 - learning_rate: 0.0010\n",
            "Epoch 78/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9865 - loss: 0.0385\n",
            "Epoch 78: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 291ms/step - accuracy: 0.9867 - loss: 0.0381 - val_accuracy: 0.5400 - val_loss: 2.3366 - learning_rate: 0.0010\n",
            "Epoch 79/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9947 - loss: 0.0219\n",
            "Epoch 79: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.9948 - loss: 0.0217 - val_accuracy: 0.5150 - val_loss: 2.3685 - learning_rate: 0.0010\n",
            "Epoch 80/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9942 - loss: 0.0348\n",
            "Epoch 80: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step - accuracy: 0.9944 - loss: 0.0340 - val_accuracy: 0.5150 - val_loss: 2.3019 - learning_rate: 0.0010\n",
            "Epoch 81/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9978 - loss: 0.0072\n",
            "Epoch 81: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 248ms/step - accuracy: 0.9979 - loss: 0.0071 - val_accuracy: 0.5400 - val_loss: 2.2296 - learning_rate: 0.0010\n",
            "Epoch 82/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9979 - loss: 0.0051\n",
            "Epoch 82: val_accuracy improved from 0.54000 to 0.56500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.9979 - loss: 0.0051 - val_accuracy: 0.5650 - val_loss: 2.1313 - learning_rate: 0.0010\n",
            "Epoch 83/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9952 - loss: 0.0082\n",
            "Epoch 83: val_accuracy improved from 0.56500 to 0.57000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.9954 - loss: 0.0081 - val_accuracy: 0.5700 - val_loss: 2.1063 - learning_rate: 0.0010\n",
            "Epoch 84/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.9912 - loss: 0.0192\n",
            "Epoch 84: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 397ms/step - accuracy: 0.9913 - loss: 0.0191 - val_accuracy: 0.5050 - val_loss: 2.9720 - learning_rate: 0.0010\n",
            "Epoch 85/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.9951 - loss: 0.0135\n",
            "Epoch 85: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 306ms/step - accuracy: 0.9951 - loss: 0.0136 - val_accuracy: 0.4950 - val_loss: 2.7218 - learning_rate: 0.0010\n",
            "Epoch 86/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9991 - loss: 0.0066\n",
            "Epoch 86: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 0.9991 - loss: 0.0066 - val_accuracy: 0.5400 - val_loss: 2.6573 - learning_rate: 0.0010\n",
            "Epoch 87/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9945 - loss: 0.0090\n",
            "Epoch 87: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - accuracy: 0.9946 - loss: 0.0088 - val_accuracy: 0.5400 - val_loss: 2.4893 - learning_rate: 0.0010\n",
            "Epoch 88/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9985 - loss: 0.0033\n",
            "Epoch 88: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - accuracy: 0.9985 - loss: 0.0033 - val_accuracy: 0.5400 - val_loss: 2.3744 - learning_rate: 0.0010\n",
            "Epoch 89/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9994 - loss: 0.0035\n",
            "Epoch 89: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.9994 - loss: 0.0036 - val_accuracy: 0.5550 - val_loss: 2.3183 - learning_rate: 0.0010\n",
            "Epoch 90/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9966 - loss: 0.0091\n",
            "Epoch 90: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9966 - loss: 0.0090 - val_accuracy: 0.5350 - val_loss: 2.2812 - learning_rate: 0.0010\n",
            "Epoch 91/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9960 - loss: 0.0136\n",
            "Epoch 91: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - accuracy: 0.9961 - loss: 0.0134 - val_accuracy: 0.5250 - val_loss: 2.3163 - learning_rate: 0.0010\n",
            "Epoch 92/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9975 - loss: 0.0048\n",
            "Epoch 92: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 291ms/step - accuracy: 0.9975 - loss: 0.0048 - val_accuracy: 0.5500 - val_loss: 2.2855 - learning_rate: 0.0010\n",
            "Epoch 93/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9917 - loss: 0.0108\n",
            "Epoch 93: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 211ms/step - accuracy: 0.9919 - loss: 0.0105 - val_accuracy: 0.5350 - val_loss: 2.3329 - learning_rate: 0.0010\n",
            "Epoch 94/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9928 - loss: 0.0116\n",
            "Epoch 94: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 229ms/step - accuracy: 0.9929 - loss: 0.0113 - val_accuracy: 0.5550 - val_loss: 2.3932 - learning_rate: 0.0010\n",
            "Epoch 95/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9988 - loss: 0.0057\n",
            "Epoch 95: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9988 - loss: 0.0059 - val_accuracy: 0.5550 - val_loss: 2.3945 - learning_rate: 0.0010\n",
            "Epoch 96/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9986 - loss: 0.0042\n",
            "Epoch 96: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.5350 - val_loss: 2.3126 - learning_rate: 0.0010\n",
            "Epoch 97/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9952 - loss: 0.0104\n",
            "Epoch 97: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 267ms/step - accuracy: 0.9954 - loss: 0.0101 - val_accuracy: 0.5300 - val_loss: 2.2947 - learning_rate: 0.0010\n",
            "Epoch 98/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9952 - loss: 0.0074\n",
            "Epoch 98: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.9953 - loss: 0.0073 - val_accuracy: 0.5400 - val_loss: 2.2773 - learning_rate: 0.0010\n",
            "Epoch 99/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9997 - loss: 0.0024\n",
            "Epoch 99: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 261ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.5650 - val_loss: 2.3385 - learning_rate: 0.0010\n",
            "Epoch 100/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9974 - loss: 0.0041\n",
            "Epoch 100: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.9974 - loss: 0.0041 - val_accuracy: 0.5600 - val_loss: 2.2960 - learning_rate: 0.0010\n",
            "Epoch 101/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9998 - loss: 0.0012\n",
            "Epoch 101: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.5700 - val_loss: 2.3240 - learning_rate: 0.0010\n",
            "Epoch 102/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 102: val_accuracy improved from 0.57000 to 0.57500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mel.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.5750 - val_loss: 2.4262 - learning_rate: 0.0010\n",
            "Epoch 103/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9983 - loss: 0.0079\n",
            "Epoch 103: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 236ms/step - accuracy: 0.9983 - loss: 0.0078 - val_accuracy: 0.5350 - val_loss: 2.4624 - learning_rate: 0.0010\n",
            "Epoch 104/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9965 - loss: 0.0038\n",
            "Epoch 104: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - accuracy: 0.9966 - loss: 0.0037 - val_accuracy: 0.5300 - val_loss: 2.4749 - learning_rate: 0.0010\n",
            "Epoch 105/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9981 - loss: 0.0047\n",
            "Epoch 105: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 248ms/step - accuracy: 0.9981 - loss: 0.0047 - val_accuracy: 0.5300 - val_loss: 2.4825 - learning_rate: 0.0010\n",
            "Epoch 106/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "Epoch 106: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 240ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.5400 - val_loss: 2.3351 - learning_rate: 0.0010\n",
            "Epoch 107/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.9997 - loss: 0.0016\n",
            "Epoch 107: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 258ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.5500 - val_loss: 2.2623 - learning_rate: 0.0010\n",
            "Epoch 108/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9954 - loss: 0.0053\n",
            "Epoch 108: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 269ms/step - accuracy: 0.9954 - loss: 0.0052 - val_accuracy: 0.5350 - val_loss: 2.2589 - learning_rate: 0.0010\n",
            "Epoch 109/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 109: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.5350 - val_loss: 2.2810 - learning_rate: 0.0010\n",
            "Epoch 110/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9983 - loss: 0.0033\n",
            "Epoch 110: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 267ms/step - accuracy: 0.9983 - loss: 0.0033 - val_accuracy: 0.5400 - val_loss: 2.2824 - learning_rate: 0.0010\n",
            "Epoch 111/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9952 - loss: 0.0148\n",
            "Epoch 111: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9954 - loss: 0.0144 - val_accuracy: 0.5300 - val_loss: 2.2985 - learning_rate: 0.0010\n",
            "Epoch 112/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9978 - loss: 0.0064\n",
            "Epoch 112: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.5450 - val_loss: 2.2488 - learning_rate: 0.0010\n",
            "Epoch 113/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9991 - loss: 0.0020\n",
            "Epoch 113: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 245ms/step - accuracy: 0.9991 - loss: 0.0021 - val_accuracy: 0.5400 - val_loss: 2.2699 - learning_rate: 0.0010\n",
            "Epoch 114/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9952 - loss: 0.0081\n",
            "Epoch 114: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 231ms/step - accuracy: 0.9954 - loss: 0.0079 - val_accuracy: 0.5500 - val_loss: 2.2762 - learning_rate: 0.0010\n",
            "Epoch 115/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9971 - loss: 0.0102\n",
            "Epoch 115: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - accuracy: 0.9972 - loss: 0.0100 - val_accuracy: 0.5600 - val_loss: 2.3718 - learning_rate: 0.0010\n",
            "Epoch 116/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9985 - loss: 0.0075\n",
            "Epoch 116: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 240ms/step - accuracy: 0.9985 - loss: 0.0074 - val_accuracy: 0.5600 - val_loss: 2.3755 - learning_rate: 0.0010\n",
            "Epoch 117/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.9971 - loss: 0.0046\n",
            "Epoch 117: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 248ms/step - accuracy: 0.9972 - loss: 0.0045 - val_accuracy: 0.5600 - val_loss: 2.3042 - learning_rate: 0.0010\n",
            "Epoch 118/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9946 - loss: 0.0065\n",
            "Epoch 118: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 256ms/step - accuracy: 0.9947 - loss: 0.0064 - val_accuracy: 0.5650 - val_loss: 2.2860 - learning_rate: 0.0010\n",
            "Epoch 119/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9966 - loss: 0.0051\n",
            "Epoch 119: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.9966 - loss: 0.0050 - val_accuracy: 0.5550 - val_loss: 2.2426 - learning_rate: 0.0010\n",
            "Epoch 120/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9991 - loss: 9.9380e-04\n",
            "Epoch 120: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.9990 - loss: 0.0011 - val_accuracy: 0.5650 - val_loss: 2.2626 - learning_rate: 0.0010\n",
            "Epoch 121/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9983 - loss: 0.0040\n",
            "Epoch 121: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.9983 - loss: 0.0039 - val_accuracy: 0.5650 - val_loss: 2.2882 - learning_rate: 0.0010\n",
            "Epoch 122/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9999 - loss: 5.8021e-04\n",
            "Epoch 122: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9999 - loss: 7.0312e-04 - val_accuracy: 0.5600 - val_loss: 2.3205 - learning_rate: 0.0010\n",
            "Epoch 123/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9987 - loss: 0.0019\n",
            "Epoch 123: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 257ms/step - accuracy: 0.9986 - loss: 0.0019 - val_accuracy: 0.4900 - val_loss: 2.8691 - learning_rate: 0.0010\n",
            "Epoch 124/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9940 - loss: 0.0212\n",
            "Epoch 124: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - accuracy: 0.9941 - loss: 0.0207 - val_accuracy: 0.4300 - val_loss: 3.2108 - learning_rate: 0.0010\n",
            "Epoch 125/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9920 - loss: 0.0235\n",
            "Epoch 125: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 232ms/step - accuracy: 0.9920 - loss: 0.0238 - val_accuracy: 0.4750 - val_loss: 3.5394 - learning_rate: 0.0010\n",
            "Epoch 126/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9911 - loss: 0.0156\n",
            "Epoch 126: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 268ms/step - accuracy: 0.9912 - loss: 0.0156 - val_accuracy: 0.4350 - val_loss: 3.0698 - learning_rate: 0.0010\n",
            "Epoch 127/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9957 - loss: 0.0131\n",
            "Epoch 127: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.9956 - loss: 0.0134 - val_accuracy: 0.4350 - val_loss: 4.6929 - learning_rate: 0.0010\n",
            "Epoch 128/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9958 - loss: 0.0212\n",
            "Epoch 128: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 292ms/step - accuracy: 0.9956 - loss: 0.0215 - val_accuracy: 0.3650 - val_loss: 4.7806 - learning_rate: 0.0010\n",
            "Epoch 129/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9744 - loss: 0.0611\n",
            "Epoch 129: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 233ms/step - accuracy: 0.9742 - loss: 0.0623 - val_accuracy: 0.3400 - val_loss: 13.6185 - learning_rate: 0.0010\n",
            "Epoch 130/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.9678 - loss: 0.0974\n",
            "Epoch 130: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9676 - loss: 0.0974 - val_accuracy: 0.3700 - val_loss: 5.6612 - learning_rate: 0.0010\n",
            "Epoch 131/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9693 - loss: 0.0928\n",
            "Epoch 131: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 233ms/step - accuracy: 0.9692 - loss: 0.0930 - val_accuracy: 0.3500 - val_loss: 6.8238 - learning_rate: 0.0010\n",
            "Epoch 132/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9802 - loss: 0.0514\n",
            "Epoch 132: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.9800 - loss: 0.0519 - val_accuracy: 0.4300 - val_loss: 5.0217 - learning_rate: 0.0010\n",
            "Epoch 133/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9875 - loss: 0.0408\n",
            "Epoch 133: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.9873 - loss: 0.0410 - val_accuracy: 0.4950 - val_loss: 3.1115 - learning_rate: 0.0010\n",
            "Epoch 134/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9913 - loss: 0.0470\n",
            "Epoch 134: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - accuracy: 0.9912 - loss: 0.0474 - val_accuracy: 0.5000 - val_loss: 3.1498 - learning_rate: 0.0010\n",
            "Epoch 135/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9958 - loss: 0.0248\n",
            "Epoch 135: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.9958 - loss: 0.0248 - val_accuracy: 0.4950 - val_loss: 2.9602 - learning_rate: 0.0010\n",
            "Epoch 136/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9898 - loss: 0.0472\n",
            "Epoch 136: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 319ms/step - accuracy: 0.9899 - loss: 0.0467 - val_accuracy: 0.5350 - val_loss: 2.7978 - learning_rate: 0.0010\n",
            "Epoch 137/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9987 - loss: 0.0127\n",
            "Epoch 137: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 321ms/step - accuracy: 0.9987 - loss: 0.0126 - val_accuracy: 0.4950 - val_loss: 2.7954 - learning_rate: 0.0010\n",
            "Epoch 138/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9959 - loss: 0.0087\n",
            "Epoch 138: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - accuracy: 0.9958 - loss: 0.0089 - val_accuracy: 0.5250 - val_loss: 2.9416 - learning_rate: 0.0010\n",
            "Epoch 139/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9900 - loss: 0.0283\n",
            "Epoch 139: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step - accuracy: 0.9900 - loss: 0.0284 - val_accuracy: 0.5250 - val_loss: 2.8714 - learning_rate: 0.0010\n",
            "Epoch 140/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9953 - loss: 0.0156\n",
            "Epoch 140: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 0.9952 - loss: 0.0157 - val_accuracy: 0.4850 - val_loss: 3.9787 - learning_rate: 0.0010\n",
            "Epoch 141/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9925 - loss: 0.0242\n",
            "Epoch 141: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9927 - loss: 0.0239 - val_accuracy: 0.3950 - val_loss: 4.8323 - learning_rate: 0.0010\n",
            "Epoch 142/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9908 - loss: 0.0286\n",
            "Epoch 142: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.9909 - loss: 0.0282 - val_accuracy: 0.4500 - val_loss: 3.5351 - learning_rate: 0.0010\n",
            "Epoch 143/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.9809 - loss: 0.0420\n",
            "Epoch 143: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - accuracy: 0.9812 - loss: 0.0414 - val_accuracy: 0.4050 - val_loss: 4.2201 - learning_rate: 0.0010\n",
            "Epoch 144/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9945 - loss: 0.0158\n",
            "Epoch 144: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 0.9944 - loss: 0.0161 - val_accuracy: 0.4150 - val_loss: 3.9840 - learning_rate: 0.0010\n",
            "Epoch 145/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9934 - loss: 0.0278\n",
            "Epoch 145: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 236ms/step - accuracy: 0.9933 - loss: 0.0276 - val_accuracy: 0.4100 - val_loss: 4.1715 - learning_rate: 0.0010\n",
            "Epoch 146/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9976 - loss: 0.0093\n",
            "Epoch 146: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - accuracy: 0.9975 - loss: 0.0094 - val_accuracy: 0.4750 - val_loss: 3.1885 - learning_rate: 0.0010\n",
            "Epoch 147/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9848 - loss: 0.0543\n",
            "Epoch 147: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - accuracy: 0.9849 - loss: 0.0538 - val_accuracy: 0.4950 - val_loss: 3.5814 - learning_rate: 0.0010\n",
            "Epoch 148/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9858 - loss: 0.0353\n",
            "Epoch 148: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9858 - loss: 0.0354 - val_accuracy: 0.4750 - val_loss: 3.1561 - learning_rate: 0.0010\n",
            "Epoch 149/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9861 - loss: 0.0283\n",
            "Epoch 149: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 255ms/step - accuracy: 0.9862 - loss: 0.0281 - val_accuracy: 0.4450 - val_loss: 3.7140 - learning_rate: 0.0010\n",
            "Epoch 150/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9971 - loss: 0.0117\n",
            "Epoch 150: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - accuracy: 0.9971 - loss: 0.0117 - val_accuracy: 0.5300 - val_loss: 2.8442 - learning_rate: 0.0010\n",
            "Epoch 151/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9887 - loss: 0.0179\n",
            "Epoch 151: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 322ms/step - accuracy: 0.9889 - loss: 0.0179 - val_accuracy: 0.5100 - val_loss: 2.8242 - learning_rate: 0.0010\n",
            "Epoch 152/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9961 - loss: 0.0111\n",
            "Epoch 152: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.9961 - loss: 0.0112 - val_accuracy: 0.5400 - val_loss: 2.3878 - learning_rate: 0.0010\n",
            "Epoch 153/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9921 - loss: 0.0164\n",
            "Epoch 153: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 296ms/step - accuracy: 0.9922 - loss: 0.0163 - val_accuracy: 0.5350 - val_loss: 2.5478 - learning_rate: 0.0010\n",
            "Epoch 154/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9980 - loss: 0.0085\n",
            "Epoch 154: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 231ms/step - accuracy: 0.9980 - loss: 0.0087 - val_accuracy: 0.5650 - val_loss: 2.4755 - learning_rate: 0.0010\n",
            "Epoch 155/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.9940 - loss: 0.0095\n",
            "Epoch 155: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 345ms/step - accuracy: 0.9940 - loss: 0.0095 - val_accuracy: 0.5300 - val_loss: 2.5736 - learning_rate: 0.0010\n",
            "Epoch 156/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9974 - loss: 0.0065\n",
            "Epoch 156: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 265ms/step - accuracy: 0.9974 - loss: 0.0064 - val_accuracy: 0.5100 - val_loss: 2.8402 - learning_rate: 0.0010\n",
            "Epoch 157/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9989 - loss: 0.0051\n",
            "Epoch 157: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.9989 - loss: 0.0052 - val_accuracy: 0.5200 - val_loss: 2.5207 - learning_rate: 0.0010\n",
            "Epoch 158/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9999 - loss: 0.0046\n",
            "Epoch 158: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 261ms/step - accuracy: 0.9999 - loss: 0.0045 - val_accuracy: 0.4900 - val_loss: 2.7131 - learning_rate: 0.0010\n",
            "Epoch 159/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9991 - loss: 0.0042\n",
            "Epoch 159: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 0.5350 - val_loss: 2.4217 - learning_rate: 0.0010\n",
            "Epoch 160/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9995 - loss: 0.0051\n",
            "Epoch 160: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 295ms/step - accuracy: 0.9995 - loss: 0.0051 - val_accuracy: 0.5400 - val_loss: 2.4253 - learning_rate: 0.0010\n",
            "Epoch 161/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9983 - loss: 0.0055\n",
            "Epoch 161: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.5500 - val_loss: 2.3581 - learning_rate: 0.0010\n",
            "Epoch 162/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9943 - loss: 0.0099\n",
            "Epoch 162: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 236ms/step - accuracy: 0.9945 - loss: 0.0098 - val_accuracy: 0.5500 - val_loss: 2.3892 - learning_rate: 0.0010\n",
            "Epoch 163/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9978 - loss: 0.0051\n",
            "Epoch 163: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.9979 - loss: 0.0051 - val_accuracy: 0.5200 - val_loss: 2.4669 - learning_rate: 0.0010\n",
            "Epoch 164/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9986 - loss: 0.0022\n",
            "Epoch 164: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 290ms/step - accuracy: 0.9985 - loss: 0.0023 - val_accuracy: 0.5300 - val_loss: 2.4558 - learning_rate: 0.0010\n",
            "Epoch 165/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "Epoch 165: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.5600 - val_loss: 2.3539 - learning_rate: 0.0010\n",
            "Epoch 166/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9950 - loss: 0.0125\n",
            "Epoch 166: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 263ms/step - accuracy: 0.9951 - loss: 0.0123 - val_accuracy: 0.5350 - val_loss: 2.4112 - learning_rate: 0.0010\n",
            "Epoch 167/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.9949 - loss: 0.0078\n",
            "Epoch 167: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 252ms/step - accuracy: 0.9950 - loss: 0.0077 - val_accuracy: 0.5000 - val_loss: 2.5455 - learning_rate: 0.0010\n",
            "Epoch 168/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9979 - loss: 0.0059\n",
            "Epoch 168: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.5100 - val_loss: 2.5974 - learning_rate: 0.0010\n",
            "Epoch 169/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9992 - loss: 0.0046\n",
            "Epoch 169: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 279ms/step - accuracy: 0.9992 - loss: 0.0046 - val_accuracy: 0.5050 - val_loss: 2.6029 - learning_rate: 0.0010\n",
            "Epoch 170/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9940 - loss: 0.0121\n",
            "Epoch 170: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 233ms/step - accuracy: 0.9941 - loss: 0.0119 - val_accuracy: 0.5500 - val_loss: 2.4756 - learning_rate: 0.0010\n",
            "Epoch 171/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9952 - loss: 0.0109\n",
            "Epoch 171: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - accuracy: 0.9954 - loss: 0.0107 - val_accuracy: 0.5150 - val_loss: 2.5593 - learning_rate: 0.0010\n",
            "Epoch 172/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9961 - loss: 0.0065\n",
            "Epoch 172: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - accuracy: 0.9961 - loss: 0.0065 - val_accuracy: 0.4900 - val_loss: 2.4864 - learning_rate: 0.0010\n",
            "Epoch 173/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 0.9993 - loss: 0.0034\n",
            "Epoch 173: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 383ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.5350 - val_loss: 2.4608 - learning_rate: 0.0010\n",
            "Epoch 174/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9942 - loss: 0.0062\n",
            "Epoch 174: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.9944 - loss: 0.0061 - val_accuracy: 0.5250 - val_loss: 2.4965 - learning_rate: 0.0010\n",
            "Epoch 175/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9966 - loss: 0.0048\n",
            "Epoch 175: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 266ms/step - accuracy: 0.9966 - loss: 0.0047 - val_accuracy: 0.5400 - val_loss: 2.4606 - learning_rate: 0.0010\n",
            "Epoch 176/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9975 - loss: 0.0051\n",
            "Epoch 176: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 0.9976 - loss: 0.0050 - val_accuracy: 0.5400 - val_loss: 2.4099 - learning_rate: 0.0010\n",
            "Epoch 177/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9952 - loss: 0.0102\n",
            "Epoch 177: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9954 - loss: 0.0100 - val_accuracy: 0.5450 - val_loss: 2.3987 - learning_rate: 0.0010\n",
            "Epoch 178/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9988 - loss: 0.0037\n",
            "Epoch 178: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 0.5500 - val_loss: 2.3903 - learning_rate: 0.0010\n",
            "Epoch 179/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.9999 - loss: 4.6526e-04\n",
            "Epoch 179: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 275ms/step - accuracy: 0.9999 - loss: 5.5797e-04 - val_accuracy: 0.5500 - val_loss: 2.3923 - learning_rate: 0.0010\n",
            "Epoch 180/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9995 - loss: 0.0020\n",
            "Epoch 180: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.5450 - val_loss: 2.4338 - learning_rate: 0.0010\n",
            "Epoch 181/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9993 - loss: 0.0027\n",
            "Epoch 181: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 266ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.5500 - val_loss: 2.4646 - learning_rate: 0.0010\n",
            "Epoch 182/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9998 - loss: 0.0012\n",
            "Epoch 182: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.5650 - val_loss: 2.4438 - learning_rate: 0.0010\n",
            "Epoch 183/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9996 - loss: 0.0020\n",
            "Epoch 183: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.5300 - val_loss: 2.4588 - learning_rate: 0.0010\n",
            "Epoch 184/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9956 - loss: 0.0111\n",
            "Epoch 184: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 232ms/step - accuracy: 0.9957 - loss: 0.0109 - val_accuracy: 0.5150 - val_loss: 2.8022 - learning_rate: 0.0010\n",
            "Epoch 185/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9904 - loss: 0.0258\n",
            "Epoch 185: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.9905 - loss: 0.0256 - val_accuracy: 0.5150 - val_loss: 3.0417 - learning_rate: 0.0010\n",
            "Epoch 186/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9936 - loss: 0.0107\n",
            "Epoch 186: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - accuracy: 0.9937 - loss: 0.0106 - val_accuracy: 0.5400 - val_loss: 2.8643 - learning_rate: 0.0010\n",
            "Epoch 187/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9977 - loss: 0.0147\n",
            "Epoch 187: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 238ms/step - accuracy: 0.9977 - loss: 0.0147 - val_accuracy: 0.4550 - val_loss: 3.4639 - learning_rate: 0.0010\n",
            "Epoch 188/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9950 - loss: 0.0120\n",
            "Epoch 188: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step - accuracy: 0.9951 - loss: 0.0120 - val_accuracy: 0.5100 - val_loss: 3.0450 - learning_rate: 0.0010\n",
            "Epoch 189/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9937 - loss: 0.0235\n",
            "Epoch 189: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.9937 - loss: 0.0238 - val_accuracy: 0.4650 - val_loss: 3.3518 - learning_rate: 0.0010\n",
            "Epoch 190/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9953 - loss: 0.0128\n",
            "Epoch 190: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.9952 - loss: 0.0129 - val_accuracy: 0.4750 - val_loss: 3.1895 - learning_rate: 0.0010\n",
            "Epoch 191/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9917 - loss: 0.0149\n",
            "Epoch 191: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 248ms/step - accuracy: 0.9918 - loss: 0.0148 - val_accuracy: 0.4950 - val_loss: 2.7992 - learning_rate: 0.0010\n",
            "Epoch 192/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9942 - loss: 0.0115\n",
            "Epoch 192: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 287ms/step - accuracy: 0.9943 - loss: 0.0116 - val_accuracy: 0.4700 - val_loss: 3.1435 - learning_rate: 0.0010\n",
            "Epoch 193/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.9915 - loss: 0.0229\n",
            "Epoch 193: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 361ms/step - accuracy: 0.9915 - loss: 0.0227 - val_accuracy: 0.4000 - val_loss: 4.0765 - learning_rate: 0.0010\n",
            "Epoch 194/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9958 - loss: 0.0159\n",
            "Epoch 194: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 348ms/step - accuracy: 0.9958 - loss: 0.0163 - val_accuracy: 0.4700 - val_loss: 3.0092 - learning_rate: 0.0010\n",
            "Epoch 195/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.9959 - loss: 0.0192\n",
            "Epoch 195: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 337ms/step - accuracy: 0.9957 - loss: 0.0195 - val_accuracy: 0.5250 - val_loss: 2.7637 - learning_rate: 0.0010\n",
            "Epoch 196/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9885 - loss: 0.0247\n",
            "Epoch 196: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 265ms/step - accuracy: 0.9887 - loss: 0.0246 - val_accuracy: 0.4550 - val_loss: 3.5969 - learning_rate: 0.0010\n",
            "Epoch 197/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9917 - loss: 0.0259\n",
            "Epoch 197: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.9917 - loss: 0.0261 - val_accuracy: 0.4450 - val_loss: 4.0732 - learning_rate: 0.0010\n",
            "Epoch 198/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9878 - loss: 0.0253\n",
            "Epoch 198: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9879 - loss: 0.0252 - val_accuracy: 0.4650 - val_loss: 3.5096 - learning_rate: 0.0010\n",
            "Epoch 199/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9956 - loss: 0.0108\n",
            "Epoch 199: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 232ms/step - accuracy: 0.9956 - loss: 0.0108 - val_accuracy: 0.5050 - val_loss: 2.9867 - learning_rate: 0.0010\n",
            "Epoch 200/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9902 - loss: 0.0160\n",
            "Epoch 200: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.9904 - loss: 0.0158 - val_accuracy: 0.5000 - val_loss: 3.0089 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute '_name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-909b9e01422c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msave_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-916bc6c7c64b>\u001b[0m in \u001b[0;36msave_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{model._name}_history_original_mel.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mcontent_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute '_name'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio files length: original MFCC"
      ],
      "metadata": {
        "id": "O1W4ZVinFm05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/GoogleCollab/Data/GTZAN/spectrograms/Spectrograms_with_test_train_split/spectrograms_mfcc.zip' -d \"/content/spectrograms_mfcc\""
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b7e145-1202-4958-f83d-4c115eb61443",
        "id": "1liAyfwLFm1A"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/GoogleCollab/Data/GTZAN/spectrograms/Spectrograms_with_test_train_split/spectrograms_mfcc.zip\n",
            "   creating: /content/spectrograms_mfcc/test/\n",
            "   creating: /content/spectrograms_mfcc/test/blues/\n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00006.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00007.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00010.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00011.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00018.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00022.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00023.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00031.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00032.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00036.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00037.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00047.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00064.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00065.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00066.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00069.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00076.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00082.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00088.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/blues/blues.00091.png  \n",
            "   creating: /content/spectrograms_mfcc/test/classical/\n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00001.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00004.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00016.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00017.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00018.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00027.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00036.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00039.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00040.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00041.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00043.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00049.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00051.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00066.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00067.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00071.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00076.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00078.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00084.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/classical/classical.00097.png  \n",
            "   creating: /content/spectrograms_mfcc/test/country/\n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00000.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00002.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00006.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00013.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00023.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00025.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00031.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00035.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00038.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00044.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00048.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00049.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00065.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00067.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00076.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00077.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00078.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00082.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00086.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/country/country.00087.png  \n",
            "   creating: /content/spectrograms_mfcc/test/disco/\n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00000.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00001.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00009.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00012.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00015.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00023.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00028.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00031.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00035.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00037.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00039.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00046.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00052.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00068.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00070.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00075.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00081.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00085.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00086.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/disco/disco.00087.png  \n",
            "   creating: /content/spectrograms_mfcc/test/hiphop/\n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00002.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00004.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00012.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00013.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00014.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00015.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00028.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00029.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00031.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00035.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00047.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00052.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00058.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00067.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00074.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00075.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00077.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00079.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00084.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/hiphop/hiphop.00093.png  \n",
            "   creating: /content/spectrograms_mfcc/test/jazz/\n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00000.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00001.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00013.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00015.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00016.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00020.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00022.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00026.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00033.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00043.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00044.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00049.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00063.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00064.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00071.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00083.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00085.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00087.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00096.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/jazz/jazz.00098.png  \n",
            "   creating: /content/spectrograms_mfcc/test/metal/\n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00005.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00007.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00010.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00015.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00016.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00017.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00032.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00033.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00034.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00039.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00046.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00049.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00061.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00066.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00070.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00071.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00076.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00080.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00089.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/metal/metal.00091.png  \n",
            "   creating: /content/spectrograms_mfcc/test/pop/\n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00001.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00003.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00009.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00018.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00019.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00027.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00028.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00032.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00033.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00036.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00039.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00044.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00057.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00063.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00071.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00076.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00080.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00084.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00087.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/pop/pop.00093.png  \n",
            "   creating: /content/spectrograms_mfcc/test/reggae/\n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00002.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00004.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00015.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00016.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00022.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00025.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00028.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00035.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00039.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00042.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00045.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00047.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00051.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00069.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00071.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00073.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00075.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00080.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00084.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/reggae/reggae.00089.png  \n",
            "   creating: /content/spectrograms_mfcc/test/rock/\n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00001.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00005.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00011.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00012.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00015.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00023.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00024.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00029.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00030.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00037.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00041.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00046.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00057.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00065.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00069.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00074.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00079.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00086.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00087.png  \n",
            "  inflating: /content/spectrograms_mfcc/test/rock/rock.00090.png  \n",
            "   creating: /content/spectrograms_mfcc/train/\n",
            "   creating: /content/spectrograms_mfcc/train/blues/\n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00000.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00001.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00002.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00003.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00004.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00005.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00008.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00009.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00012.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00013.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00014.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00015.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00016.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00017.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00019.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00020.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00021.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00024.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00025.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00026.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00027.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00028.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00029.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00030.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00033.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00034.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00035.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00038.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00039.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00040.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00041.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00042.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00043.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00044.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00045.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00046.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00048.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00049.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00050.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00051.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00052.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00053.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00054.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00055.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00056.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00057.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00058.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00059.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00060.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00061.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00062.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00063.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00067.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00068.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00070.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00071.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00072.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00073.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00074.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00075.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00077.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00078.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00079.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00080.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00081.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00083.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00084.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00085.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00086.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00087.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00089.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00090.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00092.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00093.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00094.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00095.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00096.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00097.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00098.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/blues/blues.00099.png  \n",
            "   creating: /content/spectrograms_mfcc/train/classical/\n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00000.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00002.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00003.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00005.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00006.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00007.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00008.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00009.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00010.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00011.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00012.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00013.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00014.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00015.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00019.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00020.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00021.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00022.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00023.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00024.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00025.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00026.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00028.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00029.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00030.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00031.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00032.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00033.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00034.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00035.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00037.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00038.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00042.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00044.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00045.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00046.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00047.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00048.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00050.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00052.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00053.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00054.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00055.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00056.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00057.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00058.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00059.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00060.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00061.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00062.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00063.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00064.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00065.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00068.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00069.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00070.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00072.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00073.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00074.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00075.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00077.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00079.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00080.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00081.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00082.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00083.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00085.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00086.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00088.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00089.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00090.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00091.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00092.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00093.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00094.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00095.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00096.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00098.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/classical/classical.00099.png  \n",
            "   creating: /content/spectrograms_mfcc/train/country/\n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00001.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00003.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00004.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00005.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00007.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00008.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00009.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00010.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00011.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00012.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00014.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00015.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00016.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00017.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00018.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00019.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00020.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00021.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00022.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00024.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00026.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00027.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00028.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00029.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00030.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00032.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00033.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00034.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00036.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00037.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00039.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00040.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00041.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00042.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00043.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00045.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00046.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00047.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00050.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00051.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00052.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00053.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00054.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00055.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00056.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00057.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00058.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00059.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00060.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00061.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00062.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00063.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00064.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00066.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00068.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00069.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00070.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00071.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00072.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00073.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00074.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00075.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00079.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00080.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00081.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00083.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00084.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00085.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00088.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00089.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00090.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00091.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00092.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00093.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00094.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00095.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00096.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00097.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00098.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/country/country.00099.png  \n",
            "   creating: /content/spectrograms_mfcc/train/disco/\n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00002.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00003.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00004.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00005.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00006.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00007.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00008.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00010.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00011.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00013.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00014.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00016.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00017.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00018.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00019.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00020.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00021.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00022.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00024.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00025.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00026.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00027.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00029.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00030.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00032.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00033.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00034.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00036.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00038.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00040.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00041.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00042.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00043.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00044.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00045.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00047.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00048.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00049.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00050.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00051.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00053.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00054.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00055.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00056.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00057.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00058.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00059.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00060.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00061.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00062.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00063.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00064.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00065.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00066.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00067.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00069.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00071.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00072.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00073.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00074.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00076.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00077.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00078.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00079.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00080.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00082.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00083.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00084.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00088.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00089.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00090.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00091.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00092.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00093.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00094.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00095.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00096.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00097.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00098.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/disco/disco.00099.png  \n",
            "   creating: /content/spectrograms_mfcc/train/hiphop/\n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00000.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00001.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00003.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00005.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00006.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00007.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00008.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00009.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00010.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00011.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00016.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00017.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00018.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00019.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00020.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00021.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00022.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00023.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00024.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00025.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00026.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00027.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00030.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00032.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00033.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00034.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00036.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00037.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00038.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00039.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00040.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00041.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00042.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00043.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00044.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00045.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00046.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00048.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00049.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00050.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00051.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00053.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00054.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00055.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00056.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00057.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00059.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00060.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00061.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00062.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00063.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00064.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00065.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00066.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00068.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00069.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00070.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00071.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00072.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00073.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00076.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00078.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00080.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00081.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00082.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00083.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00085.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00086.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00087.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00088.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00089.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00090.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00091.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00092.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00094.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00095.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00096.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00097.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00098.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/hiphop/hiphop.00099.png  \n",
            "   creating: /content/spectrograms_mfcc/train/jazz/\n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00002.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00003.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00004.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00005.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00006.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00007.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00008.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00009.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00010.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00011.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00012.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00014.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00017.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00018.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00019.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00021.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00023.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00024.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00025.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00027.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00028.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00029.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00030.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00031.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00032.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00034.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00035.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00036.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00037.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00038.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00039.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00040.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00041.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00042.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00045.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00046.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00047.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00048.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00050.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00051.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00052.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00053.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00055.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00056.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00057.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00058.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00059.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00060.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00061.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00062.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00065.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00066.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00067.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00068.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00069.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00070.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00072.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00073.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00074.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00075.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00076.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00077.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00078.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00079.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00080.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00081.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00082.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00084.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00086.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00088.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00089.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00090.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00091.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00092.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00093.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00094.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00095.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00097.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/jazz/jazz.00099.png  \n",
            "   creating: /content/spectrograms_mfcc/train/metal/\n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00000.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00001.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00002.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00003.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00004.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00006.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00008.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00009.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00011.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00012.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00013.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00014.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00018.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00019.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00020.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00021.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00022.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00023.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00024.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00025.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00026.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00027.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00028.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00029.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00030.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00031.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00035.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00036.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00037.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00038.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00040.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00041.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00042.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00043.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00044.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00045.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00047.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00048.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00050.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00051.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00052.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00053.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00054.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00055.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00056.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00057.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00058.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00059.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00060.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00062.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00063.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00064.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00065.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00067.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00068.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00069.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00072.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00073.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00074.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00075.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00077.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00078.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00079.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00081.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00082.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00083.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00084.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00085.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00086.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00087.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00088.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00090.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00092.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00093.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00094.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00095.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00096.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00097.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00098.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/metal/metal.00099.png  \n",
            "   creating: /content/spectrograms_mfcc/train/pop/\n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00000.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00002.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00004.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00005.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00006.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00007.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00008.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00010.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00011.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00012.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00013.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00014.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00015.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00016.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00017.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00020.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00021.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00022.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00023.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00024.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00025.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00026.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00029.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00030.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00031.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00034.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00035.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00037.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00038.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00040.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00041.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00042.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00043.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00045.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00046.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00047.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00048.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00049.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00050.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00051.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00052.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00053.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00054.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00055.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00056.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00058.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00059.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00060.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00061.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00062.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00064.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00065.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00066.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00067.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00068.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00069.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00070.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00072.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00073.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00074.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00075.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00077.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00078.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00079.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00081.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00082.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00083.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00085.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00086.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00088.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00089.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00090.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00091.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00092.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00094.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00095.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00096.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00097.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00098.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/pop/pop.00099.png  \n",
            "   creating: /content/spectrograms_mfcc/train/reggae/\n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00000.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00001.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00003.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00005.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00006.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00007.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00008.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00009.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00010.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00011.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00012.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00013.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00014.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00017.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00018.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00019.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00020.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00021.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00023.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00024.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00026.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00027.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00029.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00030.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00031.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00032.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00033.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00034.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00036.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00037.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00038.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00040.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00041.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00043.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00044.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00046.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00048.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00049.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00050.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00052.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00053.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00054.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00055.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00056.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00057.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00058.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00059.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00060.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00061.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00062.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00063.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00064.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00065.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00066.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00067.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00068.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00070.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00072.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00074.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00076.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00077.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00078.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00079.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00081.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00082.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00083.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00085.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00086.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00087.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00088.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00090.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00091.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00092.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00093.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00094.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00095.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00096.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00097.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00098.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/reggae/reggae.00099.png  \n",
            "   creating: /content/spectrograms_mfcc/train/rock/\n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00000.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00002.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00003.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00004.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00006.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00007.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00008.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00009.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00010.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00013.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00014.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00016.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00017.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00018.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00019.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00020.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00021.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00022.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00025.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00026.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00027.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00028.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00031.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00032.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00033.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00034.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00035.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00036.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00038.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00039.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00040.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00042.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00043.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00044.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00045.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00047.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00048.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00049.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00050.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00051.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00052.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00053.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00054.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00055.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00056.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00058.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00059.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00060.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00061.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00062.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00063.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00064.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00066.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00067.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00068.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00070.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00071.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00072.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00073.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00075.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00076.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00077.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00078.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00080.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00081.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00082.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00083.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00084.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00085.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00088.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00089.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00091.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00092.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00093.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00094.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00095.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00096.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00097.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00098.png  \n",
            "  inflating: /content/spectrograms_mfcc/train/rock/rock.00099.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data"
      ],
      "metadata": {
        "id": "NWZb-uB9Fm1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spectrograms_test_dir = '/content/spectrograms_mfcc/test'\n",
        "spectrograms_train_dir = '/content/spectrograms_mfcc/train'\n",
        "\n",
        "train_ds = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "  spectrograms_train_dir,\n",
        "  label_mode='categorical',\n",
        "  seed=123,\n",
        "  image_size=(600, 300))\n",
        "\n",
        "test_ds = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "  spectrograms_test_dir,\n",
        "  label_mode='categorical',\n",
        "  seed=123,\n",
        "  image_size=(600, 300))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0ca871-35e7-40e7-d0ad-f587613411f6",
        "id": "4Q3d_7X0Fm1B"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 798 files belonging to 10 classes.\n",
            "Found 200 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(images, labels):\n",
        "  return tensorflow.keras.applications.resnet50.preprocess_input(images), labels\n",
        "\n",
        "train_ds = train_ds.map(preprocess)"
      ],
      "metadata": {
        "id": "xSH8ZslDFm1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = create_nn_model_1()\n",
        "# model = create_nn_model_4()\n",
        "# model = create_nn_model_3()\n",
        "model = create_nn_model_2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2841f5-78c6-499c-97f8-be0ea7aa1e27",
        "id": "SUHkxEG5Fm1B"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = \"/content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/\"\n",
        "checkpoint_subdir = os.path.join(checkpoint_dir, model.name)\n",
        "if not os.path.exists(checkpoint_subdir):\n",
        "  os.makedirs(checkpoint_subdir)\n",
        "\n",
        "checkpoint_path = os.path.join(checkpoint_subdir, f\"best_model_original_mfcc.keras\")"
      ],
      "metadata": {
        "id": "oxOmbH8RFm1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train models"
      ],
      "metadata": {
        "id": "Ge4a-YjNFm1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def save_history(history):\n",
        "  filename = f'{model.name}_history_original_mfcc.npy'\n",
        "  np.save(filename, H.history)\n",
        "  content_dir = \"/content/\" + filename\n",
        "  checkpoint_dir = \"/content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/\" + model.name\n",
        "  shutil.copy(content_dir, checkpoint_dir)"
      ],
      "metadata": {
        "id": "VbsiUCNsFm1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet model"
      ],
      "metadata": {
        "id": "Y6UY7-g1Fm1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, checkpoint = resnet_compile(model, checkpoint_path)\n",
        "H = model.fit(train_ds, epochs=100, validation_data=test_ds, callbacks=[checkpoint])\n",
        "save_history(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54038c85-597c-425d-86ee-61fcd73e24a5",
        "id": "Uw_1W0NeFm1C"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.0985 - accuracy: 0.2469\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 34s 831ms/step - loss: 2.0985 - accuracy: 0.2469 - val_loss: 1.8515 - val_accuracy: 0.3100\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8092 - accuracy: 0.3647\n",
            "Epoch 2: val_accuracy improved from 0.31000 to 0.39500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 14s 514ms/step - loss: 1.8092 - accuracy: 0.3647 - val_loss: 1.6912 - val_accuracy: 0.3950\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6895 - accuracy: 0.3985\n",
            "Epoch 3: val_accuracy improved from 0.39500 to 0.40000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 14s 527ms/step - loss: 1.6895 - accuracy: 0.3985 - val_loss: 1.6106 - val_accuracy: 0.4000\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5986 - accuracy: 0.4273\n",
            "Epoch 4: val_accuracy improved from 0.40000 to 0.44500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 16s 609ms/step - loss: 1.5986 - accuracy: 0.4273 - val_loss: 1.5224 - val_accuracy: 0.4450\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5431 - accuracy: 0.4561\n",
            "Epoch 5: val_accuracy did not improve from 0.44500\n",
            "25/25 [==============================] - 14s 504ms/step - loss: 1.5431 - accuracy: 0.4561 - val_loss: 1.5251 - val_accuracy: 0.4100\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4876 - accuracy: 0.4486\n",
            "Epoch 6: val_accuracy did not improve from 0.44500\n",
            "25/25 [==============================] - 14s 516ms/step - loss: 1.4876 - accuracy: 0.4486 - val_loss: 1.4957 - val_accuracy: 0.4100\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4309 - accuracy: 0.5138\n",
            "Epoch 7: val_accuracy did not improve from 0.44500\n",
            "25/25 [==============================] - 13s 501ms/step - loss: 1.4309 - accuracy: 0.5138 - val_loss: 1.4603 - val_accuracy: 0.4250\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3926 - accuracy: 0.5213\n",
            "Epoch 8: val_accuracy did not improve from 0.44500\n",
            "25/25 [==============================] - 13s 470ms/step - loss: 1.3926 - accuracy: 0.5213 - val_loss: 1.4323 - val_accuracy: 0.4450\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3653 - accuracy: 0.5301\n",
            "Epoch 9: val_accuracy improved from 0.44500 to 0.51500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 17s 666ms/step - loss: 1.3653 - accuracy: 0.5301 - val_loss: 1.3748 - val_accuracy: 0.5150\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3316 - accuracy: 0.5464\n",
            "Epoch 10: val_accuracy did not improve from 0.51500\n",
            "25/25 [==============================] - 14s 503ms/step - loss: 1.3316 - accuracy: 0.5464 - val_loss: 1.3571 - val_accuracy: 0.4850\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2892 - accuracy: 0.5789\n",
            "Epoch 11: val_accuracy did not improve from 0.51500\n",
            "25/25 [==============================] - 13s 480ms/step - loss: 1.2892 - accuracy: 0.5789 - val_loss: 1.3502 - val_accuracy: 0.5150\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2734 - accuracy: 0.5739\n",
            "Epoch 12: val_accuracy did not improve from 0.51500\n",
            "25/25 [==============================] - 13s 485ms/step - loss: 1.2734 - accuracy: 0.5739 - val_loss: 1.3527 - val_accuracy: 0.4800\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2596 - accuracy: 0.5614\n",
            "Epoch 13: val_accuracy did not improve from 0.51500\n",
            "25/25 [==============================] - 14s 505ms/step - loss: 1.2596 - accuracy: 0.5614 - val_loss: 1.3177 - val_accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2324 - accuracy: 0.5714\n",
            "Epoch 14: val_accuracy did not improve from 0.51500\n",
            "25/25 [==============================] - 13s 498ms/step - loss: 1.2324 - accuracy: 0.5714 - val_loss: 1.3308 - val_accuracy: 0.4750\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2182 - accuracy: 0.5777\n",
            "Epoch 15: val_accuracy improved from 0.51500 to 0.53500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 16s 602ms/step - loss: 1.2182 - accuracy: 0.5777 - val_loss: 1.2791 - val_accuracy: 0.5350\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1922 - accuracy: 0.5902\n",
            "Epoch 16: val_accuracy did not improve from 0.53500\n",
            "25/25 [==============================] - 13s 483ms/step - loss: 1.1922 - accuracy: 0.5902 - val_loss: 1.3470 - val_accuracy: 0.4800\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1798 - accuracy: 0.6090\n",
            "Epoch 17: val_accuracy did not improve from 0.53500\n",
            "25/25 [==============================] - 13s 483ms/step - loss: 1.1798 - accuracy: 0.6090 - val_loss: 1.2796 - val_accuracy: 0.5200\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1596 - accuracy: 0.6153\n",
            "Epoch 18: val_accuracy did not improve from 0.53500\n",
            "25/25 [==============================] - 13s 485ms/step - loss: 1.1596 - accuracy: 0.6153 - val_loss: 1.2994 - val_accuracy: 0.4850\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1506 - accuracy: 0.5952\n",
            "Epoch 19: val_accuracy did not improve from 0.53500\n",
            "25/25 [==============================] - 13s 497ms/step - loss: 1.1506 - accuracy: 0.5952 - val_loss: 1.2481 - val_accuracy: 0.5150\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1353 - accuracy: 0.6040\n",
            "Epoch 20: val_accuracy did not improve from 0.53500\n",
            "25/25 [==============================] - 13s 494ms/step - loss: 1.1353 - accuracy: 0.6040 - val_loss: 1.2419 - val_accuracy: 0.5150\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1135 - accuracy: 0.6028\n",
            "Epoch 21: val_accuracy did not improve from 0.53500\n",
            "25/25 [==============================] - 15s 558ms/step - loss: 1.1135 - accuracy: 0.6028 - val_loss: 1.2328 - val_accuracy: 0.5350\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1060 - accuracy: 0.6266\n",
            "Epoch 22: val_accuracy did not improve from 0.53500\n",
            "25/25 [==============================] - 13s 497ms/step - loss: 1.1060 - accuracy: 0.6266 - val_loss: 1.2315 - val_accuracy: 0.5350\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0890 - accuracy: 0.6391\n",
            "Epoch 23: val_accuracy did not improve from 0.53500\n",
            "25/25 [==============================] - 13s 495ms/step - loss: 1.0890 - accuracy: 0.6391 - val_loss: 1.2681 - val_accuracy: 0.4650\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0749 - accuracy: 0.6404\n",
            "Epoch 24: val_accuracy did not improve from 0.53500\n",
            "25/25 [==============================] - 13s 489ms/step - loss: 1.0749 - accuracy: 0.6404 - val_loss: 1.2467 - val_accuracy: 0.5350\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0810 - accuracy: 0.6378\n",
            "Epoch 25: val_accuracy improved from 0.53500 to 0.54500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 15s 578ms/step - loss: 1.0810 - accuracy: 0.6378 - val_loss: 1.2141 - val_accuracy: 0.5450\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0564 - accuracy: 0.6466\n",
            "Epoch 26: val_accuracy improved from 0.54500 to 0.56000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 15s 569ms/step - loss: 1.0564 - accuracy: 0.6466 - val_loss: 1.2262 - val_accuracy: 0.5600\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0596 - accuracy: 0.6504\n",
            "Epoch 27: val_accuracy did not improve from 0.56000\n",
            "25/25 [==============================] - 14s 498ms/step - loss: 1.0596 - accuracy: 0.6504 - val_loss: 1.2077 - val_accuracy: 0.5600\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0411 - accuracy: 0.6291\n",
            "Epoch 28: val_accuracy did not improve from 0.56000\n",
            "25/25 [==============================] - 13s 490ms/step - loss: 1.0411 - accuracy: 0.6291 - val_loss: 1.2114 - val_accuracy: 0.5250\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0341 - accuracy: 0.6541\n",
            "Epoch 29: val_accuracy improved from 0.56000 to 0.56500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 15s 583ms/step - loss: 1.0341 - accuracy: 0.6541 - val_loss: 1.1962 - val_accuracy: 0.5650\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0219 - accuracy: 0.6479\n",
            "Epoch 30: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 491ms/step - loss: 1.0219 - accuracy: 0.6479 - val_loss: 1.1865 - val_accuracy: 0.5400\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0167 - accuracy: 0.6554\n",
            "Epoch 31: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 472ms/step - loss: 1.0167 - accuracy: 0.6554 - val_loss: 1.2058 - val_accuracy: 0.5450\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0029 - accuracy: 0.6704\n",
            "Epoch 32: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 494ms/step - loss: 1.0029 - accuracy: 0.6704 - val_loss: 1.1993 - val_accuracy: 0.5350\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9959 - accuracy: 0.6767\n",
            "Epoch 33: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 483ms/step - loss: 0.9959 - accuracy: 0.6767 - val_loss: 1.2110 - val_accuracy: 0.5500\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9931 - accuracy: 0.6729\n",
            "Epoch 34: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 15s 570ms/step - loss: 0.9931 - accuracy: 0.6729 - val_loss: 1.2112 - val_accuracy: 0.5400\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9906 - accuracy: 0.6679\n",
            "Epoch 35: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 470ms/step - loss: 0.9906 - accuracy: 0.6679 - val_loss: 1.1826 - val_accuracy: 0.5400\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9729 - accuracy: 0.6754\n",
            "Epoch 36: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 469ms/step - loss: 0.9729 - accuracy: 0.6754 - val_loss: 1.2112 - val_accuracy: 0.5550\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9736 - accuracy: 0.6742\n",
            "Epoch 37: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 14s 501ms/step - loss: 0.9736 - accuracy: 0.6742 - val_loss: 1.2003 - val_accuracy: 0.5450\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9609 - accuracy: 0.6779\n",
            "Epoch 38: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 14s 508ms/step - loss: 0.9609 - accuracy: 0.6779 - val_loss: 1.1794 - val_accuracy: 0.5300\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9615 - accuracy: 0.6842\n",
            "Epoch 39: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 500ms/step - loss: 0.9615 - accuracy: 0.6842 - val_loss: 1.1754 - val_accuracy: 0.5550\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9560 - accuracy: 0.6867\n",
            "Epoch 40: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 496ms/step - loss: 0.9560 - accuracy: 0.6867 - val_loss: 1.1750 - val_accuracy: 0.5550\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9392 - accuracy: 0.6917\n",
            "Epoch 41: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 493ms/step - loss: 0.9392 - accuracy: 0.6917 - val_loss: 1.1926 - val_accuracy: 0.5350\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9503 - accuracy: 0.6855\n",
            "Epoch 42: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 502ms/step - loss: 0.9503 - accuracy: 0.6855 - val_loss: 1.1643 - val_accuracy: 0.5400\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9347 - accuracy: 0.6967\n",
            "Epoch 43: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 506ms/step - loss: 0.9347 - accuracy: 0.6967 - val_loss: 1.1834 - val_accuracy: 0.5500\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9316 - accuracy: 0.6942\n",
            "Epoch 44: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 479ms/step - loss: 0.9316 - accuracy: 0.6942 - val_loss: 1.1761 - val_accuracy: 0.5350\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9256 - accuracy: 0.6905\n",
            "Epoch 45: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 483ms/step - loss: 0.9256 - accuracy: 0.6905 - val_loss: 1.1602 - val_accuracy: 0.5350\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9226 - accuracy: 0.6905\n",
            "Epoch 46: val_accuracy did not improve from 0.56500\n",
            "25/25 [==============================] - 13s 486ms/step - loss: 0.9226 - accuracy: 0.6905 - val_loss: 1.1691 - val_accuracy: 0.5650\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9224 - accuracy: 0.6880\n",
            "Epoch 47: val_accuracy improved from 0.56500 to 0.57500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 15s 572ms/step - loss: 0.9224 - accuracy: 0.6880 - val_loss: 1.1510 - val_accuracy: 0.5750\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9177 - accuracy: 0.6980\n",
            "Epoch 48: val_accuracy did not improve from 0.57500\n",
            "25/25 [==============================] - 13s 491ms/step - loss: 0.9177 - accuracy: 0.6980 - val_loss: 1.1632 - val_accuracy: 0.5550\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9112 - accuracy: 0.7055\n",
            "Epoch 49: val_accuracy did not improve from 0.57500\n",
            "25/25 [==============================] - 13s 475ms/step - loss: 0.9112 - accuracy: 0.7055 - val_loss: 1.1638 - val_accuracy: 0.5450\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9073 - accuracy: 0.7005\n",
            "Epoch 50: val_accuracy did not improve from 0.57500\n",
            "25/25 [==============================] - 13s 482ms/step - loss: 0.9073 - accuracy: 0.7005 - val_loss: 1.1499 - val_accuracy: 0.5500\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9044 - accuracy: 0.7130\n",
            "Epoch 51: val_accuracy did not improve from 0.57500\n",
            "25/25 [==============================] - 13s 489ms/step - loss: 0.9044 - accuracy: 0.7130 - val_loss: 1.1476 - val_accuracy: 0.5500\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8998 - accuracy: 0.7005\n",
            "Epoch 52: val_accuracy did not improve from 0.57500\n",
            "25/25 [==============================] - 13s 480ms/step - loss: 0.8998 - accuracy: 0.7005 - val_loss: 1.1582 - val_accuracy: 0.5700\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8961 - accuracy: 0.7180\n",
            "Epoch 53: val_accuracy did not improve from 0.57500\n",
            "25/25 [==============================] - 13s 478ms/step - loss: 0.8961 - accuracy: 0.7180 - val_loss: 1.1553 - val_accuracy: 0.5450\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8945 - accuracy: 0.7055\n",
            "Epoch 54: val_accuracy did not improve from 0.57500\n",
            "25/25 [==============================] - 13s 485ms/step - loss: 0.8945 - accuracy: 0.7055 - val_loss: 1.1484 - val_accuracy: 0.5700\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8896 - accuracy: 0.7143\n",
            "Epoch 55: val_accuracy did not improve from 0.57500\n",
            "25/25 [==============================] - 16s 558ms/step - loss: 0.8896 - accuracy: 0.7143 - val_loss: 1.1439 - val_accuracy: 0.5650\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8869 - accuracy: 0.7093\n",
            "Epoch 56: val_accuracy improved from 0.57500 to 0.58000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 17s 656ms/step - loss: 0.8869 - accuracy: 0.7093 - val_loss: 1.1465 - val_accuracy: 0.5800\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8845 - accuracy: 0.7143\n",
            "Epoch 57: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 479ms/step - loss: 0.8845 - accuracy: 0.7143 - val_loss: 1.1481 - val_accuracy: 0.5800\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8841 - accuracy: 0.7030\n",
            "Epoch 58: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 494ms/step - loss: 0.8841 - accuracy: 0.7030 - val_loss: 1.1427 - val_accuracy: 0.5650\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8806 - accuracy: 0.7055\n",
            "Epoch 59: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 485ms/step - loss: 0.8806 - accuracy: 0.7055 - val_loss: 1.1470 - val_accuracy: 0.5700\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8746 - accuracy: 0.7155\n",
            "Epoch 60: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 486ms/step - loss: 0.8746 - accuracy: 0.7155 - val_loss: 1.1427 - val_accuracy: 0.5800\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8765 - accuracy: 0.7105\n",
            "Epoch 61: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 15s 570ms/step - loss: 0.8765 - accuracy: 0.7105 - val_loss: 1.1483 - val_accuracy: 0.5600\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8691 - accuracy: 0.7143\n",
            "Epoch 62: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 474ms/step - loss: 0.8691 - accuracy: 0.7143 - val_loss: 1.1495 - val_accuracy: 0.5600\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8710 - accuracy: 0.7130\n",
            "Epoch 63: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 477ms/step - loss: 0.8710 - accuracy: 0.7130 - val_loss: 1.1376 - val_accuracy: 0.5650\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8641 - accuracy: 0.7180\n",
            "Epoch 64: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 471ms/step - loss: 0.8641 - accuracy: 0.7180 - val_loss: 1.1526 - val_accuracy: 0.5600\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8640 - accuracy: 0.7218\n",
            "Epoch 65: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 475ms/step - loss: 0.8640 - accuracy: 0.7218 - val_loss: 1.1362 - val_accuracy: 0.5800\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8632 - accuracy: 0.7168\n",
            "Epoch 66: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 476ms/step - loss: 0.8632 - accuracy: 0.7168 - val_loss: 1.1373 - val_accuracy: 0.5650\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8584 - accuracy: 0.7231\n",
            "Epoch 67: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 16s 555ms/step - loss: 0.8584 - accuracy: 0.7231 - val_loss: 1.1412 - val_accuracy: 0.5650\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8574 - accuracy: 0.7231\n",
            "Epoch 68: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 14s 505ms/step - loss: 0.8574 - accuracy: 0.7231 - val_loss: 1.1472 - val_accuracy: 0.5550\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8556 - accuracy: 0.7155\n",
            "Epoch 69: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 14s 519ms/step - loss: 0.8556 - accuracy: 0.7155 - val_loss: 1.1433 - val_accuracy: 0.5750\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8556 - accuracy: 0.7231\n",
            "Epoch 70: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 478ms/step - loss: 0.8556 - accuracy: 0.7231 - val_loss: 1.1400 - val_accuracy: 0.5750\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8528 - accuracy: 0.7206\n",
            "Epoch 71: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 495ms/step - loss: 0.8528 - accuracy: 0.7206 - val_loss: 1.1379 - val_accuracy: 0.5550\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8504 - accuracy: 0.7281\n",
            "Epoch 72: val_accuracy did not improve from 0.58000\n",
            "25/25 [==============================] - 13s 481ms/step - loss: 0.8504 - accuracy: 0.7281 - val_loss: 1.1360 - val_accuracy: 0.5550\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8483 - accuracy: 0.7268\n",
            "Epoch 73: val_accuracy improved from 0.58000 to 0.58500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_ResNet50/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 17s 632ms/step - loss: 0.8483 - accuracy: 0.7268 - val_loss: 1.1350 - val_accuracy: 0.5850\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8471 - accuracy: 0.7318\n",
            "Epoch 74: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 490ms/step - loss: 0.8471 - accuracy: 0.7318 - val_loss: 1.1327 - val_accuracy: 0.5600\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8466 - accuracy: 0.7243\n",
            "Epoch 75: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 483ms/step - loss: 0.8466 - accuracy: 0.7243 - val_loss: 1.1341 - val_accuracy: 0.5650\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8438 - accuracy: 0.7268\n",
            "Epoch 76: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 480ms/step - loss: 0.8438 - accuracy: 0.7268 - val_loss: 1.1354 - val_accuracy: 0.5700\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8411 - accuracy: 0.7268\n",
            "Epoch 77: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 474ms/step - loss: 0.8411 - accuracy: 0.7268 - val_loss: 1.1358 - val_accuracy: 0.5550\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8414 - accuracy: 0.7243\n",
            "Epoch 78: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 481ms/step - loss: 0.8414 - accuracy: 0.7243 - val_loss: 1.1344 - val_accuracy: 0.5600\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8405 - accuracy: 0.7343\n",
            "Epoch 79: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 484ms/step - loss: 0.8405 - accuracy: 0.7343 - val_loss: 1.1307 - val_accuracy: 0.5750\n",
            "Epoch 80/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8374 - accuracy: 0.7419\n",
            "Epoch 80: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 484ms/step - loss: 0.8374 - accuracy: 0.7419 - val_loss: 1.1326 - val_accuracy: 0.5650\n",
            "Epoch 81/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8376 - accuracy: 0.7406\n",
            "Epoch 81: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 15s 570ms/step - loss: 0.8376 - accuracy: 0.7406 - val_loss: 1.1313 - val_accuracy: 0.5750\n",
            "Epoch 82/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8358 - accuracy: 0.7393\n",
            "Epoch 82: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 472ms/step - loss: 0.8358 - accuracy: 0.7393 - val_loss: 1.1312 - val_accuracy: 0.5750\n",
            "Epoch 83/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8343 - accuracy: 0.7306\n",
            "Epoch 83: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 471ms/step - loss: 0.8343 - accuracy: 0.7306 - val_loss: 1.1291 - val_accuracy: 0.5850\n",
            "Epoch 84/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8321 - accuracy: 0.7343\n",
            "Epoch 84: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 477ms/step - loss: 0.8321 - accuracy: 0.7343 - val_loss: 1.1306 - val_accuracy: 0.5600\n",
            "Epoch 85/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8329 - accuracy: 0.7281\n",
            "Epoch 85: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 485ms/step - loss: 0.8329 - accuracy: 0.7281 - val_loss: 1.1315 - val_accuracy: 0.5650\n",
            "Epoch 86/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8320 - accuracy: 0.7406\n",
            "Epoch 86: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 500ms/step - loss: 0.8320 - accuracy: 0.7406 - val_loss: 1.1312 - val_accuracy: 0.5600\n",
            "Epoch 87/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8310 - accuracy: 0.7281\n",
            "Epoch 87: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 491ms/step - loss: 0.8310 - accuracy: 0.7281 - val_loss: 1.1304 - val_accuracy: 0.5600\n",
            "Epoch 88/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8300 - accuracy: 0.7331\n",
            "Epoch 88: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 484ms/step - loss: 0.8300 - accuracy: 0.7331 - val_loss: 1.1282 - val_accuracy: 0.5700\n",
            "Epoch 89/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8275 - accuracy: 0.7343\n",
            "Epoch 89: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 496ms/step - loss: 0.8275 - accuracy: 0.7343 - val_loss: 1.1298 - val_accuracy: 0.5700\n",
            "Epoch 90/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8276 - accuracy: 0.7368\n",
            "Epoch 90: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 469ms/step - loss: 0.8276 - accuracy: 0.7368 - val_loss: 1.1283 - val_accuracy: 0.5800\n",
            "Epoch 91/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8264 - accuracy: 0.7331\n",
            "Epoch 91: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 481ms/step - loss: 0.8264 - accuracy: 0.7331 - val_loss: 1.1295 - val_accuracy: 0.5750\n",
            "Epoch 92/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8259 - accuracy: 0.7343\n",
            "Epoch 92: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 491ms/step - loss: 0.8259 - accuracy: 0.7343 - val_loss: 1.1318 - val_accuracy: 0.5700\n",
            "Epoch 93/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8250 - accuracy: 0.7368\n",
            "Epoch 93: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 500ms/step - loss: 0.8250 - accuracy: 0.7368 - val_loss: 1.1294 - val_accuracy: 0.5700\n",
            "Epoch 94/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8241 - accuracy: 0.7381\n",
            "Epoch 94: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 14s 515ms/step - loss: 0.8241 - accuracy: 0.7381 - val_loss: 1.1300 - val_accuracy: 0.5700\n",
            "Epoch 95/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8234 - accuracy: 0.7368\n",
            "Epoch 95: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 500ms/step - loss: 0.8234 - accuracy: 0.7368 - val_loss: 1.1279 - val_accuracy: 0.5750\n",
            "Epoch 96/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8223 - accuracy: 0.7356\n",
            "Epoch 96: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 494ms/step - loss: 0.8223 - accuracy: 0.7356 - val_loss: 1.1274 - val_accuracy: 0.5750\n",
            "Epoch 97/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8218 - accuracy: 0.7368\n",
            "Epoch 97: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 502ms/step - loss: 0.8218 - accuracy: 0.7368 - val_loss: 1.1268 - val_accuracy: 0.5800\n",
            "Epoch 98/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8211 - accuracy: 0.7393\n",
            "Epoch 98: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 481ms/step - loss: 0.8211 - accuracy: 0.7393 - val_loss: 1.1264 - val_accuracy: 0.5800\n",
            "Epoch 99/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8199 - accuracy: 0.7368\n",
            "Epoch 99: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 14s 508ms/step - loss: 0.8199 - accuracy: 0.7368 - val_loss: 1.1277 - val_accuracy: 0.5750\n",
            "Epoch 100/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8198 - accuracy: 0.7381\n",
            "Epoch 100: val_accuracy did not improve from 0.58500\n",
            "25/25 [==============================] - 13s 482ms/step - loss: 0.8198 - accuracy: 0.7381 - val_loss: 1.1274 - val_accuracy: 0.5800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Model_1"
      ],
      "metadata": {
        "id": "HONEYRjSFm1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, reduce_lr, checkpoint = model_1_compile(model, checkpoint_path)\n",
        "H = model.fit(train_ds, epochs=100, validation_data=test_ds, callbacks=[checkpoint, reduce_lr])\n",
        "save_history(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162daa37-863c-4843-8594-8eccb709507f",
        "id": "8tpO0bF8Fm1C",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 36.0836 - accuracy: 0.1103\n",
            "Epoch 1: val_accuracy improved from -inf to 0.10000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 24s 838ms/step - loss: 36.0836 - accuracy: 0.1103 - val_loss: 2.3034 - val_accuracy: 0.1000 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.3201 - accuracy: 0.0977\n",
            "Epoch 2: val_accuracy did not improve from 0.10000\n",
            "25/25 [==============================] - 19s 713ms/step - loss: 2.3201 - accuracy: 0.0977 - val_loss: 2.3010 - val_accuracy: 0.0950 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.2985 - accuracy: 0.1216\n",
            "Epoch 3: val_accuracy improved from 0.10000 to 0.11000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 22s 830ms/step - loss: 2.2985 - accuracy: 0.1216 - val_loss: 2.2765 - val_accuracy: 0.1100 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.2475 - accuracy: 0.1429\n",
            "Epoch 4: val_accuracy improved from 0.11000 to 0.21500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 20s 765ms/step - loss: 2.2475 - accuracy: 0.1429 - val_loss: 2.1749 - val_accuracy: 0.2150 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.2037 - accuracy: 0.1880\n",
            "Epoch 5: val_accuracy improved from 0.21500 to 0.22000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 21s 810ms/step - loss: 2.2037 - accuracy: 0.1880 - val_loss: 2.1862 - val_accuracy: 0.2200 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.1600 - accuracy: 0.1942\n",
            "Epoch 6: val_accuracy did not improve from 0.22000\n",
            "25/25 [==============================] - 19s 713ms/step - loss: 2.1600 - accuracy: 0.1942 - val_loss: 2.0826 - val_accuracy: 0.2050 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.1324 - accuracy: 0.1992\n",
            "Epoch 7: val_accuracy improved from 0.22000 to 0.26500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 21s 785ms/step - loss: 2.1324 - accuracy: 0.1992 - val_loss: 2.0726 - val_accuracy: 0.2650 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.0561 - accuracy: 0.2155\n",
            "Epoch 8: val_accuracy did not improve from 0.26500\n",
            "25/25 [==============================] - 19s 715ms/step - loss: 2.0561 - accuracy: 0.2155 - val_loss: 2.0294 - val_accuracy: 0.2350 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.0048 - accuracy: 0.2381\n",
            "Epoch 9: val_accuracy did not improve from 0.26500\n",
            "25/25 [==============================] - 19s 716ms/step - loss: 2.0048 - accuracy: 0.2381 - val_loss: 1.9815 - val_accuracy: 0.2450 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.9901 - accuracy: 0.2368\n",
            "Epoch 10: val_accuracy did not improve from 0.26500\n",
            "25/25 [==============================] - 20s 733ms/step - loss: 1.9901 - accuracy: 0.2368 - val_loss: 1.9101 - val_accuracy: 0.2650 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.9595 - accuracy: 0.2544\n",
            "Epoch 11: val_accuracy did not improve from 0.26500\n",
            "25/25 [==============================] - 19s 709ms/step - loss: 1.9595 - accuracy: 0.2544 - val_loss: 1.9774 - val_accuracy: 0.2600 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.9360 - accuracy: 0.2644\n",
            "Epoch 12: val_accuracy did not improve from 0.26500\n",
            "25/25 [==============================] - 20s 763ms/step - loss: 1.9360 - accuracy: 0.2644 - val_loss: 1.9115 - val_accuracy: 0.2450 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.9189 - accuracy: 0.2694\n",
            "Epoch 13: val_accuracy improved from 0.26500 to 0.31500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 21s 776ms/step - loss: 1.9189 - accuracy: 0.2694 - val_loss: 1.9280 - val_accuracy: 0.3150 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.9128 - accuracy: 0.2669\n",
            "Epoch 14: val_accuracy did not improve from 0.31500\n",
            "25/25 [==============================] - 19s 742ms/step - loss: 1.9128 - accuracy: 0.2669 - val_loss: 1.9150 - val_accuracy: 0.2950 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8745 - accuracy: 0.2794\n",
            "Epoch 15: val_accuracy did not improve from 0.31500\n",
            "25/25 [==============================] - 20s 711ms/step - loss: 1.8745 - accuracy: 0.2794 - val_loss: 1.8268 - val_accuracy: 0.3050 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8302 - accuracy: 0.3308\n",
            "Epoch 16: val_accuracy improved from 0.31500 to 0.32500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 21s 780ms/step - loss: 1.8302 - accuracy: 0.3308 - val_loss: 1.8589 - val_accuracy: 0.3250 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8062 - accuracy: 0.3183\n",
            "Epoch 17: val_accuracy did not improve from 0.32500\n",
            "25/25 [==============================] - 20s 714ms/step - loss: 1.8062 - accuracy: 0.3183 - val_loss: 1.9182 - val_accuracy: 0.2950 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8470 - accuracy: 0.2907\n",
            "Epoch 18: val_accuracy did not improve from 0.32500\n",
            "25/25 [==============================] - 19s 708ms/step - loss: 1.8470 - accuracy: 0.2907 - val_loss: 1.8142 - val_accuracy: 0.2800 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7655 - accuracy: 0.3622\n",
            "Epoch 19: val_accuracy improved from 0.32500 to 0.33500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 21s 793ms/step - loss: 1.7655 - accuracy: 0.3622 - val_loss: 1.7787 - val_accuracy: 0.3350 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8116 - accuracy: 0.3170\n",
            "Epoch 20: val_accuracy did not improve from 0.33500\n",
            "25/25 [==============================] - 19s 721ms/step - loss: 1.8116 - accuracy: 0.3170 - val_loss: 1.8157 - val_accuracy: 0.3200 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7691 - accuracy: 0.3596\n",
            "Epoch 21: val_accuracy improved from 0.33500 to 0.36000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 21s 804ms/step - loss: 1.7691 - accuracy: 0.3596 - val_loss: 1.7152 - val_accuracy: 0.3600 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7166 - accuracy: 0.3421\n",
            "Epoch 22: val_accuracy did not improve from 0.36000\n",
            "25/25 [==============================] - 19s 734ms/step - loss: 1.7166 - accuracy: 0.3421 - val_loss: 1.7299 - val_accuracy: 0.3350 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7466 - accuracy: 0.3371\n",
            "Epoch 23: val_accuracy did not improve from 0.36000\n",
            "25/25 [==============================] - 19s 705ms/step - loss: 1.7466 - accuracy: 0.3371 - val_loss: 1.7428 - val_accuracy: 0.3400 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7022 - accuracy: 0.3571\n",
            "Epoch 24: val_accuracy did not improve from 0.36000\n",
            "25/25 [==============================] - 20s 762ms/step - loss: 1.7022 - accuracy: 0.3571 - val_loss: 1.7059 - val_accuracy: 0.3600 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7415 - accuracy: 0.3559\n",
            "Epoch 25: val_accuracy did not improve from 0.36000\n",
            "25/25 [==============================] - 19s 705ms/step - loss: 1.7415 - accuracy: 0.3559 - val_loss: 1.7963 - val_accuracy: 0.3500 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7103 - accuracy: 0.3471\n",
            "Epoch 26: val_accuracy improved from 0.36000 to 0.36500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 20s 772ms/step - loss: 1.7103 - accuracy: 0.3471 - val_loss: 1.7638 - val_accuracy: 0.3650 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7012 - accuracy: 0.3634\n",
            "Epoch 27: val_accuracy did not improve from 0.36500\n",
            "25/25 [==============================] - 19s 709ms/step - loss: 1.7012 - accuracy: 0.3634 - val_loss: 1.7122 - val_accuracy: 0.3600 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6502 - accuracy: 0.3797\n",
            "Epoch 28: val_accuracy improved from 0.36500 to 0.37500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 20s 774ms/step - loss: 1.6502 - accuracy: 0.3797 - val_loss: 1.8026 - val_accuracy: 0.3750 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6640 - accuracy: 0.3759\n",
            "Epoch 29: val_accuracy did not improve from 0.37500\n",
            "25/25 [==============================] - 19s 736ms/step - loss: 1.6640 - accuracy: 0.3759 - val_loss: 1.7731 - val_accuracy: 0.3400 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6669 - accuracy: 0.3709\n",
            "Epoch 30: val_accuracy did not improve from 0.37500\n",
            "25/25 [==============================] - 19s 721ms/step - loss: 1.6669 - accuracy: 0.3709 - val_loss: 1.7379 - val_accuracy: 0.3200 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6939 - accuracy: 0.3446\n",
            "Epoch 31: val_accuracy did not improve from 0.37500\n",
            "25/25 [==============================] - 20s 765ms/step - loss: 1.6939 - accuracy: 0.3446 - val_loss: 1.6598 - val_accuracy: 0.3550 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5973 - accuracy: 0.3972\n",
            "Epoch 32: val_accuracy did not improve from 0.37500\n",
            "25/25 [==============================] - 19s 707ms/step - loss: 1.5973 - accuracy: 0.3972 - val_loss: 1.7318 - val_accuracy: 0.3650 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6215 - accuracy: 0.3947\n",
            "Epoch 33: val_accuracy did not improve from 0.37500\n",
            "25/25 [==============================] - 19s 708ms/step - loss: 1.6215 - accuracy: 0.3947 - val_loss: 1.6167 - val_accuracy: 0.3550 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6173 - accuracy: 0.3972\n",
            "Epoch 34: val_accuracy did not improve from 0.37500\n",
            "25/25 [==============================] - 20s 714ms/step - loss: 1.6173 - accuracy: 0.3972 - val_loss: 1.7638 - val_accuracy: 0.3700 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6714 - accuracy: 0.3847\n",
            "Epoch 35: val_accuracy improved from 0.37500 to 0.39500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 20s 771ms/step - loss: 1.6714 - accuracy: 0.3847 - val_loss: 1.7215 - val_accuracy: 0.3950 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6480 - accuracy: 0.3885\n",
            "Epoch 36: val_accuracy did not improve from 0.39500\n",
            "25/25 [==============================] - 20s 741ms/step - loss: 1.6480 - accuracy: 0.3885 - val_loss: 1.7130 - val_accuracy: 0.3800 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5745 - accuracy: 0.3985\n",
            "Epoch 37: val_accuracy did not improve from 0.39500\n",
            "25/25 [==============================] - 19s 716ms/step - loss: 1.5745 - accuracy: 0.3985 - val_loss: 1.6800 - val_accuracy: 0.3400 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5680 - accuracy: 0.4085\n",
            "Epoch 38: val_accuracy did not improve from 0.39500\n",
            "25/25 [==============================] - 19s 737ms/step - loss: 1.5680 - accuracy: 0.4085 - val_loss: 1.6266 - val_accuracy: 0.3750 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5722 - accuracy: 0.3835\n",
            "Epoch 39: val_accuracy did not improve from 0.39500\n",
            "25/25 [==============================] - 19s 709ms/step - loss: 1.5722 - accuracy: 0.3835 - val_loss: 1.7904 - val_accuracy: 0.3350 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5215 - accuracy: 0.4323\n",
            "Epoch 40: val_accuracy did not improve from 0.39500\n",
            "25/25 [==============================] - 19s 731ms/step - loss: 1.5215 - accuracy: 0.4323 - val_loss: 1.6686 - val_accuracy: 0.3950 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5642 - accuracy: 0.4023\n",
            "Epoch 41: val_accuracy improved from 0.39500 to 0.42500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 21s 768ms/step - loss: 1.5642 - accuracy: 0.4023 - val_loss: 1.6606 - val_accuracy: 0.4250 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5054 - accuracy: 0.4424\n",
            "Epoch 42: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 20s 763ms/step - loss: 1.5054 - accuracy: 0.4424 - val_loss: 1.8917 - val_accuracy: 0.3300 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5595 - accuracy: 0.3972\n",
            "Epoch 43: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 19s 708ms/step - loss: 1.5595 - accuracy: 0.3972 - val_loss: 1.7222 - val_accuracy: 0.3700 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5166 - accuracy: 0.4586\n",
            "Epoch 44: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 19s 709ms/step - loss: 1.5166 - accuracy: 0.4586 - val_loss: 1.6084 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4523 - accuracy: 0.4361\n",
            "Epoch 45: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 19s 717ms/step - loss: 1.4523 - accuracy: 0.4361 - val_loss: 1.7104 - val_accuracy: 0.3250 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5383 - accuracy: 0.4148\n",
            "Epoch 46: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 19s 705ms/step - loss: 1.5383 - accuracy: 0.4148 - val_loss: 1.6540 - val_accuracy: 0.4000 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4787 - accuracy: 0.4261\n",
            "Epoch 47: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 20s 759ms/step - loss: 1.4787 - accuracy: 0.4261 - val_loss: 1.5947 - val_accuracy: 0.3900 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3867 - accuracy: 0.4624\n",
            "Epoch 48: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 19s 703ms/step - loss: 1.3867 - accuracy: 0.4624 - val_loss: 1.5648 - val_accuracy: 0.4150 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4526 - accuracy: 0.4474\n",
            "Epoch 49: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 20s 760ms/step - loss: 1.4526 - accuracy: 0.4474 - val_loss: 1.6385 - val_accuracy: 0.3900 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4512 - accuracy: 0.4486\n",
            "Epoch 50: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 19s 710ms/step - loss: 1.4512 - accuracy: 0.4486 - val_loss: 1.5736 - val_accuracy: 0.3800 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3606 - accuracy: 0.4712\n",
            "Epoch 51: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 19s 706ms/step - loss: 1.3606 - accuracy: 0.4712 - val_loss: 1.5954 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3758 - accuracy: 0.4699\n",
            "Epoch 52: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 20s 704ms/step - loss: 1.3758 - accuracy: 0.4699 - val_loss: 1.6204 - val_accuracy: 0.3900 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3872 - accuracy: 0.4737\n",
            "Epoch 53: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 19s 714ms/step - loss: 1.3872 - accuracy: 0.4737 - val_loss: 1.6686 - val_accuracy: 0.3900 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3742 - accuracy: 0.4925\n",
            "Epoch 54: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 20s 758ms/step - loss: 1.3742 - accuracy: 0.4925 - val_loss: 1.5838 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3547 - accuracy: 0.4712\n",
            "Epoch 55: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 19s 706ms/step - loss: 1.3547 - accuracy: 0.4712 - val_loss: 1.6401 - val_accuracy: 0.3900 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3424 - accuracy: 0.4674\n",
            "Epoch 56: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 19s 703ms/step - loss: 1.3424 - accuracy: 0.4674 - val_loss: 1.6088 - val_accuracy: 0.3950 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2429 - accuracy: 0.5313\n",
            "Epoch 57: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 19s 706ms/step - loss: 1.2429 - accuracy: 0.5313 - val_loss: 1.5292 - val_accuracy: 0.3950 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2516 - accuracy: 0.5201\n",
            "Epoch 58: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 20s 761ms/step - loss: 1.2516 - accuracy: 0.5201 - val_loss: 1.5605 - val_accuracy: 0.4000 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3101 - accuracy: 0.4937\n",
            "Epoch 59: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 20s 713ms/step - loss: 1.3101 - accuracy: 0.4937 - val_loss: 1.7338 - val_accuracy: 0.3800 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3082 - accuracy: 0.5201\n",
            "Epoch 60: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 18s 703ms/step - loss: 1.3082 - accuracy: 0.5201 - val_loss: 1.5445 - val_accuracy: 0.4250 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1682 - accuracy: 0.5414\n",
            "Epoch 61: val_accuracy did not improve from 0.42500\n",
            "25/25 [==============================] - 20s 760ms/step - loss: 1.1682 - accuracy: 0.5414 - val_loss: 1.6241 - val_accuracy: 0.3450 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1942 - accuracy: 0.5251\n",
            "Epoch 62: val_accuracy improved from 0.42500 to 0.43500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 21s 766ms/step - loss: 1.1942 - accuracy: 0.5251 - val_loss: 1.5252 - val_accuracy: 0.4350 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2030 - accuracy: 0.5539\n",
            "Epoch 63: val_accuracy did not improve from 0.43500\n",
            "25/25 [==============================] - 19s 718ms/step - loss: 1.2030 - accuracy: 0.5539 - val_loss: 1.7001 - val_accuracy: 0.3400 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2043 - accuracy: 0.5539\n",
            "Epoch 64: val_accuracy did not improve from 0.43500\n",
            "25/25 [==============================] - 19s 704ms/step - loss: 1.2043 - accuracy: 0.5539 - val_loss: 1.6416 - val_accuracy: 0.3750 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2554 - accuracy: 0.5414\n",
            "Epoch 65: val_accuracy did not improve from 0.43500\n",
            "25/25 [==============================] - 19s 707ms/step - loss: 1.2554 - accuracy: 0.5414 - val_loss: 1.8093 - val_accuracy: 0.3400 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1721 - accuracy: 0.5652\n",
            "Epoch 66: val_accuracy did not improve from 0.43500\n",
            "25/25 [==============================] - 19s 720ms/step - loss: 1.1721 - accuracy: 0.5652 - val_loss: 1.6477 - val_accuracy: 0.3650 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1305 - accuracy: 0.5802\n",
            "Epoch 67: val_accuracy did not improve from 0.43500\n",
            "25/25 [==============================] - 19s 703ms/step - loss: 1.1305 - accuracy: 0.5802 - val_loss: 1.9059 - val_accuracy: 0.3500 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1336 - accuracy: 0.5539\n",
            "Epoch 68: val_accuracy improved from 0.43500 to 0.46500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_1/best_model_original_mfcc.h5\n",
            "25/25 [==============================] - 21s 814ms/step - loss: 1.1336 - accuracy: 0.5539 - val_loss: 1.5404 - val_accuracy: 0.4650 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0647 - accuracy: 0.5827\n",
            "Epoch 69: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 720ms/step - loss: 1.0647 - accuracy: 0.5827 - val_loss: 1.6210 - val_accuracy: 0.4100 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0526 - accuracy: 0.6015\n",
            "Epoch 70: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 18s 697ms/step - loss: 1.0526 - accuracy: 0.6015 - val_loss: 1.8036 - val_accuracy: 0.3800 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0663 - accuracy: 0.5827\n",
            "Epoch 71: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 710ms/step - loss: 1.0663 - accuracy: 0.5827 - val_loss: 1.6577 - val_accuracy: 0.4350 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0108 - accuracy: 0.6103\n",
            "Epoch 72: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 20s 730ms/step - loss: 1.0108 - accuracy: 0.6103 - val_loss: 1.7370 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0262 - accuracy: 0.5915\n",
            "Epoch 73: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 705ms/step - loss: 1.0262 - accuracy: 0.5915 - val_loss: 1.7788 - val_accuracy: 0.3750 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9772 - accuracy: 0.6278\n",
            "Epoch 74: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 720ms/step - loss: 0.9772 - accuracy: 0.6278 - val_loss: 1.7899 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0387 - accuracy: 0.5990\n",
            "Epoch 75: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 700ms/step - loss: 1.0387 - accuracy: 0.5990 - val_loss: 1.6421 - val_accuracy: 0.4250 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8853 - accuracy: 0.6642\n",
            "Epoch 76: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 20s 758ms/step - loss: 0.8853 - accuracy: 0.6642 - val_loss: 1.8354 - val_accuracy: 0.4400 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9371 - accuracy: 0.6541\n",
            "Epoch 77: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 694ms/step - loss: 0.9371 - accuracy: 0.6541 - val_loss: 1.7787 - val_accuracy: 0.4200 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8287 - accuracy: 0.6955\n",
            "Epoch 78: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 711ms/step - loss: 0.8287 - accuracy: 0.6955 - val_loss: 1.9263 - val_accuracy: 0.4350 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8364 - accuracy: 0.6779\n",
            "Epoch 79: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 713ms/step - loss: 0.8364 - accuracy: 0.6779 - val_loss: 1.9865 - val_accuracy: 0.4000 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8018 - accuracy: 0.6930\n",
            "Epoch 80: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 708ms/step - loss: 0.8018 - accuracy: 0.6930 - val_loss: 2.0706 - val_accuracy: 0.4150 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9586 - accuracy: 0.6391\n",
            "Epoch 81: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 733ms/step - loss: 0.9586 - accuracy: 0.6391 - val_loss: 1.9855 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9452 - accuracy: 0.6667\n",
            "Epoch 82: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 702ms/step - loss: 0.9452 - accuracy: 0.6667 - val_loss: 1.7371 - val_accuracy: 0.4300 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8055 - accuracy: 0.6930\n",
            "Epoch 83: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 20s 760ms/step - loss: 0.8055 - accuracy: 0.6930 - val_loss: 1.7766 - val_accuracy: 0.4250 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.7419\n",
            "Epoch 84: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 702ms/step - loss: 0.6946 - accuracy: 0.7419 - val_loss: 2.0853 - val_accuracy: 0.4350 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8273 - accuracy: 0.6880\n",
            "Epoch 85: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 18s 698ms/step - loss: 0.8273 - accuracy: 0.6880 - val_loss: 1.8940 - val_accuracy: 0.4250 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7756 - accuracy: 0.6992\n",
            "Epoch 86: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 20s 722ms/step - loss: 0.7756 - accuracy: 0.6992 - val_loss: 1.8021 - val_accuracy: 0.4350 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8720 - accuracy: 0.6679\n",
            "Epoch 87: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 18s 702ms/step - loss: 0.8720 - accuracy: 0.6679 - val_loss: 1.9622 - val_accuracy: 0.4450 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7965 - accuracy: 0.6955\n",
            "Epoch 88: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 18s 702ms/step - loss: 0.7965 - accuracy: 0.6955 - val_loss: 1.9205 - val_accuracy: 0.4100 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7092 - accuracy: 0.7306\n",
            "Epoch 89: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 704ms/step - loss: 0.7092 - accuracy: 0.7306 - val_loss: 2.0559 - val_accuracy: 0.4350 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6542 - accuracy: 0.7657\n",
            "Epoch 90: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 712ms/step - loss: 0.6542 - accuracy: 0.7657 - val_loss: 1.9423 - val_accuracy: 0.4400 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7601 - accuracy: 0.7268\n",
            "Epoch 91: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 702ms/step - loss: 0.7601 - accuracy: 0.7268 - val_loss: 1.8178 - val_accuracy: 0.4350 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7024 - accuracy: 0.7469\n",
            "Epoch 92: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 18s 689ms/step - loss: 0.7024 - accuracy: 0.7469 - val_loss: 2.0022 - val_accuracy: 0.3900 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5860 - accuracy: 0.7820\n",
            "Epoch 93: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 706ms/step - loss: 0.5860 - accuracy: 0.7820 - val_loss: 2.0405 - val_accuracy: 0.4150 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5773 - accuracy: 0.7769\n",
            "Epoch 94: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 729ms/step - loss: 0.5773 - accuracy: 0.7769 - val_loss: 2.1428 - val_accuracy: 0.4200 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.7657\n",
            "Epoch 95: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 20s 708ms/step - loss: 0.6317 - accuracy: 0.7657 - val_loss: 2.2133 - val_accuracy: 0.3750 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.7857\n",
            "Epoch 96: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 703ms/step - loss: 0.6169 - accuracy: 0.7857 - val_loss: 2.1253 - val_accuracy: 0.3850 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5966 - accuracy: 0.7794\n",
            "Epoch 97: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 705ms/step - loss: 0.5966 - accuracy: 0.7794 - val_loss: 2.2627 - val_accuracy: 0.4300 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7333 - accuracy: 0.7494\n",
            "Epoch 98: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 20s 752ms/step - loss: 0.7333 - accuracy: 0.7494 - val_loss: 1.9497 - val_accuracy: 0.4300 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6496 - accuracy: 0.7669\n",
            "Epoch 99: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 19s 702ms/step - loss: 0.6496 - accuracy: 0.7669 - val_loss: 1.9310 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.8246\n",
            "Epoch 100: val_accuracy did not improve from 0.46500\n",
            "25/25 [==============================] - 20s 755ms/step - loss: 0.5162 - accuracy: 0.8246 - val_loss: 1.9514 - val_accuracy: 0.4150 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Model_2"
      ],
      "metadata": {
        "id": "nUlayxXRPcbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, reduce_lr, checkpoint = model_1_compile(model, checkpoint_path)\n",
        "H = model.fit(train_ds, epochs=200, validation_data=test_ds, callbacks=[checkpoint, reduce_lr])\n",
        "save_history(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9SjXrzdPeZm",
        "outputId": "2625f717-1c9c-4d8c-a0a6-6ad9ff4fe1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.1358 - loss: 2.6134\n",
            "Epoch 1: val_accuracy improved from -inf to 0.10000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 848ms/step - accuracy: 0.1363 - loss: 2.6091 - val_accuracy: 0.1000 - val_loss: 2.4242 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.2109 - loss: 2.2069\n",
            "Epoch 2: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 183ms/step - accuracy: 0.2112 - loss: 2.2056 - val_accuracy: 0.1000 - val_loss: 3.8011 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.2718 - loss: 2.0900\n",
            "Epoch 3: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 308ms/step - accuracy: 0.2718 - loss: 2.0890 - val_accuracy: 0.0850 - val_loss: 6.1275 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.2770 - loss: 1.9967\n",
            "Epoch 4: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.2779 - loss: 1.9957 - val_accuracy: 0.1000 - val_loss: 7.8796 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.3456 - loss: 1.9011\n",
            "Epoch 5: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 237ms/step - accuracy: 0.3443 - loss: 1.9017 - val_accuracy: 0.1000 - val_loss: 9.5571 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.3826 - loss: 1.8032\n",
            "Epoch 6: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - accuracy: 0.3824 - loss: 1.8035 - val_accuracy: 0.1000 - val_loss: 10.1160 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.3710 - loss: 1.7772\n",
            "Epoch 7: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - accuracy: 0.3714 - loss: 1.7766 - val_accuracy: 0.1000 - val_loss: 12.1646 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.3914 - loss: 1.7300\n",
            "Epoch 8: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - accuracy: 0.3918 - loss: 1.7301 - val_accuracy: 0.1000 - val_loss: 13.7054 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.4067 - loss: 1.7048\n",
            "Epoch 9: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 202ms/step - accuracy: 0.4074 - loss: 1.7040 - val_accuracy: 0.1000 - val_loss: 15.5781 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.4319 - loss: 1.6170\n",
            "Epoch 10: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.4315 - loss: 1.6181 - val_accuracy: 0.1000 - val_loss: 18.3360 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.4271 - loss: 1.5650\n",
            "Epoch 11: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 183ms/step - accuracy: 0.4273 - loss: 1.5648 - val_accuracy: 0.1000 - val_loss: 17.3657 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.4741 - loss: 1.5085\n",
            "Epoch 12: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 255ms/step - accuracy: 0.4738 - loss: 1.5094 - val_accuracy: 0.1000 - val_loss: 19.8091 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.4494 - loss: 1.5325\n",
            "Epoch 13: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 0.4495 - loss: 1.5327 - val_accuracy: 0.1000 - val_loss: 18.9287 - learning_rate: 0.0010\n",
            "Epoch 14/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.4770 - loss: 1.5114\n",
            "Epoch 14: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 217ms/step - accuracy: 0.4772 - loss: 1.5101 - val_accuracy: 0.1000 - val_loss: 22.5116 - learning_rate: 0.0010\n",
            "Epoch 15/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5190 - loss: 1.3831\n",
            "Epoch 15: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 266ms/step - accuracy: 0.5182 - loss: 1.3848 - val_accuracy: 0.1000 - val_loss: 22.4287 - learning_rate: 0.0010\n",
            "Epoch 16/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.5106 - loss: 1.4393\n",
            "Epoch 16: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.5106 - loss: 1.4390 - val_accuracy: 0.1000 - val_loss: 22.5577 - learning_rate: 0.0010\n",
            "Epoch 17/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.4859 - loss: 1.3888\n",
            "Epoch 17: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 248ms/step - accuracy: 0.4860 - loss: 1.3892 - val_accuracy: 0.1000 - val_loss: 24.9526 - learning_rate: 0.0010\n",
            "Epoch 18/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.4720 - loss: 1.4619\n",
            "Epoch 18: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.4723 - loss: 1.4607 - val_accuracy: 0.1000 - val_loss: 21.0906 - learning_rate: 0.0010\n",
            "Epoch 19/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.4950 - loss: 1.3541\n",
            "Epoch 19: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.4959 - loss: 1.3538 - val_accuracy: 0.1000 - val_loss: 22.5956 - learning_rate: 0.0010\n",
            "Epoch 20/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.5454 - loss: 1.3251\n",
            "Epoch 20: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 0.5448 - loss: 1.3255 - val_accuracy: 0.1000 - val_loss: 25.8971 - learning_rate: 0.0010\n",
            "Epoch 21/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.5545 - loss: 1.3020\n",
            "Epoch 21: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step - accuracy: 0.5531 - loss: 1.3035 - val_accuracy: 0.1000 - val_loss: 24.4990 - learning_rate: 0.0010\n",
            "Epoch 22/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.5569 - loss: 1.2994\n",
            "Epoch 22: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.5566 - loss: 1.2996 - val_accuracy: 0.1000 - val_loss: 22.2310 - learning_rate: 0.0010\n",
            "Epoch 23/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.5769 - loss: 1.2628\n",
            "Epoch 23: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.5765 - loss: 1.2623 - val_accuracy: 0.1000 - val_loss: 25.6098 - learning_rate: 0.0010\n",
            "Epoch 24/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.5757 - loss: 1.2225\n",
            "Epoch 24: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.5756 - loss: 1.2222 - val_accuracy: 0.1000 - val_loss: 26.2571 - learning_rate: 0.0010\n",
            "Epoch 25/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.5696 - loss: 1.2208\n",
            "Epoch 25: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 240ms/step - accuracy: 0.5694 - loss: 1.2209 - val_accuracy: 0.1000 - val_loss: 24.6489 - learning_rate: 0.0010\n",
            "Epoch 26/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.5818 - loss: 1.2203\n",
            "Epoch 26: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 245ms/step - accuracy: 0.5811 - loss: 1.2203 - val_accuracy: 0.1000 - val_loss: 20.8521 - learning_rate: 0.0010\n",
            "Epoch 27/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.6018 - loss: 1.1773\n",
            "Epoch 27: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.6022 - loss: 1.1761 - val_accuracy: 0.1000 - val_loss: 26.0063 - learning_rate: 0.0010\n",
            "Epoch 28/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.5822 - loss: 1.2105\n",
            "Epoch 28: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - accuracy: 0.5815 - loss: 1.2104 - val_accuracy: 0.1000 - val_loss: 26.6308 - learning_rate: 0.0010\n",
            "Epoch 29/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.6173 - loss: 1.1344\n",
            "Epoch 29: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - accuracy: 0.6169 - loss: 1.1338 - val_accuracy: 0.1000 - val_loss: 22.5861 - learning_rate: 0.0010\n",
            "Epoch 30/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6083 - loss: 1.0946\n",
            "Epoch 30: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 257ms/step - accuracy: 0.6085 - loss: 1.0944 - val_accuracy: 0.1000 - val_loss: 22.7916 - learning_rate: 0.0010\n",
            "Epoch 31/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.5864 - loss: 1.1119\n",
            "Epoch 31: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 187ms/step - accuracy: 0.5872 - loss: 1.1111 - val_accuracy: 0.1000 - val_loss: 23.8768 - learning_rate: 0.0010\n",
            "Epoch 32/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.6418 - loss: 1.0821\n",
            "Epoch 32: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.6415 - loss: 1.0814 - val_accuracy: 0.1000 - val_loss: 25.8352 - learning_rate: 0.0010\n",
            "Epoch 33/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.6421 - loss: 1.0155\n",
            "Epoch 33: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.6415 - loss: 1.0155 - val_accuracy: 0.1000 - val_loss: 26.9201 - learning_rate: 0.0010\n",
            "Epoch 34/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6693 - loss: 0.9803\n",
            "Epoch 34: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 269ms/step - accuracy: 0.6690 - loss: 0.9798 - val_accuracy: 0.1000 - val_loss: 28.2394 - learning_rate: 0.0010\n",
            "Epoch 35/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.6701 - loss: 0.9764\n",
            "Epoch 35: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 206ms/step - accuracy: 0.6696 - loss: 0.9762 - val_accuracy: 0.1000 - val_loss: 25.2909 - learning_rate: 0.0010\n",
            "Epoch 36/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6932 - loss: 0.9171\n",
            "Epoch 36: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 268ms/step - accuracy: 0.6928 - loss: 0.9180 - val_accuracy: 0.1000 - val_loss: 25.7682 - learning_rate: 0.0010\n",
            "Epoch 37/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7312 - loss: 0.8534\n",
            "Epoch 37: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.7302 - loss: 0.8548 - val_accuracy: 0.1000 - val_loss: 25.4048 - learning_rate: 0.0010\n",
            "Epoch 38/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6920 - loss: 0.9248\n",
            "Epoch 38: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 272ms/step - accuracy: 0.6925 - loss: 0.9236 - val_accuracy: 0.1000 - val_loss: 22.6095 - learning_rate: 0.0010\n",
            "Epoch 39/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7227 - loss: 0.8163\n",
            "Epoch 39: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.7226 - loss: 0.8172 - val_accuracy: 0.1000 - val_loss: 30.7101 - learning_rate: 0.0010\n",
            "Epoch 40/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7710 - loss: 0.7508\n",
            "Epoch 40: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - accuracy: 0.7705 - loss: 0.7521 - val_accuracy: 0.1000 - val_loss: 26.2673 - learning_rate: 0.0010\n",
            "Epoch 41/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7416 - loss: 0.7711\n",
            "Epoch 41: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 250ms/step - accuracy: 0.7418 - loss: 0.7717 - val_accuracy: 0.1000 - val_loss: 24.4671 - learning_rate: 0.0010\n",
            "Epoch 42/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7760 - loss: 0.7013\n",
            "Epoch 42: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.7763 - loss: 0.7009 - val_accuracy: 0.1000 - val_loss: 22.1904 - learning_rate: 0.0010\n",
            "Epoch 43/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8077 - loss: 0.6339\n",
            "Epoch 43: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.8073 - loss: 0.6345 - val_accuracy: 0.1000 - val_loss: 22.9858 - learning_rate: 0.0010\n",
            "Epoch 44/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7543 - loss: 0.7385\n",
            "Epoch 44: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 278ms/step - accuracy: 0.7547 - loss: 0.7367 - val_accuracy: 0.1000 - val_loss: 18.1276 - learning_rate: 0.0010\n",
            "Epoch 45/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8051 - loss: 0.5984\n",
            "Epoch 45: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - accuracy: 0.8054 - loss: 0.5977 - val_accuracy: 0.1000 - val_loss: 20.4864 - learning_rate: 0.0010\n",
            "Epoch 46/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8418 - loss: 0.5492\n",
            "Epoch 46: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.8418 - loss: 0.5496 - val_accuracy: 0.1000 - val_loss: 20.5362 - learning_rate: 0.0010\n",
            "Epoch 47/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.8437 - loss: 0.5035\n",
            "Epoch 47: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.8437 - loss: 0.5036 - val_accuracy: 0.1000 - val_loss: 16.0204 - learning_rate: 0.0010\n",
            "Epoch 48/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8516 - loss: 0.5256\n",
            "Epoch 48: val_accuracy improved from 0.10000 to 0.14000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 244ms/step - accuracy: 0.8517 - loss: 0.5255 - val_accuracy: 0.1400 - val_loss: 12.7060 - learning_rate: 0.0010\n",
            "Epoch 49/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.8025 - loss: 0.5984\n",
            "Epoch 49: val_accuracy did not improve from 0.14000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 219ms/step - accuracy: 0.8026 - loss: 0.5978 - val_accuracy: 0.1050 - val_loss: 13.1082 - learning_rate: 0.0010\n",
            "Epoch 50/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.8248 - loss: 0.5263\n",
            "Epoch 50: val_accuracy improved from 0.14000 to 0.18000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 282ms/step - accuracy: 0.8254 - loss: 0.5262 - val_accuracy: 0.1800 - val_loss: 9.1231 - learning_rate: 0.0010\n",
            "Epoch 51/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8808 - loss: 0.4198\n",
            "Epoch 51: val_accuracy improved from 0.18000 to 0.21500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - accuracy: 0.8800 - loss: 0.4207 - val_accuracy: 0.2150 - val_loss: 8.0485 - learning_rate: 0.0010\n",
            "Epoch 52/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9034 - loss: 0.3862\n",
            "Epoch 52: val_accuracy did not improve from 0.21500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - accuracy: 0.9033 - loss: 0.3863 - val_accuracy: 0.1700 - val_loss: 9.0625 - learning_rate: 0.0010\n",
            "Epoch 53/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9147 - loss: 0.3578\n",
            "Epoch 53: val_accuracy did not improve from 0.21500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.9143 - loss: 0.3584 - val_accuracy: 0.1500 - val_loss: 9.4394 - learning_rate: 0.0010\n",
            "Epoch 54/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9125 - loss: 0.3399\n",
            "Epoch 54: val_accuracy improved from 0.21500 to 0.26000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 265ms/step - accuracy: 0.9121 - loss: 0.3405 - val_accuracy: 0.2600 - val_loss: 6.0107 - learning_rate: 0.0010\n",
            "Epoch 55/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9114 - loss: 0.3263\n",
            "Epoch 55: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - accuracy: 0.9116 - loss: 0.3267 - val_accuracy: 0.2550 - val_loss: 7.0088 - learning_rate: 0.0010\n",
            "Epoch 56/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9048 - loss: 0.3311\n",
            "Epoch 56: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 253ms/step - accuracy: 0.9052 - loss: 0.3310 - val_accuracy: 0.2550 - val_loss: 5.5172 - learning_rate: 0.0010\n",
            "Epoch 57/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9030 - loss: 0.3205\n",
            "Epoch 57: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - accuracy: 0.9035 - loss: 0.3197 - val_accuracy: 0.1800 - val_loss: 9.9925 - learning_rate: 0.0010\n",
            "Epoch 58/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9220 - loss: 0.3050\n",
            "Epoch 58: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - accuracy: 0.9212 - loss: 0.3062 - val_accuracy: 0.1800 - val_loss: 7.2664 - learning_rate: 0.0010\n",
            "Epoch 59/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.8927 - loss: 0.3306\n",
            "Epoch 59: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 264ms/step - accuracy: 0.8932 - loss: 0.3301 - val_accuracy: 0.2250 - val_loss: 8.7231 - learning_rate: 0.0010\n",
            "Epoch 60/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8888 - loss: 0.3626\n",
            "Epoch 60: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 202ms/step - accuracy: 0.8891 - loss: 0.3620 - val_accuracy: 0.2250 - val_loss: 9.2588 - learning_rate: 0.0010\n",
            "Epoch 61/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9219 - loss: 0.2560\n",
            "Epoch 61: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.9221 - loss: 0.2562 - val_accuracy: 0.2100 - val_loss: 10.0981 - learning_rate: 0.0010\n",
            "Epoch 62/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9327 - loss: 0.2533\n",
            "Epoch 62: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 266ms/step - accuracy: 0.9328 - loss: 0.2532 - val_accuracy: 0.2100 - val_loss: 7.8922 - learning_rate: 0.0010\n",
            "Epoch 63/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9283 - loss: 0.2467\n",
            "Epoch 63: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 205ms/step - accuracy: 0.9284 - loss: 0.2467 - val_accuracy: 0.2550 - val_loss: 10.0492 - learning_rate: 0.0010\n",
            "Epoch 64/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9481 - loss: 0.2087\n",
            "Epoch 64: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 192ms/step - accuracy: 0.9474 - loss: 0.2099 - val_accuracy: 0.2550 - val_loss: 9.5084 - learning_rate: 0.0010\n",
            "Epoch 65/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9460 - loss: 0.2103\n",
            "Epoch 65: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - accuracy: 0.9456 - loss: 0.2108 - val_accuracy: 0.2400 - val_loss: 10.1425 - learning_rate: 0.0010\n",
            "Epoch 66/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9503 - loss: 0.2269\n",
            "Epoch 66: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - accuracy: 0.9501 - loss: 0.2269 - val_accuracy: 0.1750 - val_loss: 10.5136 - learning_rate: 0.0010\n",
            "Epoch 67/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9421 - loss: 0.2054\n",
            "Epoch 67: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.9419 - loss: 0.2063 - val_accuracy: 0.2350 - val_loss: 11.4825 - learning_rate: 0.0010\n",
            "Epoch 68/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9485 - loss: 0.2134\n",
            "Epoch 68: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - accuracy: 0.9482 - loss: 0.2136 - val_accuracy: 0.1700 - val_loss: 12.6582 - learning_rate: 0.0010\n",
            "Epoch 69/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9532 - loss: 0.1856\n",
            "Epoch 69: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 301ms/step - accuracy: 0.9529 - loss: 0.1865 - val_accuracy: 0.1700 - val_loss: 11.7636 - learning_rate: 0.0010\n",
            "Epoch 70/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9395 - loss: 0.2291\n",
            "Epoch 70: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.9393 - loss: 0.2290 - val_accuracy: 0.2150 - val_loss: 9.9139 - learning_rate: 0.0010\n",
            "Epoch 71/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9512 - loss: 0.2192\n",
            "Epoch 71: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.9511 - loss: 0.2185 - val_accuracy: 0.1550 - val_loss: 11.0594 - learning_rate: 0.0010\n",
            "Epoch 72/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9479 - loss: 0.1815\n",
            "Epoch 72: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - accuracy: 0.9481 - loss: 0.1811 - val_accuracy: 0.1800 - val_loss: 10.1504 - learning_rate: 0.0010\n",
            "Epoch 73/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9360 - loss: 0.2082\n",
            "Epoch 73: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - accuracy: 0.9362 - loss: 0.2077 - val_accuracy: 0.2500 - val_loss: 8.5012 - learning_rate: 0.0010\n",
            "Epoch 74/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9619 - loss: 0.1501\n",
            "Epoch 74: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 267ms/step - accuracy: 0.9618 - loss: 0.1503 - val_accuracy: 0.2000 - val_loss: 9.1511 - learning_rate: 0.0010\n",
            "Epoch 75/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9328 - loss: 0.1868\n",
            "Epoch 75: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.9335 - loss: 0.1854 - val_accuracy: 0.1800 - val_loss: 10.1558 - learning_rate: 0.0010\n",
            "Epoch 76/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9592 - loss: 0.1545\n",
            "Epoch 76: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 232ms/step - accuracy: 0.9586 - loss: 0.1557 - val_accuracy: 0.2150 - val_loss: 10.9255 - learning_rate: 0.0010\n",
            "Epoch 77/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9719 - loss: 0.1350\n",
            "Epoch 77: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 248ms/step - accuracy: 0.9718 - loss: 0.1350 - val_accuracy: 0.2400 - val_loss: 8.3004 - learning_rate: 0.0010\n",
            "Epoch 78/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9737 - loss: 0.1263\n",
            "Epoch 78: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.9738 - loss: 0.1264 - val_accuracy: 0.2000 - val_loss: 8.6693 - learning_rate: 0.0010\n",
            "Epoch 79/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9677 - loss: 0.1073\n",
            "Epoch 79: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - accuracy: 0.9676 - loss: 0.1079 - val_accuracy: 0.1800 - val_loss: 10.1519 - learning_rate: 0.0010\n",
            "Epoch 80/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9400 - loss: 0.2018\n",
            "Epoch 80: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.9401 - loss: 0.2012 - val_accuracy: 0.1500 - val_loss: 9.9244 - learning_rate: 0.0010\n",
            "Epoch 81/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9668 - loss: 0.1275\n",
            "Epoch 81: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 244ms/step - accuracy: 0.9665 - loss: 0.1277 - val_accuracy: 0.1700 - val_loss: 10.5886 - learning_rate: 0.0010\n",
            "Epoch 82/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9552 - loss: 0.1515\n",
            "Epoch 82: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - accuracy: 0.9552 - loss: 0.1516 - val_accuracy: 0.2050 - val_loss: 9.2684 - learning_rate: 0.0010\n",
            "Epoch 83/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9818 - loss: 0.0863\n",
            "Epoch 83: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 240ms/step - accuracy: 0.9817 - loss: 0.0863 - val_accuracy: 0.1950 - val_loss: 10.0016 - learning_rate: 0.0010\n",
            "Epoch 84/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9797 - loss: 0.1059\n",
            "Epoch 84: val_accuracy did not improve from 0.26000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 191ms/step - accuracy: 0.9795 - loss: 0.1058 - val_accuracy: 0.2100 - val_loss: 8.1366 - learning_rate: 0.0010\n",
            "Epoch 85/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9848 - loss: 0.1035\n",
            "Epoch 85: val_accuracy improved from 0.26000 to 0.26500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 298ms/step - accuracy: 0.9845 - loss: 0.1041 - val_accuracy: 0.2650 - val_loss: 6.4167 - learning_rate: 0.0010\n",
            "Epoch 86/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9824 - loss: 0.0809\n",
            "Epoch 86: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.9823 - loss: 0.0812 - val_accuracy: 0.2200 - val_loss: 9.1635 - learning_rate: 0.0010\n",
            "Epoch 87/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9764 - loss: 0.1121\n",
            "Epoch 87: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 219ms/step - accuracy: 0.9763 - loss: 0.1121 - val_accuracy: 0.1700 - val_loss: 9.7349 - learning_rate: 0.0010\n",
            "Epoch 88/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9809 - loss: 0.1027\n",
            "Epoch 88: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.9809 - loss: 0.1024 - val_accuracy: 0.2150 - val_loss: 7.4708 - learning_rate: 0.0010\n",
            "Epoch 89/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9742 - loss: 0.1030\n",
            "Epoch 89: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 261ms/step - accuracy: 0.9745 - loss: 0.1021 - val_accuracy: 0.2100 - val_loss: 6.9632 - learning_rate: 0.0010\n",
            "Epoch 90/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9839 - loss: 0.0770\n",
            "Epoch 90: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - accuracy: 0.9837 - loss: 0.0773 - val_accuracy: 0.2300 - val_loss: 5.5180 - learning_rate: 0.0010\n",
            "Epoch 91/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9778 - loss: 0.0703\n",
            "Epoch 91: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9780 - loss: 0.0702 - val_accuracy: 0.2150 - val_loss: 6.5360 - learning_rate: 0.0010\n",
            "Epoch 92/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9836 - loss: 0.0711\n",
            "Epoch 92: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - accuracy: 0.9834 - loss: 0.0713 - val_accuracy: 0.1900 - val_loss: 7.7303 - learning_rate: 0.0010\n",
            "Epoch 93/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9895 - loss: 0.0634\n",
            "Epoch 93: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 265ms/step - accuracy: 0.9894 - loss: 0.0638 - val_accuracy: 0.2350 - val_loss: 6.0636 - learning_rate: 0.0010\n",
            "Epoch 94/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9888 - loss: 0.0618\n",
            "Epoch 94: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.9890 - loss: 0.0615 - val_accuracy: 0.2200 - val_loss: 6.9791 - learning_rate: 0.0010\n",
            "Epoch 95/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9840 - loss: 0.0617\n",
            "Epoch 95: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 216ms/step - accuracy: 0.9838 - loss: 0.0625 - val_accuracy: 0.1750 - val_loss: 7.2933 - learning_rate: 0.0010\n",
            "Epoch 96/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9862 - loss: 0.0676\n",
            "Epoch 96: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 235ms/step - accuracy: 0.9858 - loss: 0.0682 - val_accuracy: 0.1950 - val_loss: 7.2459 - learning_rate: 0.0010\n",
            "Epoch 97/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9469 - loss: 0.1547\n",
            "Epoch 97: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - accuracy: 0.9474 - loss: 0.1534 - val_accuracy: 0.1800 - val_loss: 7.8463 - learning_rate: 0.0010\n",
            "Epoch 98/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9619 - loss: 0.0935\n",
            "Epoch 98: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 309ms/step - accuracy: 0.9620 - loss: 0.0937 - val_accuracy: 0.1900 - val_loss: 6.8106 - learning_rate: 0.0010\n",
            "Epoch 99/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.9757 - loss: 0.1023\n",
            "Epoch 99: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 184ms/step - accuracy: 0.9757 - loss: 0.1020 - val_accuracy: 0.1350 - val_loss: 8.9413 - learning_rate: 0.0010\n",
            "Epoch 100/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9832 - loss: 0.0634\n",
            "Epoch 100: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 309ms/step - accuracy: 0.9832 - loss: 0.0637 - val_accuracy: 0.1650 - val_loss: 8.2605 - learning_rate: 0.0010\n",
            "Epoch 101/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9895 - loss: 0.0582\n",
            "Epoch 101: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - accuracy: 0.9893 - loss: 0.0588 - val_accuracy: 0.1900 - val_loss: 7.2525 - learning_rate: 0.0010\n",
            "Epoch 102/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9792 - loss: 0.0830\n",
            "Epoch 102: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - accuracy: 0.9792 - loss: 0.0832 - val_accuracy: 0.1900 - val_loss: 8.0869 - learning_rate: 0.0010\n",
            "Epoch 103/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9563 - loss: 0.1140\n",
            "Epoch 103: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - accuracy: 0.9565 - loss: 0.1140 - val_accuracy: 0.2450 - val_loss: 6.6751 - learning_rate: 0.0010\n",
            "Epoch 104/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9755 - loss: 0.0947\n",
            "Epoch 104: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 236ms/step - accuracy: 0.9756 - loss: 0.0945 - val_accuracy: 0.2000 - val_loss: 8.5142 - learning_rate: 0.0010\n",
            "Epoch 105/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9698 - loss: 0.0969\n",
            "Epoch 105: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - accuracy: 0.9700 - loss: 0.0964 - val_accuracy: 0.1800 - val_loss: 8.0366 - learning_rate: 0.0010\n",
            "Epoch 106/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9783 - loss: 0.0829\n",
            "Epoch 106: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.9779 - loss: 0.0837 - val_accuracy: 0.2400 - val_loss: 4.9012 - learning_rate: 0.0010\n",
            "Epoch 107/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9819 - loss: 0.0764\n",
            "Epoch 107: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - accuracy: 0.9817 - loss: 0.0765 - val_accuracy: 0.1600 - val_loss: 6.0300 - learning_rate: 0.0010\n",
            "Epoch 108/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9836 - loss: 0.0642\n",
            "Epoch 108: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - accuracy: 0.9836 - loss: 0.0643 - val_accuracy: 0.1900 - val_loss: 4.9206 - learning_rate: 0.0010\n",
            "Epoch 109/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9869 - loss: 0.0597\n",
            "Epoch 109: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9865 - loss: 0.0601 - val_accuracy: 0.2250 - val_loss: 5.5886 - learning_rate: 0.0010\n",
            "Epoch 110/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.9738 - loss: 0.0950\n",
            "Epoch 110: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 206ms/step - accuracy: 0.9739 - loss: 0.0949 - val_accuracy: 0.1500 - val_loss: 5.5326 - learning_rate: 0.0010\n",
            "Epoch 111/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9819 - loss: 0.0832\n",
            "Epoch 111: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 184ms/step - accuracy: 0.9822 - loss: 0.0825 - val_accuracy: 0.2200 - val_loss: 3.8709 - learning_rate: 0.0010\n",
            "Epoch 112/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9926 - loss: 0.0437\n",
            "Epoch 112: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - accuracy: 0.9926 - loss: 0.0437 - val_accuracy: 0.2450 - val_loss: 4.1758 - learning_rate: 0.0010\n",
            "Epoch 113/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9897 - loss: 0.0436\n",
            "Epoch 113: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 187ms/step - accuracy: 0.9897 - loss: 0.0437 - val_accuracy: 0.2400 - val_loss: 4.6166 - learning_rate: 0.0010\n",
            "Epoch 114/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9723 - loss: 0.0787\n",
            "Epoch 114: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 248ms/step - accuracy: 0.9726 - loss: 0.0784 - val_accuracy: 0.1900 - val_loss: 5.4336 - learning_rate: 0.0010\n",
            "Epoch 115/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9778 - loss: 0.0687\n",
            "Epoch 115: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - accuracy: 0.9779 - loss: 0.0685 - val_accuracy: 0.2100 - val_loss: 5.8432 - learning_rate: 0.0010\n",
            "Epoch 116/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9656 - loss: 0.1219\n",
            "Epoch 116: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - accuracy: 0.9663 - loss: 0.1201 - val_accuracy: 0.2200 - val_loss: 7.8370 - learning_rate: 0.0010\n",
            "Epoch 117/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.9852 - loss: 0.0612\n",
            "Epoch 117: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.9853 - loss: 0.0609 - val_accuracy: 0.2200 - val_loss: 6.2871 - learning_rate: 0.0010\n",
            "Epoch 118/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9886 - loss: 0.0396\n",
            "Epoch 118: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.9886 - loss: 0.0398 - val_accuracy: 0.2500 - val_loss: 5.8403 - learning_rate: 0.0010\n",
            "Epoch 119/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9916 - loss: 0.0406\n",
            "Epoch 119: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 183ms/step - accuracy: 0.9914 - loss: 0.0408 - val_accuracy: 0.2500 - val_loss: 5.1046 - learning_rate: 0.0010\n",
            "Epoch 120/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.9816 - loss: 0.0775\n",
            "Epoch 120: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 254ms/step - accuracy: 0.9816 - loss: 0.0771 - val_accuracy: 0.2650 - val_loss: 6.5732 - learning_rate: 0.0010\n",
            "Epoch 121/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9765 - loss: 0.0847\n",
            "Epoch 121: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 185ms/step - accuracy: 0.9766 - loss: 0.0840 - val_accuracy: 0.1950 - val_loss: 8.7398 - learning_rate: 0.0010\n",
            "Epoch 122/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9730 - loss: 0.0756\n",
            "Epoch 122: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.9734 - loss: 0.0748 - val_accuracy: 0.1900 - val_loss: 8.7143 - learning_rate: 0.0010\n",
            "Epoch 123/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9918 - loss: 0.0422\n",
            "Epoch 123: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.9918 - loss: 0.0422 - val_accuracy: 0.2250 - val_loss: 6.2158 - learning_rate: 0.0010\n",
            "Epoch 124/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9896 - loss: 0.0512\n",
            "Epoch 124: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - accuracy: 0.9898 - loss: 0.0506 - val_accuracy: 0.2050 - val_loss: 6.8873 - learning_rate: 0.0010\n",
            "Epoch 125/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9945 - loss: 0.0340\n",
            "Epoch 125: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 270ms/step - accuracy: 0.9945 - loss: 0.0341 - val_accuracy: 0.2200 - val_loss: 6.5986 - learning_rate: 0.0010\n",
            "Epoch 126/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9959 - loss: 0.0284\n",
            "Epoch 126: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - accuracy: 0.9958 - loss: 0.0284 - val_accuracy: 0.2300 - val_loss: 7.0801 - learning_rate: 0.0010\n",
            "Epoch 127/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9965 - loss: 0.0225\n",
            "Epoch 127: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 259ms/step - accuracy: 0.9965 - loss: 0.0226 - val_accuracy: 0.2250 - val_loss: 7.7862 - learning_rate: 0.0010\n",
            "Epoch 128/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9942 - loss: 0.0301\n",
            "Epoch 128: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.9941 - loss: 0.0303 - val_accuracy: 0.2200 - val_loss: 6.6070 - learning_rate: 0.0010\n",
            "Epoch 129/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9925 - loss: 0.0356\n",
            "Epoch 129: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.9926 - loss: 0.0353 - val_accuracy: 0.2200 - val_loss: 7.8163 - learning_rate: 0.0010\n",
            "Epoch 130/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9869 - loss: 0.0438\n",
            "Epoch 130: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 185ms/step - accuracy: 0.9872 - loss: 0.0432 - val_accuracy: 0.2350 - val_loss: 6.5488 - learning_rate: 0.0010\n",
            "Epoch 131/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9904 - loss: 0.0366\n",
            "Epoch 131: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step - accuracy: 0.9905 - loss: 0.0365 - val_accuracy: 0.2200 - val_loss: 6.7268 - learning_rate: 0.0010\n",
            "Epoch 132/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9930 - loss: 0.0351\n",
            "Epoch 132: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 189ms/step - accuracy: 0.9930 - loss: 0.0352 - val_accuracy: 0.2400 - val_loss: 6.9980 - learning_rate: 0.0010\n",
            "Epoch 133/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9983 - loss: 0.0244\n",
            "Epoch 133: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 256ms/step - accuracy: 0.9982 - loss: 0.0246 - val_accuracy: 0.2300 - val_loss: 6.0144 - learning_rate: 0.0010\n",
            "Epoch 134/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9834 - loss: 0.0503\n",
            "Epoch 134: val_accuracy did not improve from 0.26500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 190ms/step - accuracy: 0.9836 - loss: 0.0500 - val_accuracy: 0.2150 - val_loss: 5.0466 - learning_rate: 0.0010\n",
            "Epoch 135/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9857 - loss: 0.0539\n",
            "Epoch 135: val_accuracy improved from 0.26500 to 0.27000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_2/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 302ms/step - accuracy: 0.9859 - loss: 0.0535 - val_accuracy: 0.2700 - val_loss: 5.3585 - learning_rate: 0.0010\n",
            "Epoch 136/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9932 - loss: 0.0288\n",
            "Epoch 136: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 190ms/step - accuracy: 0.9933 - loss: 0.0288 - val_accuracy: 0.2650 - val_loss: 4.9111 - learning_rate: 0.0010\n",
            "Epoch 137/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9888 - loss: 0.0277\n",
            "Epoch 137: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 259ms/step - accuracy: 0.9889 - loss: 0.0276 - val_accuracy: 0.2400 - val_loss: 5.6313 - learning_rate: 0.0010\n",
            "Epoch 138/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9883 - loss: 0.0378\n",
            "Epoch 138: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - accuracy: 0.9884 - loss: 0.0376 - val_accuracy: 0.2150 - val_loss: 7.0823 - learning_rate: 0.0010\n",
            "Epoch 139/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9903 - loss: 0.0384\n",
            "Epoch 139: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.9903 - loss: 0.0385 - val_accuracy: 0.1750 - val_loss: 8.7972 - learning_rate: 0.0010\n",
            "Epoch 140/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9840 - loss: 0.0616\n",
            "Epoch 140: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.9841 - loss: 0.0614 - val_accuracy: 0.2250 - val_loss: 6.4654 - learning_rate: 0.0010\n",
            "Epoch 141/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9833 - loss: 0.0511\n",
            "Epoch 141: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 188ms/step - accuracy: 0.9835 - loss: 0.0507 - val_accuracy: 0.1750 - val_loss: 9.1831 - learning_rate: 0.0010\n",
            "Epoch 142/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9820 - loss: 0.0573\n",
            "Epoch 142: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 269ms/step - accuracy: 0.9821 - loss: 0.0571 - val_accuracy: 0.1850 - val_loss: 8.4166 - learning_rate: 0.0010\n",
            "Epoch 143/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9830 - loss: 0.0584\n",
            "Epoch 143: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.9831 - loss: 0.0581 - val_accuracy: 0.1800 - val_loss: 8.9752 - learning_rate: 0.0010\n",
            "Epoch 144/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9746 - loss: 0.0823\n",
            "Epoch 144: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - accuracy: 0.9747 - loss: 0.0818 - val_accuracy: 0.1750 - val_loss: 11.5717 - learning_rate: 0.0010\n",
            "Epoch 145/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9795 - loss: 0.0657\n",
            "Epoch 145: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 259ms/step - accuracy: 0.9795 - loss: 0.0658 - val_accuracy: 0.1550 - val_loss: 10.3915 - learning_rate: 0.0010\n",
            "Epoch 146/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9652 - loss: 0.0835\n",
            "Epoch 146: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.9654 - loss: 0.0832 - val_accuracy: 0.2350 - val_loss: 9.0004 - learning_rate: 0.0010\n",
            "Epoch 147/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9861 - loss: 0.0667\n",
            "Epoch 147: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - accuracy: 0.9860 - loss: 0.0668 - val_accuracy: 0.2250 - val_loss: 7.5751 - learning_rate: 0.0010\n",
            "Epoch 148/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9794 - loss: 0.0663\n",
            "Epoch 148: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - accuracy: 0.9792 - loss: 0.0669 - val_accuracy: 0.1650 - val_loss: 9.2871 - learning_rate: 0.0010\n",
            "Epoch 149/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9831 - loss: 0.0623\n",
            "Epoch 149: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 310ms/step - accuracy: 0.9830 - loss: 0.0627 - val_accuracy: 0.1900 - val_loss: 7.5489 - learning_rate: 0.0010\n",
            "Epoch 150/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9624 - loss: 0.0825\n",
            "Epoch 150: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 214ms/step - accuracy: 0.9625 - loss: 0.0823 - val_accuracy: 0.1550 - val_loss: 7.9499 - learning_rate: 0.0010\n",
            "Epoch 151/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9771 - loss: 0.0700\n",
            "Epoch 151: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 272ms/step - accuracy: 0.9773 - loss: 0.0694 - val_accuracy: 0.1650 - val_loss: 9.7382 - learning_rate: 0.0010\n",
            "Epoch 152/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9895 - loss: 0.0392\n",
            "Epoch 152: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.9894 - loss: 0.0395 - val_accuracy: 0.1900 - val_loss: 8.7550 - learning_rate: 0.0010\n",
            "Epoch 153/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9936 - loss: 0.0365\n",
            "Epoch 153: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step - accuracy: 0.9934 - loss: 0.0368 - val_accuracy: 0.2050 - val_loss: 7.6733 - learning_rate: 0.0010\n",
            "Epoch 154/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9838 - loss: 0.0431\n",
            "Epoch 154: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.9839 - loss: 0.0430 - val_accuracy: 0.2450 - val_loss: 6.9867 - learning_rate: 0.0010\n",
            "Epoch 155/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9875 - loss: 0.0444\n",
            "Epoch 155: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - accuracy: 0.9876 - loss: 0.0442 - val_accuracy: 0.2150 - val_loss: 8.0153 - learning_rate: 0.0010\n",
            "Epoch 156/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9821 - loss: 0.0511\n",
            "Epoch 156: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 0.9823 - loss: 0.0509 - val_accuracy: 0.2250 - val_loss: 8.6579 - learning_rate: 0.0010\n",
            "Epoch 157/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9794 - loss: 0.0478\n",
            "Epoch 157: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.9795 - loss: 0.0479 - val_accuracy: 0.2200 - val_loss: 9.1000 - learning_rate: 0.0010\n",
            "Epoch 158/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9987 - loss: 0.0181\n",
            "Epoch 158: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 189ms/step - accuracy: 0.9986 - loss: 0.0182 - val_accuracy: 0.2050 - val_loss: 10.3594 - learning_rate: 0.0010\n",
            "Epoch 159/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9955 - loss: 0.0183\n",
            "Epoch 159: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.9954 - loss: 0.0184 - val_accuracy: 0.1650 - val_loss: 12.3502 - learning_rate: 0.0010\n",
            "Epoch 160/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9915 - loss: 0.0465\n",
            "Epoch 160: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - accuracy: 0.9913 - loss: 0.0467 - val_accuracy: 0.2550 - val_loss: 7.9614 - learning_rate: 0.0010\n",
            "Epoch 161/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.9917 - loss: 0.0344\n",
            "Epoch 161: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 312ms/step - accuracy: 0.9919 - loss: 0.0342 - val_accuracy: 0.2050 - val_loss: 9.7862 - learning_rate: 0.0010\n",
            "Epoch 162/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9953 - loss: 0.0218\n",
            "Epoch 162: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 183ms/step - accuracy: 0.9951 - loss: 0.0222 - val_accuracy: 0.2050 - val_loss: 10.1852 - learning_rate: 0.0010\n",
            "Epoch 163/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9779 - loss: 0.0615\n",
            "Epoch 163: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 261ms/step - accuracy: 0.9781 - loss: 0.0612 - val_accuracy: 0.2150 - val_loss: 10.2410 - learning_rate: 0.0010\n",
            "Epoch 164/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9947 - loss: 0.0272\n",
            "Epoch 164: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 191ms/step - accuracy: 0.9945 - loss: 0.0274 - val_accuracy: 0.2100 - val_loss: 10.2241 - learning_rate: 0.0010\n",
            "Epoch 165/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9903 - loss: 0.0398\n",
            "Epoch 165: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 273ms/step - accuracy: 0.9903 - loss: 0.0399 - val_accuracy: 0.2050 - val_loss: 12.2326 - learning_rate: 0.0010\n",
            "Epoch 166/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9836 - loss: 0.0601\n",
            "Epoch 166: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.9836 - loss: 0.0602 - val_accuracy: 0.2450 - val_loss: 8.3931 - learning_rate: 0.0010\n",
            "Epoch 167/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9915 - loss: 0.0422\n",
            "Epoch 167: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.9915 - loss: 0.0421 - val_accuracy: 0.2250 - val_loss: 11.6151 - learning_rate: 0.0010\n",
            "Epoch 168/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9899 - loss: 0.0365\n",
            "Epoch 168: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - accuracy: 0.9898 - loss: 0.0367 - val_accuracy: 0.2150 - val_loss: 11.8751 - learning_rate: 0.0010\n",
            "Epoch 169/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9898 - loss: 0.0364\n",
            "Epoch 169: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 245ms/step - accuracy: 0.9899 - loss: 0.0361 - val_accuracy: 0.2050 - val_loss: 12.0328 - learning_rate: 0.0010\n",
            "Epoch 170/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9888 - loss: 0.0344\n",
            "Epoch 170: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - accuracy: 0.9888 - loss: 0.0343 - val_accuracy: 0.1950 - val_loss: 13.6327 - learning_rate: 0.0010\n",
            "Epoch 171/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9828 - loss: 0.0509\n",
            "Epoch 171: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - accuracy: 0.9828 - loss: 0.0507 - val_accuracy: 0.2150 - val_loss: 10.5651 - learning_rate: 0.0010\n",
            "Epoch 172/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9951 - loss: 0.0308\n",
            "Epoch 172: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - accuracy: 0.9951 - loss: 0.0308 - val_accuracy: 0.2050 - val_loss: 10.2232 - learning_rate: 0.0010\n",
            "Epoch 173/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9956 - loss: 0.0214\n",
            "Epoch 173: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 309ms/step - accuracy: 0.9956 - loss: 0.0215 - val_accuracy: 0.1900 - val_loss: 11.9871 - learning_rate: 0.0010\n",
            "Epoch 174/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9885 - loss: 0.0527\n",
            "Epoch 174: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 213ms/step - accuracy: 0.9885 - loss: 0.0523 - val_accuracy: 0.2150 - val_loss: 9.8431 - learning_rate: 0.0010\n",
            "Epoch 175/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9902 - loss: 0.0351\n",
            "Epoch 175: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 249ms/step - accuracy: 0.9903 - loss: 0.0350 - val_accuracy: 0.2300 - val_loss: 8.7529 - learning_rate: 0.0010\n",
            "Epoch 176/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9837 - loss: 0.0379\n",
            "Epoch 176: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - accuracy: 0.9839 - loss: 0.0375 - val_accuracy: 0.1850 - val_loss: 10.3530 - learning_rate: 0.0010\n",
            "Epoch 177/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9922 - loss: 0.0204\n",
            "Epoch 177: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 204ms/step - accuracy: 0.9923 - loss: 0.0203 - val_accuracy: 0.1800 - val_loss: 10.4705 - learning_rate: 0.0010\n",
            "Epoch 178/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9981 - loss: 0.0147\n",
            "Epoch 178: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 188ms/step - accuracy: 0.9981 - loss: 0.0147 - val_accuracy: 0.1800 - val_loss: 9.4540 - learning_rate: 0.0010\n",
            "Epoch 179/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.9993 - loss: 0.0104\n",
            "Epoch 179: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 260ms/step - accuracy: 0.9993 - loss: 0.0105 - val_accuracy: 0.1700 - val_loss: 9.8732 - learning_rate: 0.0010\n",
            "Epoch 180/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9937 - loss: 0.0146\n",
            "Epoch 180: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - accuracy: 0.9938 - loss: 0.0145 - val_accuracy: 0.1550 - val_loss: 10.8565 - learning_rate: 0.0010\n",
            "Epoch 181/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9932 - loss: 0.0233\n",
            "Epoch 181: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - accuracy: 0.9931 - loss: 0.0235 - val_accuracy: 0.1850 - val_loss: 11.2368 - learning_rate: 0.0010\n",
            "Epoch 182/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9877 - loss: 0.0414\n",
            "Epoch 182: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 251ms/step - accuracy: 0.9878 - loss: 0.0412 - val_accuracy: 0.1850 - val_loss: 9.0223 - learning_rate: 0.0010\n",
            "Epoch 183/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9915 - loss: 0.0325\n",
            "Epoch 183: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - accuracy: 0.9916 - loss: 0.0325 - val_accuracy: 0.1950 - val_loss: 7.5907 - learning_rate: 0.0010\n",
            "Epoch 184/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9953 - loss: 0.0291\n",
            "Epoch 184: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.9952 - loss: 0.0290 - val_accuracy: 0.1750 - val_loss: 8.7361 - learning_rate: 0.0010\n",
            "Epoch 185/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9958 - loss: 0.0208\n",
            "Epoch 185: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.9957 - loss: 0.0208 - val_accuracy: 0.1550 - val_loss: 9.9866 - learning_rate: 0.0010\n",
            "Epoch 186/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9984 - loss: 0.0128\n",
            "Epoch 186: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 261ms/step - accuracy: 0.9983 - loss: 0.0131 - val_accuracy: 0.1800 - val_loss: 8.6832 - learning_rate: 0.0010\n",
            "Epoch 187/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9945 - loss: 0.0269\n",
            "Epoch 187: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - accuracy: 0.9945 - loss: 0.0267 - val_accuracy: 0.1700 - val_loss: 9.3917 - learning_rate: 0.0010\n",
            "Epoch 188/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9923 - loss: 0.0302\n",
            "Epoch 188: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 225ms/step - accuracy: 0.9921 - loss: 0.0308 - val_accuracy: 0.1500 - val_loss: 11.6560 - learning_rate: 0.0010\n",
            "Epoch 189/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9821 - loss: 0.0632\n",
            "Epoch 189: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - accuracy: 0.9821 - loss: 0.0628 - val_accuracy: 0.1300 - val_loss: 13.2921 - learning_rate: 0.0010\n",
            "Epoch 190/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9822 - loss: 0.0536\n",
            "Epoch 190: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 251ms/step - accuracy: 0.9819 - loss: 0.0547 - val_accuracy: 0.1700 - val_loss: 14.7553 - learning_rate: 0.0010\n",
            "Epoch 191/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9737 - loss: 0.0859\n",
            "Epoch 191: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 194ms/step - accuracy: 0.9738 - loss: 0.0855 - val_accuracy: 0.1900 - val_loss: 8.1563 - learning_rate: 0.0010\n",
            "Epoch 192/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9748 - loss: 0.0638\n",
            "Epoch 192: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 264ms/step - accuracy: 0.9745 - loss: 0.0645 - val_accuracy: 0.1800 - val_loss: 9.9971 - learning_rate: 0.0010\n",
            "Epoch 193/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9689 - loss: 0.0849\n",
            "Epoch 193: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - accuracy: 0.9690 - loss: 0.0848 - val_accuracy: 0.1800 - val_loss: 10.5126 - learning_rate: 0.0010\n",
            "Epoch 194/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9744 - loss: 0.0652\n",
            "Epoch 194: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 270ms/step - accuracy: 0.9744 - loss: 0.0653 - val_accuracy: 0.1650 - val_loss: 11.5272 - learning_rate: 0.0010\n",
            "Epoch 195/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9843 - loss: 0.0501\n",
            "Epoch 195: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 192ms/step - accuracy: 0.9844 - loss: 0.0503 - val_accuracy: 0.1900 - val_loss: 11.4943 - learning_rate: 0.0010\n",
            "Epoch 196/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9841 - loss: 0.0512\n",
            "Epoch 196: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 308ms/step - accuracy: 0.9843 - loss: 0.0510 - val_accuracy: 0.1800 - val_loss: 10.3761 - learning_rate: 0.0010\n",
            "Epoch 197/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9811 - loss: 0.0536\n",
            "Epoch 197: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 189ms/step - accuracy: 0.9812 - loss: 0.0534 - val_accuracy: 0.1600 - val_loss: 11.5971 - learning_rate: 0.0010\n",
            "Epoch 198/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9886 - loss: 0.0404\n",
            "Epoch 198: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 249ms/step - accuracy: 0.9884 - loss: 0.0409 - val_accuracy: 0.1750 - val_loss: 9.8683 - learning_rate: 0.0010\n",
            "Epoch 199/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9920 - loss: 0.0338\n",
            "Epoch 199: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - accuracy: 0.9918 - loss: 0.0340 - val_accuracy: 0.1700 - val_loss: 11.4542 - learning_rate: 0.0010\n",
            "Epoch 200/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9921 - loss: 0.0292\n",
            "Epoch 200: val_accuracy did not improve from 0.27000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - accuracy: 0.9920 - loss: 0.0294 - val_accuracy: 0.1800 - val_loss: 9.6409 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/model_2_mfcc.h5', save_format='h5')\n",
        "!cp /content/model_2_mfcc.h5 /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbRG1QBRQQlY",
        "outputId": "7e2a7cb2-fd1a-45bd-f6fa-58cae8bfb558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Model_3\n"
      ],
      "metadata": {
        "id": "GzSs5miH7jeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, reduce_lr, checkpoint = model_1_compile(model, checkpoint_path)\n",
        "H = model.fit(train_ds, epochs=200, validation_data=test_ds, callbacks=[checkpoint, reduce_lr])\n",
        "save_history(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AamwVmyY7mbw",
        "outputId": "c1fdd8dd-e9e5-4bfe-e5f6-60d5f921463c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.1585 - loss: 2.8087\n",
            "Epoch 1: val_accuracy improved from -inf to 0.10000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.1601 - loss: 2.7973 - val_accuracy: 0.1000 - val_loss: 49.1786 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.3244 - loss: 1.8689\n",
            "Epoch 2: val_accuracy improved from 0.10000 to 0.17000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.3249 - loss: 1.8677 - val_accuracy: 0.1700 - val_loss: 9.5001 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.4034 - loss: 1.7163\n",
            "Epoch 3: val_accuracy did not improve from 0.17000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 258ms/step - accuracy: 0.4033 - loss: 1.7155 - val_accuracy: 0.0950 - val_loss: 9.4543 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.3945 - loss: 1.7145\n",
            "Epoch 4: val_accuracy improved from 0.17000 to 0.18500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.3954 - loss: 1.7116 - val_accuracy: 0.1850 - val_loss: 4.9951 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.4319 - loss: 1.6057\n",
            "Epoch 5: val_accuracy improved from 0.18500 to 0.19000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.4319 - loss: 1.6051 - val_accuracy: 0.1900 - val_loss: 8.5245 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.4348 - loss: 1.5252\n",
            "Epoch 6: val_accuracy did not improve from 0.19000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.4346 - loss: 1.5251 - val_accuracy: 0.1350 - val_loss: 5.7814 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.4647 - loss: 1.4693\n",
            "Epoch 7: val_accuracy improved from 0.19000 to 0.21500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.4642 - loss: 1.4709 - val_accuracy: 0.2150 - val_loss: 9.0922 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.4898 - loss: 1.5201\n",
            "Epoch 8: val_accuracy improved from 0.21500 to 0.22500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.4894 - loss: 1.5189 - val_accuracy: 0.2250 - val_loss: 6.6116 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.5025 - loss: 1.3874\n",
            "Epoch 9: val_accuracy improved from 0.22500 to 0.24000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.5020 - loss: 1.3895 - val_accuracy: 0.2400 - val_loss: 6.1563 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.4886 - loss: 1.3903\n",
            "Epoch 10: val_accuracy did not improve from 0.24000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 295ms/step - accuracy: 0.4874 - loss: 1.3920 - val_accuracy: 0.2000 - val_loss: 5.0173 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5117 - loss: 1.3498\n",
            "Epoch 11: val_accuracy improved from 0.24000 to 0.31000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.5117 - loss: 1.3492 - val_accuracy: 0.3100 - val_loss: 2.2492 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.4995 - loss: 1.3109\n",
            "Epoch 12: val_accuracy improved from 0.31000 to 0.37500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.4998 - loss: 1.3121 - val_accuracy: 0.3750 - val_loss: 2.1475 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.4807 - loss: 1.3712\n",
            "Epoch 13: val_accuracy did not improve from 0.37500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 253ms/step - accuracy: 0.4814 - loss: 1.3713 - val_accuracy: 0.2550 - val_loss: 9.8837 - learning_rate: 0.0010\n",
            "Epoch 14/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.4862 - loss: 1.4504\n",
            "Epoch 14: val_accuracy did not improve from 0.37500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 230ms/step - accuracy: 0.4872 - loss: 1.4476 - val_accuracy: 0.3600 - val_loss: 1.9951 - learning_rate: 0.0010\n",
            "Epoch 15/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.5503 - loss: 1.2619\n",
            "Epoch 15: val_accuracy improved from 0.37500 to 0.40000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.5497 - loss: 1.2631 - val_accuracy: 0.4000 - val_loss: 1.9276 - learning_rate: 0.0010\n",
            "Epoch 16/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5295 - loss: 1.2824\n",
            "Epoch 16: val_accuracy did not improve from 0.40000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.5295 - loss: 1.2828 - val_accuracy: 0.2450 - val_loss: 3.0746 - learning_rate: 0.0010\n",
            "Epoch 17/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.5919 - loss: 1.2032\n",
            "Epoch 17: val_accuracy did not improve from 0.40000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 314ms/step - accuracy: 0.5915 - loss: 1.2043 - val_accuracy: 0.2150 - val_loss: 6.0814 - learning_rate: 0.0010\n",
            "Epoch 18/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5633 - loss: 1.2669\n",
            "Epoch 18: val_accuracy did not improve from 0.40000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - accuracy: 0.5631 - loss: 1.2665 - val_accuracy: 0.3200 - val_loss: 2.7912 - learning_rate: 0.0010\n",
            "Epoch 19/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.5685 - loss: 1.1460\n",
            "Epoch 19: val_accuracy improved from 0.40000 to 0.42000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.5685 - loss: 1.1469 - val_accuracy: 0.4200 - val_loss: 1.7848 - learning_rate: 0.0010\n",
            "Epoch 20/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.6100 - loss: 1.1100\n",
            "Epoch 20: val_accuracy improved from 0.42000 to 0.45000, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.6093 - loss: 1.1118 - val_accuracy: 0.4500 - val_loss: 1.5829 - learning_rate: 0.0010\n",
            "Epoch 21/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.6004 - loss: 1.1011\n",
            "Epoch 21: val_accuracy did not improve from 0.45000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.5997 - loss: 1.1028 - val_accuracy: 0.3950 - val_loss: 1.7432 - learning_rate: 0.0010\n",
            "Epoch 22/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.6215 - loss: 1.0558\n",
            "Epoch 22: val_accuracy did not improve from 0.45000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 308ms/step - accuracy: 0.6209 - loss: 1.0566 - val_accuracy: 0.3900 - val_loss: 2.2501 - learning_rate: 0.0010\n",
            "Epoch 23/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.6326 - loss: 1.0407\n",
            "Epoch 23: val_accuracy improved from 0.45000 to 0.52500, saving model to /content/drive/MyDrive/GoogleCollab/Data/GTZAN/checkpoints/Model_3/best_model_original_mfcc.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.6317 - loss: 1.0409 - val_accuracy: 0.5250 - val_loss: 1.5095 - learning_rate: 0.0010\n",
            "Epoch 24/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6406 - loss: 1.0358\n",
            "Epoch 24: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 263ms/step - accuracy: 0.6406 - loss: 1.0357 - val_accuracy: 0.4450 - val_loss: 1.7496 - learning_rate: 0.0010\n",
            "Epoch 25/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6335 - loss: 0.9813\n",
            "Epoch 25: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - accuracy: 0.6341 - loss: 0.9810 - val_accuracy: 0.5000 - val_loss: 1.6738 - learning_rate: 0.0010\n",
            "Epoch 26/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6666 - loss: 0.9036\n",
            "Epoch 26: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 0.6660 - loss: 0.9061 - val_accuracy: 0.4450 - val_loss: 1.5719 - learning_rate: 0.0010\n",
            "Epoch 27/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.6770 - loss: 0.8902\n",
            "Epoch 27: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - accuracy: 0.6774 - loss: 0.8897 - val_accuracy: 0.4750 - val_loss: 1.6778 - learning_rate: 0.0010\n",
            "Epoch 28/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6595 - loss: 0.9514\n",
            "Epoch 28: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 0.6588 - loss: 0.9525 - val_accuracy: 0.3000 - val_loss: 2.8158 - learning_rate: 0.0010\n",
            "Epoch 29/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.6520 - loss: 0.8782\n",
            "Epoch 29: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.6537 - loss: 0.8760 - val_accuracy: 0.3400 - val_loss: 3.2336 - learning_rate: 0.0010\n",
            "Epoch 30/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7219 - loss: 0.7681\n",
            "Epoch 30: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - accuracy: 0.7220 - loss: 0.7681 - val_accuracy: 0.5100 - val_loss: 1.4258 - learning_rate: 0.0010\n",
            "Epoch 31/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7791 - loss: 0.6212\n",
            "Epoch 31: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 0.7789 - loss: 0.6221 - val_accuracy: 0.3450 - val_loss: 2.9096 - learning_rate: 0.0010\n",
            "Epoch 32/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8068 - loss: 0.5537\n",
            "Epoch 32: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.8063 - loss: 0.5545 - val_accuracy: 0.3450 - val_loss: 3.9028 - learning_rate: 0.0010\n",
            "Epoch 33/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.8715 - loss: 0.4094\n",
            "Epoch 33: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.8704 - loss: 0.4114 - val_accuracy: 0.3050 - val_loss: 4.6962 - learning_rate: 0.0010\n",
            "Epoch 34/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8642 - loss: 0.4423\n",
            "Epoch 34: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - accuracy: 0.8638 - loss: 0.4429 - val_accuracy: 0.3750 - val_loss: 2.8164 - learning_rate: 0.0010\n",
            "Epoch 35/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8347 - loss: 0.4508\n",
            "Epoch 35: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - accuracy: 0.8352 - loss: 0.4503 - val_accuracy: 0.3400 - val_loss: 3.5688 - learning_rate: 0.0010\n",
            "Epoch 36/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.8806 - loss: 0.3213\n",
            "Epoch 36: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 295ms/step - accuracy: 0.8801 - loss: 0.3224 - val_accuracy: 0.3500 - val_loss: 2.6511 - learning_rate: 0.0010\n",
            "Epoch 37/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8796 - loss: 0.3424\n",
            "Epoch 37: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 211ms/step - accuracy: 0.8797 - loss: 0.3426 - val_accuracy: 0.4450 - val_loss: 2.4619 - learning_rate: 0.0010\n",
            "Epoch 38/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9095 - loss: 0.2684\n",
            "Epoch 38: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - accuracy: 0.9097 - loss: 0.2682 - val_accuracy: 0.3400 - val_loss: 3.6492 - learning_rate: 0.0010\n",
            "Epoch 39/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9261 - loss: 0.2103\n",
            "Epoch 39: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 264ms/step - accuracy: 0.9257 - loss: 0.2116 - val_accuracy: 0.4450 - val_loss: 2.1367 - learning_rate: 0.0010\n",
            "Epoch 40/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9476 - loss: 0.1835\n",
            "Epoch 40: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 258ms/step - accuracy: 0.9471 - loss: 0.1842 - val_accuracy: 0.4050 - val_loss: 2.9518 - learning_rate: 0.0010\n",
            "Epoch 41/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9277 - loss: 0.2533\n",
            "Epoch 41: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - accuracy: 0.9277 - loss: 0.2526 - val_accuracy: 0.3100 - val_loss: 4.2868 - learning_rate: 0.0010\n",
            "Epoch 42/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 0.9378 - loss: 0.1857\n",
            "Epoch 42: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 414ms/step - accuracy: 0.9377 - loss: 0.1856 - val_accuracy: 0.5050 - val_loss: 2.2750 - learning_rate: 0.0010\n",
            "Epoch 43/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9350 - loss: 0.1941\n",
            "Epoch 43: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 273ms/step - accuracy: 0.9350 - loss: 0.1942 - val_accuracy: 0.4350 - val_loss: 2.3754 - learning_rate: 0.0010\n",
            "Epoch 44/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9554 - loss: 0.1376\n",
            "Epoch 44: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 267ms/step - accuracy: 0.9550 - loss: 0.1384 - val_accuracy: 0.4250 - val_loss: 2.8376 - learning_rate: 0.0010\n",
            "Epoch 45/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9569 - loss: 0.1149\n",
            "Epoch 45: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 232ms/step - accuracy: 0.9569 - loss: 0.1152 - val_accuracy: 0.3900 - val_loss: 3.9385 - learning_rate: 0.0010\n",
            "Epoch 46/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9620 - loss: 0.1216\n",
            "Epoch 46: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 230ms/step - accuracy: 0.9620 - loss: 0.1215 - val_accuracy: 0.4300 - val_loss: 2.6833 - learning_rate: 0.0010\n",
            "Epoch 47/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9928 - loss: 0.0563\n",
            "Epoch 47: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 273ms/step - accuracy: 0.9925 - loss: 0.0566 - val_accuracy: 0.4100 - val_loss: 3.0712 - learning_rate: 0.0010\n",
            "Epoch 48/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9775 - loss: 0.0822\n",
            "Epoch 48: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.9776 - loss: 0.0820 - val_accuracy: 0.4400 - val_loss: 2.4407 - learning_rate: 0.0010\n",
            "Epoch 49/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9454 - loss: 0.1596\n",
            "Epoch 49: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 233ms/step - accuracy: 0.9457 - loss: 0.1585 - val_accuracy: 0.4750 - val_loss: 2.9457 - learning_rate: 0.0010\n",
            "Epoch 50/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9742 - loss: 0.0963\n",
            "Epoch 50: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 263ms/step - accuracy: 0.9742 - loss: 0.0963 - val_accuracy: 0.4600 - val_loss: 2.6496 - learning_rate: 0.0010\n",
            "Epoch 51/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9766 - loss: 0.0732\n",
            "Epoch 51: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - accuracy: 0.9764 - loss: 0.0734 - val_accuracy: 0.4450 - val_loss: 2.6053 - learning_rate: 0.0010\n",
            "Epoch 52/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9824 - loss: 0.0737\n",
            "Epoch 52: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 284ms/step - accuracy: 0.9821 - loss: 0.0740 - val_accuracy: 0.3700 - val_loss: 3.8443 - learning_rate: 0.0010\n",
            "Epoch 53/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9637 - loss: 0.1527\n",
            "Epoch 53: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 0.9636 - loss: 0.1524 - val_accuracy: 0.3150 - val_loss: 5.9194 - learning_rate: 0.0010\n",
            "Epoch 54/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9685 - loss: 0.0910\n",
            "Epoch 54: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - accuracy: 0.9685 - loss: 0.0906 - val_accuracy: 0.4400 - val_loss: 2.5677 - learning_rate: 0.0010\n",
            "Epoch 55/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9922 - loss: 0.0461\n",
            "Epoch 55: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 306ms/step - accuracy: 0.9920 - loss: 0.0459 - val_accuracy: 0.4250 - val_loss: 3.0358 - learning_rate: 0.0010\n",
            "Epoch 56/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9838 - loss: 0.0587\n",
            "Epoch 56: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 214ms/step - accuracy: 0.9838 - loss: 0.0592 - val_accuracy: 0.3350 - val_loss: 3.5395 - learning_rate: 0.0010\n",
            "Epoch 57/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9789 - loss: 0.0696\n",
            "Epoch 57: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.9792 - loss: 0.0691 - val_accuracy: 0.5050 - val_loss: 2.2140 - learning_rate: 0.0010\n",
            "Epoch 58/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9843 - loss: 0.0459\n",
            "Epoch 58: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 232ms/step - accuracy: 0.9842 - loss: 0.0462 - val_accuracy: 0.5050 - val_loss: 2.4573 - learning_rate: 0.0010\n",
            "Epoch 59/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9765 - loss: 0.0505\n",
            "Epoch 59: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 292ms/step - accuracy: 0.9768 - loss: 0.0505 - val_accuracy: 0.4950 - val_loss: 2.5554 - learning_rate: 0.0010\n",
            "Epoch 60/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.9910 - loss: 0.0471\n",
            "Epoch 60: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 353ms/step - accuracy: 0.9909 - loss: 0.0473 - val_accuracy: 0.4750 - val_loss: 2.3041 - learning_rate: 0.0010\n",
            "Epoch 61/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9773 - loss: 0.0717\n",
            "Epoch 61: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.9774 - loss: 0.0716 - val_accuracy: 0.4950 - val_loss: 2.5998 - learning_rate: 0.0010\n",
            "Epoch 62/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9862 - loss: 0.0513\n",
            "Epoch 62: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - accuracy: 0.9862 - loss: 0.0513 - val_accuracy: 0.3800 - val_loss: 3.8249 - learning_rate: 0.0010\n",
            "Epoch 63/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9808 - loss: 0.0599\n",
            "Epoch 63: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 232ms/step - accuracy: 0.9809 - loss: 0.0596 - val_accuracy: 0.4600 - val_loss: 2.8222 - learning_rate: 0.0010\n",
            "Epoch 64/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9808 - loss: 0.0711\n",
            "Epoch 64: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9811 - loss: 0.0702 - val_accuracy: 0.4850 - val_loss: 2.7022 - learning_rate: 0.0010\n",
            "Epoch 65/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9926 - loss: 0.0363\n",
            "Epoch 65: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - accuracy: 0.9926 - loss: 0.0364 - val_accuracy: 0.3650 - val_loss: 3.6982 - learning_rate: 0.0010\n",
            "Epoch 66/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.9890 - loss: 0.0326\n",
            "Epoch 66: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 314ms/step - accuracy: 0.9888 - loss: 0.0328 - val_accuracy: 0.4650 - val_loss: 2.8081 - learning_rate: 0.0010\n",
            "Epoch 67/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9810 - loss: 0.0550\n",
            "Epoch 67: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.9808 - loss: 0.0553 - val_accuracy: 0.3450 - val_loss: 4.4681 - learning_rate: 0.0010\n",
            "Epoch 68/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9891 - loss: 0.0577\n",
            "Epoch 68: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 301ms/step - accuracy: 0.9888 - loss: 0.0578 - val_accuracy: 0.3650 - val_loss: 4.1373 - learning_rate: 0.0010\n",
            "Epoch 69/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9861 - loss: 0.0455\n",
            "Epoch 69: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 231ms/step - accuracy: 0.9859 - loss: 0.0457 - val_accuracy: 0.3800 - val_loss: 3.3322 - learning_rate: 0.0010\n",
            "Epoch 70/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9701 - loss: 0.0830\n",
            "Epoch 70: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 297ms/step - accuracy: 0.9701 - loss: 0.0830 - val_accuracy: 0.4450 - val_loss: 3.1843 - learning_rate: 0.0010\n",
            "Epoch 71/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9777 - loss: 0.0923\n",
            "Epoch 71: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - accuracy: 0.9774 - loss: 0.0926 - val_accuracy: 0.4450 - val_loss: 2.9450 - learning_rate: 0.0010\n",
            "Epoch 72/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9709 - loss: 0.1021\n",
            "Epoch 72: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 252ms/step - accuracy: 0.9714 - loss: 0.1007 - val_accuracy: 0.4250 - val_loss: 2.6939 - learning_rate: 0.0010\n",
            "Epoch 73/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9766 - loss: 0.0765\n",
            "Epoch 73: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.9767 - loss: 0.0763 - val_accuracy: 0.4700 - val_loss: 2.6757 - learning_rate: 0.0010\n",
            "Epoch 74/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9846 - loss: 0.0493\n",
            "Epoch 74: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step - accuracy: 0.9848 - loss: 0.0493 - val_accuracy: 0.4500 - val_loss: 3.2477 - learning_rate: 0.0010\n",
            "Epoch 75/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9774 - loss: 0.0493\n",
            "Epoch 75: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.9777 - loss: 0.0493 - val_accuracy: 0.4250 - val_loss: 3.3907 - learning_rate: 0.0010\n",
            "Epoch 76/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9971 - loss: 0.0189\n",
            "Epoch 76: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 275ms/step - accuracy: 0.9970 - loss: 0.0191 - val_accuracy: 0.3600 - val_loss: 4.3918 - learning_rate: 0.0010\n",
            "Epoch 77/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9899 - loss: 0.0216\n",
            "Epoch 77: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 300ms/step - accuracy: 0.9899 - loss: 0.0217 - val_accuracy: 0.4900 - val_loss: 2.7317 - learning_rate: 0.0010\n",
            "Epoch 78/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9863 - loss: 0.0333\n",
            "Epoch 78: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.9864 - loss: 0.0332 - val_accuracy: 0.3750 - val_loss: 4.0142 - learning_rate: 0.0010\n",
            "Epoch 79/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.9909 - loss: 0.0302\n",
            "Epoch 79: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 384ms/step - accuracy: 0.9910 - loss: 0.0300 - val_accuracy: 0.4650 - val_loss: 3.1216 - learning_rate: 0.0010\n",
            "Epoch 80/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9873 - loss: 0.0465\n",
            "Epoch 80: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.9874 - loss: 0.0461 - val_accuracy: 0.4700 - val_loss: 2.8532 - learning_rate: 0.0010\n",
            "Epoch 81/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9951 - loss: 0.0282\n",
            "Epoch 81: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 255ms/step - accuracy: 0.9950 - loss: 0.0281 - val_accuracy: 0.4450 - val_loss: 2.9597 - learning_rate: 0.0010\n",
            "Epoch 82/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9866 - loss: 0.0238\n",
            "Epoch 82: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 271ms/step - accuracy: 0.9868 - loss: 0.0238 - val_accuracy: 0.4800 - val_loss: 2.7408 - learning_rate: 0.0010\n",
            "Epoch 83/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9930 - loss: 0.0459\n",
            "Epoch 83: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.9931 - loss: 0.0453 - val_accuracy: 0.4800 - val_loss: 2.5656 - learning_rate: 0.0010\n",
            "Epoch 84/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9934 - loss: 0.0215\n",
            "Epoch 84: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.9935 - loss: 0.0214 - val_accuracy: 0.4650 - val_loss: 2.9369 - learning_rate: 0.0010\n",
            "Epoch 85/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9964 - loss: 0.0170\n",
            "Epoch 85: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 236ms/step - accuracy: 0.9963 - loss: 0.0174 - val_accuracy: 0.3650 - val_loss: 4.8914 - learning_rate: 0.0010\n",
            "Epoch 86/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9802 - loss: 0.0653\n",
            "Epoch 86: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - accuracy: 0.9801 - loss: 0.0658 - val_accuracy: 0.3500 - val_loss: 5.6018 - learning_rate: 0.0010\n",
            "Epoch 87/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9575 - loss: 0.1084\n",
            "Epoch 87: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 292ms/step - accuracy: 0.9577 - loss: 0.1075 - val_accuracy: 0.3900 - val_loss: 4.1400 - learning_rate: 0.0010\n",
            "Epoch 88/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9850 - loss: 0.0592\n",
            "Epoch 88: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 233ms/step - accuracy: 0.9849 - loss: 0.0595 - val_accuracy: 0.4550 - val_loss: 3.1291 - learning_rate: 0.0010\n",
            "Epoch 89/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9837 - loss: 0.0481\n",
            "Epoch 89: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.9837 - loss: 0.0480 - val_accuracy: 0.4500 - val_loss: 3.1598 - learning_rate: 0.0010\n",
            "Epoch 90/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9940 - loss: 0.0195\n",
            "Epoch 90: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 263ms/step - accuracy: 0.9940 - loss: 0.0196 - val_accuracy: 0.4350 - val_loss: 3.2839 - learning_rate: 0.0010\n",
            "Epoch 91/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9918 - loss: 0.0181\n",
            "Epoch 91: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 311ms/step - accuracy: 0.9918 - loss: 0.0182 - val_accuracy: 0.5000 - val_loss: 2.7268 - learning_rate: 0.0010\n",
            "Epoch 92/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9898 - loss: 0.0286\n",
            "Epoch 92: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 0.9898 - loss: 0.0286 - val_accuracy: 0.4800 - val_loss: 2.8537 - learning_rate: 0.0010\n",
            "Epoch 93/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9856 - loss: 0.0344\n",
            "Epoch 93: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 251ms/step - accuracy: 0.9858 - loss: 0.0342 - val_accuracy: 0.4350 - val_loss: 3.8863 - learning_rate: 0.0010\n",
            "Epoch 94/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9932 - loss: 0.0287\n",
            "Epoch 94: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 244ms/step - accuracy: 0.9932 - loss: 0.0286 - val_accuracy: 0.4200 - val_loss: 3.6817 - learning_rate: 0.0010\n",
            "Epoch 95/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9918 - loss: 0.0228\n",
            "Epoch 95: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - accuracy: 0.9918 - loss: 0.0232 - val_accuracy: 0.4050 - val_loss: 4.0497 - learning_rate: 0.0010\n",
            "Epoch 96/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9959 - loss: 0.0242\n",
            "Epoch 96: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 309ms/step - accuracy: 0.9960 - loss: 0.0241 - val_accuracy: 0.4100 - val_loss: 3.4656 - learning_rate: 0.0010\n",
            "Epoch 97/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9926 - loss: 0.0216\n",
            "Epoch 97: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.9926 - loss: 0.0215 - val_accuracy: 0.4450 - val_loss: 3.2458 - learning_rate: 0.0010\n",
            "Epoch 98/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9943 - loss: 0.0208\n",
            "Epoch 98: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 233ms/step - accuracy: 0.9943 - loss: 0.0208 - val_accuracy: 0.4800 - val_loss: 3.0491 - learning_rate: 0.0010\n",
            "Epoch 99/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9935 - loss: 0.0205\n",
            "Epoch 99: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 232ms/step - accuracy: 0.9936 - loss: 0.0204 - val_accuracy: 0.4700 - val_loss: 2.9023 - learning_rate: 0.0010\n",
            "Epoch 100/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9970 - loss: 0.0157\n",
            "Epoch 100: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 256ms/step - accuracy: 0.9969 - loss: 0.0158 - val_accuracy: 0.4350 - val_loss: 2.9972 - learning_rate: 0.0010\n",
            "Epoch 101/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9986 - loss: 0.0071\n",
            "Epoch 101: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9985 - loss: 0.0074 - val_accuracy: 0.4500 - val_loss: 3.0667 - learning_rate: 0.0010\n",
            "Epoch 102/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9897 - loss: 0.0211\n",
            "Epoch 102: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 232ms/step - accuracy: 0.9898 - loss: 0.0209 - val_accuracy: 0.4150 - val_loss: 3.5549 - learning_rate: 0.0010\n",
            "Epoch 103/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9926 - loss: 0.0293\n",
            "Epoch 103: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 217ms/step - accuracy: 0.9926 - loss: 0.0292 - val_accuracy: 0.4650 - val_loss: 3.0942 - learning_rate: 0.0010\n",
            "Epoch 104/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9908 - loss: 0.0372\n",
            "Epoch 104: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 277ms/step - accuracy: 0.9909 - loss: 0.0369 - val_accuracy: 0.4600 - val_loss: 3.1148 - learning_rate: 0.0010\n",
            "Epoch 105/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9959 - loss: 0.0142\n",
            "Epoch 105: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 289ms/step - accuracy: 0.9960 - loss: 0.0141 - val_accuracy: 0.4700 - val_loss: 2.8896 - learning_rate: 0.0010\n",
            "Epoch 106/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 0.0100\n",
            "Epoch 106: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.4600 - val_loss: 2.7984 - learning_rate: 0.0010\n",
            "Epoch 107/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9963 - loss: 0.0158\n",
            "Epoch 107: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.9963 - loss: 0.0158 - val_accuracy: 0.4550 - val_loss: 2.9289 - learning_rate: 0.0010\n",
            "Epoch 108/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9978 - loss: 0.0144\n",
            "Epoch 108: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 299ms/step - accuracy: 0.9979 - loss: 0.0143 - val_accuracy: 0.4700 - val_loss: 2.9444 - learning_rate: 0.0010\n",
            "Epoch 109/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9959 - loss: 0.0140\n",
            "Epoch 109: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 235ms/step - accuracy: 0.9959 - loss: 0.0139 - val_accuracy: 0.4600 - val_loss: 3.1360 - learning_rate: 0.0010\n",
            "Epoch 110/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9939 - loss: 0.0148\n",
            "Epoch 110: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.9939 - loss: 0.0150 - val_accuracy: 0.4450 - val_loss: 2.9405 - learning_rate: 0.0010\n",
            "Epoch 111/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9917 - loss: 0.0218\n",
            "Epoch 111: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 240ms/step - accuracy: 0.9919 - loss: 0.0216 - val_accuracy: 0.4500 - val_loss: 2.8376 - learning_rate: 0.0010\n",
            "Epoch 112/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.9871 - loss: 0.0217\n",
            "Epoch 112: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 259ms/step - accuracy: 0.9873 - loss: 0.0213 - val_accuracy: 0.4750 - val_loss: 2.8387 - learning_rate: 0.0010\n",
            "Epoch 113/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.9890 - loss: 0.0333\n",
            "Epoch 113: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 410ms/step - accuracy: 0.9890 - loss: 0.0332 - val_accuracy: 0.4700 - val_loss: 2.6913 - learning_rate: 0.0010\n",
            "Epoch 114/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9915 - loss: 0.0290\n",
            "Epoch 114: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 241ms/step - accuracy: 0.9915 - loss: 0.0287 - val_accuracy: 0.4800 - val_loss: 2.9378 - learning_rate: 0.0010\n",
            "Epoch 115/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9891 - loss: 0.0217\n",
            "Epoch 115: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9892 - loss: 0.0215 - val_accuracy: 0.4850 - val_loss: 2.7654 - learning_rate: 0.0010\n",
            "Epoch 116/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9852 - loss: 0.0316\n",
            "Epoch 116: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - accuracy: 0.9854 - loss: 0.0315 - val_accuracy: 0.4550 - val_loss: 3.2793 - learning_rate: 0.0010\n",
            "Epoch 117/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9954 - loss: 0.0264\n",
            "Epoch 117: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 235ms/step - accuracy: 0.9954 - loss: 0.0260 - val_accuracy: 0.4600 - val_loss: 2.9603 - learning_rate: 0.0010\n",
            "Epoch 118/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9970 - loss: 0.0203\n",
            "Epoch 118: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 289ms/step - accuracy: 0.9970 - loss: 0.0203 - val_accuracy: 0.4650 - val_loss: 3.1717 - learning_rate: 0.0010\n",
            "Epoch 119/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9954 - loss: 0.0152\n",
            "Epoch 119: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - accuracy: 0.9954 - loss: 0.0151 - val_accuracy: 0.4950 - val_loss: 3.0583 - learning_rate: 0.0010\n",
            "Epoch 120/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9948 - loss: 0.0243\n",
            "Epoch 120: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9947 - loss: 0.0246 - val_accuracy: 0.3650 - val_loss: 5.1370 - learning_rate: 0.0010\n",
            "Epoch 121/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9950 - loss: 0.0220\n",
            "Epoch 121: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - accuracy: 0.9951 - loss: 0.0218 - val_accuracy: 0.4900 - val_loss: 2.8762 - learning_rate: 0.0010\n",
            "Epoch 122/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9925 - loss: 0.0259\n",
            "Epoch 122: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 272ms/step - accuracy: 0.9923 - loss: 0.0264 - val_accuracy: 0.4700 - val_loss: 3.0243 - learning_rate: 0.0010\n",
            "Epoch 123/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9886 - loss: 0.0398\n",
            "Epoch 123: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 306ms/step - accuracy: 0.9886 - loss: 0.0398 - val_accuracy: 0.4200 - val_loss: 4.2105 - learning_rate: 0.0010\n",
            "Epoch 124/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9795 - loss: 0.0679\n",
            "Epoch 124: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.9797 - loss: 0.0669 - val_accuracy: 0.4800 - val_loss: 3.6635 - learning_rate: 0.0010\n",
            "Epoch 125/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9776 - loss: 0.0649\n",
            "Epoch 125: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 243ms/step - accuracy: 0.9778 - loss: 0.0641 - val_accuracy: 0.4400 - val_loss: 3.5204 - learning_rate: 0.0010\n",
            "Epoch 126/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9891 - loss: 0.0215\n",
            "Epoch 126: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 248ms/step - accuracy: 0.9892 - loss: 0.0214 - val_accuracy: 0.4050 - val_loss: 4.2493 - learning_rate: 0.0010\n",
            "Epoch 127/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9891 - loss: 0.0206\n",
            "Epoch 127: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9890 - loss: 0.0209 - val_accuracy: 0.4650 - val_loss: 3.3084 - learning_rate: 0.0010\n",
            "Epoch 128/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9929 - loss: 0.0271\n",
            "Epoch 128: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 297ms/step - accuracy: 0.9928 - loss: 0.0274 - val_accuracy: 0.4600 - val_loss: 3.3972 - learning_rate: 0.0010\n",
            "Epoch 129/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9932 - loss: 0.0269\n",
            "Epoch 129: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 229ms/step - accuracy: 0.9929 - loss: 0.0272 - val_accuracy: 0.4400 - val_loss: 3.5264 - learning_rate: 0.0010\n",
            "Epoch 130/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9925 - loss: 0.0309\n",
            "Epoch 130: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 291ms/step - accuracy: 0.9924 - loss: 0.0311 - val_accuracy: 0.3900 - val_loss: 4.0981 - learning_rate: 0.0010\n",
            "Epoch 131/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.9855 - loss: 0.0368\n",
            "Epoch 131: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 417ms/step - accuracy: 0.9856 - loss: 0.0368 - val_accuracy: 0.4200 - val_loss: 3.6294 - learning_rate: 0.0010\n",
            "Epoch 132/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9925 - loss: 0.0279\n",
            "Epoch 132: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.9925 - loss: 0.0278 - val_accuracy: 0.4250 - val_loss: 3.1765 - learning_rate: 0.0010\n",
            "Epoch 133/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9934 - loss: 0.0270\n",
            "Epoch 133: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 267ms/step - accuracy: 0.9935 - loss: 0.0268 - val_accuracy: 0.4600 - val_loss: 3.0269 - learning_rate: 0.0010\n",
            "Epoch 134/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9925 - loss: 0.0264\n",
            "Epoch 134: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 242ms/step - accuracy: 0.9925 - loss: 0.0264 - val_accuracy: 0.3950 - val_loss: 3.5063 - learning_rate: 0.0010\n",
            "Epoch 135/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9928 - loss: 0.0229\n",
            "Epoch 135: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 254ms/step - accuracy: 0.9927 - loss: 0.0232 - val_accuracy: 0.4500 - val_loss: 3.1798 - learning_rate: 0.0010\n",
            "Epoch 136/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9955 - loss: 0.0245\n",
            "Epoch 136: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - accuracy: 0.9954 - loss: 0.0247 - val_accuracy: 0.4600 - val_loss: 3.1514 - learning_rate: 0.0010\n",
            "Epoch 137/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9829 - loss: 0.0339\n",
            "Epoch 137: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 233ms/step - accuracy: 0.9831 - loss: 0.0337 - val_accuracy: 0.3650 - val_loss: 3.9828 - learning_rate: 0.0010\n",
            "Epoch 138/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9933 - loss: 0.0244\n",
            "Epoch 138: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 267ms/step - accuracy: 0.9931 - loss: 0.0247 - val_accuracy: 0.4400 - val_loss: 3.2341 - learning_rate: 0.0010\n",
            "Epoch 139/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9902 - loss: 0.0249\n",
            "Epoch 139: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.9900 - loss: 0.0255 - val_accuracy: 0.4500 - val_loss: 3.0664 - learning_rate: 0.0010\n",
            "Epoch 140/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9847 - loss: 0.0537\n",
            "Epoch 140: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 234ms/step - accuracy: 0.9848 - loss: 0.0536 - val_accuracy: 0.4300 - val_loss: 3.5374 - learning_rate: 0.0010\n",
            "Epoch 141/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9734 - loss: 0.0775\n",
            "Epoch 141: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 249ms/step - accuracy: 0.9738 - loss: 0.0768 - val_accuracy: 0.3950 - val_loss: 4.0653 - learning_rate: 0.0010\n",
            "Epoch 142/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9842 - loss: 0.0594\n",
            "Epoch 142: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - accuracy: 0.9841 - loss: 0.0595 - val_accuracy: 0.4000 - val_loss: 4.0495 - learning_rate: 0.0010\n",
            "Epoch 143/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9886 - loss: 0.0342\n",
            "Epoch 143: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 216ms/step - accuracy: 0.9886 - loss: 0.0344 - val_accuracy: 0.3700 - val_loss: 4.0881 - learning_rate: 0.0010\n",
            "Epoch 144/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9895 - loss: 0.0418\n",
            "Epoch 144: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 333ms/step - accuracy: 0.9895 - loss: 0.0416 - val_accuracy: 0.4700 - val_loss: 3.2858 - learning_rate: 0.0010\n",
            "Epoch 145/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9831 - loss: 0.0441\n",
            "Epoch 145: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - accuracy: 0.9834 - loss: 0.0435 - val_accuracy: 0.4850 - val_loss: 3.1627 - learning_rate: 0.0010\n",
            "Epoch 146/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9847 - loss: 0.0362\n",
            "Epoch 146: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 254ms/step - accuracy: 0.9848 - loss: 0.0363 - val_accuracy: 0.4850 - val_loss: 3.0000 - learning_rate: 0.0010\n",
            "Epoch 147/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9830 - loss: 0.0609\n",
            "Epoch 147: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 240ms/step - accuracy: 0.9832 - loss: 0.0603 - val_accuracy: 0.4050 - val_loss: 3.9762 - learning_rate: 0.0010\n",
            "Epoch 148/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9892 - loss: 0.0308\n",
            "Epoch 148: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 311ms/step - accuracy: 0.9892 - loss: 0.0311 - val_accuracy: 0.3600 - val_loss: 4.0923 - learning_rate: 0.0010\n",
            "Epoch 149/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9913 - loss: 0.0359\n",
            "Epoch 149: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 305ms/step - accuracy: 0.9911 - loss: 0.0365 - val_accuracy: 0.4250 - val_loss: 3.3892 - learning_rate: 0.0010\n",
            "Epoch 150/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9911 - loss: 0.0297\n",
            "Epoch 150: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 300ms/step - accuracy: 0.9911 - loss: 0.0297 - val_accuracy: 0.3900 - val_loss: 4.2066 - learning_rate: 0.0010\n",
            "Epoch 151/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9979 - loss: 0.0149\n",
            "Epoch 151: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9978 - loss: 0.0151 - val_accuracy: 0.4900 - val_loss: 2.9274 - learning_rate: 0.0010\n",
            "Epoch 152/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9942 - loss: 0.0177\n",
            "Epoch 152: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - accuracy: 0.9941 - loss: 0.0178 - val_accuracy: 0.4700 - val_loss: 3.1313 - learning_rate: 0.0010\n",
            "Epoch 153/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9930 - loss: 0.0184\n",
            "Epoch 153: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.9930 - loss: 0.0184 - val_accuracy: 0.4200 - val_loss: 3.1428 - learning_rate: 0.0010\n",
            "Epoch 154/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9914 - loss: 0.0193\n",
            "Epoch 154: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 295ms/step - accuracy: 0.9915 - loss: 0.0193 - val_accuracy: 0.4600 - val_loss: 3.2247 - learning_rate: 0.0010\n",
            "Epoch 155/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9984 - loss: 0.0130\n",
            "Epoch 155: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - accuracy: 0.9982 - loss: 0.0133 - val_accuracy: 0.4500 - val_loss: 3.5566 - learning_rate: 0.0010\n",
            "Epoch 156/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9956 - loss: 0.0184\n",
            "Epoch 156: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 262ms/step - accuracy: 0.9956 - loss: 0.0184 - val_accuracy: 0.4400 - val_loss: 3.8294 - learning_rate: 0.0010\n",
            "Epoch 157/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9920 - loss: 0.0220\n",
            "Epoch 157: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9917 - loss: 0.0227 - val_accuracy: 0.4850 - val_loss: 3.5396 - learning_rate: 0.0010\n",
            "Epoch 158/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9946 - loss: 0.0208\n",
            "Epoch 158: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.9945 - loss: 0.0209 - val_accuracy: 0.4500 - val_loss: 3.0079 - learning_rate: 0.0010\n",
            "Epoch 159/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9924 - loss: 0.0263\n",
            "Epoch 159: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.9924 - loss: 0.0261 - val_accuracy: 0.4550 - val_loss: 3.0680 - learning_rate: 0.0010\n",
            "Epoch 160/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9933 - loss: 0.0187\n",
            "Epoch 160: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 299ms/step - accuracy: 0.9934 - loss: 0.0189 - val_accuracy: 0.4450 - val_loss: 3.9551 - learning_rate: 0.0010\n",
            "Epoch 161/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9917 - loss: 0.0335\n",
            "Epoch 161: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 230ms/step - accuracy: 0.9916 - loss: 0.0337 - val_accuracy: 0.4400 - val_loss: 3.8687 - learning_rate: 0.0010\n",
            "Epoch 162/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9930 - loss: 0.0197\n",
            "Epoch 162: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 273ms/step - accuracy: 0.9931 - loss: 0.0198 - val_accuracy: 0.4950 - val_loss: 3.0931 - learning_rate: 0.0010\n",
            "Epoch 163/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9944 - loss: 0.0201\n",
            "Epoch 163: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 240ms/step - accuracy: 0.9943 - loss: 0.0203 - val_accuracy: 0.4550 - val_loss: 3.1249 - learning_rate: 0.0010\n",
            "Epoch 164/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9924 - loss: 0.0126\n",
            "Epoch 164: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 236ms/step - accuracy: 0.9924 - loss: 0.0128 - val_accuracy: 0.4450 - val_loss: 3.1674 - learning_rate: 0.0010\n",
            "Epoch 165/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9931 - loss: 0.0258\n",
            "Epoch 165: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 232ms/step - accuracy: 0.9932 - loss: 0.0255 - val_accuracy: 0.4550 - val_loss: 3.3940 - learning_rate: 0.0010\n",
            "Epoch 166/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.9951 - loss: 0.0150\n",
            "Epoch 166: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 370ms/step - accuracy: 0.9952 - loss: 0.0149 - val_accuracy: 0.5200 - val_loss: 2.9533 - learning_rate: 0.0010\n",
            "Epoch 167/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9925 - loss: 0.0141\n",
            "Epoch 167: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - accuracy: 0.9926 - loss: 0.0141 - val_accuracy: 0.4700 - val_loss: 3.5302 - learning_rate: 0.0010\n",
            "Epoch 168/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9921 - loss: 0.0287\n",
            "Epoch 168: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 232ms/step - accuracy: 0.9920 - loss: 0.0291 - val_accuracy: 0.4500 - val_loss: 3.3826 - learning_rate: 0.0010\n",
            "Epoch 169/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9880 - loss: 0.0311\n",
            "Epoch 169: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 277ms/step - accuracy: 0.9883 - loss: 0.0308 - val_accuracy: 0.4200 - val_loss: 4.0360 - learning_rate: 0.0010\n",
            "Epoch 170/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9835 - loss: 0.0555\n",
            "Epoch 170: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - accuracy: 0.9837 - loss: 0.0548 - val_accuracy: 0.4000 - val_loss: 4.0915 - learning_rate: 0.0010\n",
            "Epoch 171/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9758 - loss: 0.0451\n",
            "Epoch 171: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.9760 - loss: 0.0452 - val_accuracy: 0.4700 - val_loss: 3.1370 - learning_rate: 0.0010\n",
            "Epoch 172/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9856 - loss: 0.0308\n",
            "Epoch 172: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - accuracy: 0.9857 - loss: 0.0307 - val_accuracy: 0.4200 - val_loss: 4.6027 - learning_rate: 0.0010\n",
            "Epoch 173/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9910 - loss: 0.0241\n",
            "Epoch 173: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 291ms/step - accuracy: 0.9911 - loss: 0.0241 - val_accuracy: 0.4450 - val_loss: 3.6491 - learning_rate: 0.0010\n",
            "Epoch 174/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9869 - loss: 0.0298\n",
            "Epoch 174: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 233ms/step - accuracy: 0.9870 - loss: 0.0299 - val_accuracy: 0.4100 - val_loss: 3.3519 - learning_rate: 0.0010\n",
            "Epoch 175/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9914 - loss: 0.0282\n",
            "Epoch 175: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.9913 - loss: 0.0284 - val_accuracy: 0.4300 - val_loss: 3.9094 - learning_rate: 0.0010\n",
            "Epoch 176/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9875 - loss: 0.0323\n",
            "Epoch 176: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 258ms/step - accuracy: 0.9877 - loss: 0.0320 - val_accuracy: 0.4650 - val_loss: 3.0475 - learning_rate: 0.0010\n",
            "Epoch 177/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9880 - loss: 0.0310\n",
            "Epoch 177: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - accuracy: 0.9881 - loss: 0.0309 - val_accuracy: 0.4000 - val_loss: 4.5732 - learning_rate: 0.0010\n",
            "Epoch 178/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9890 - loss: 0.0369\n",
            "Epoch 178: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 273ms/step - accuracy: 0.9890 - loss: 0.0369 - val_accuracy: 0.4450 - val_loss: 3.6128 - learning_rate: 0.0010\n",
            "Epoch 179/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9903 - loss: 0.0299\n",
            "Epoch 179: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 234ms/step - accuracy: 0.9903 - loss: 0.0301 - val_accuracy: 0.4550 - val_loss: 3.7349 - learning_rate: 0.0010\n",
            "Epoch 180/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9899 - loss: 0.0318\n",
            "Epoch 180: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 0.9898 - loss: 0.0321 - val_accuracy: 0.3850 - val_loss: 4.8814 - learning_rate: 0.0010\n",
            "Epoch 181/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9888 - loss: 0.0338\n",
            "Epoch 181: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - accuracy: 0.9889 - loss: 0.0335 - val_accuracy: 0.4700 - val_loss: 3.6403 - learning_rate: 0.0010\n",
            "Epoch 182/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9984 - loss: 0.0092\n",
            "Epoch 182: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step - accuracy: 0.9982 - loss: 0.0096 - val_accuracy: 0.4700 - val_loss: 3.5876 - learning_rate: 0.0010\n",
            "Epoch 183/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9917 - loss: 0.0172\n",
            "Epoch 183: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - accuracy: 0.9916 - loss: 0.0179 - val_accuracy: 0.3800 - val_loss: 4.1846 - learning_rate: 0.0010\n",
            "Epoch 184/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.9906 - loss: 0.0302\n",
            "Epoch 184: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 332ms/step - accuracy: 0.9906 - loss: 0.0302 - val_accuracy: 0.3850 - val_loss: 5.4266 - learning_rate: 0.0010\n",
            "Epoch 185/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9825 - loss: 0.0371\n",
            "Epoch 185: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 310ms/step - accuracy: 0.9824 - loss: 0.0373 - val_accuracy: 0.3700 - val_loss: 5.0931 - learning_rate: 0.0010\n",
            "Epoch 186/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9955 - loss: 0.0143\n",
            "Epoch 186: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9954 - loss: 0.0144 - val_accuracy: 0.4300 - val_loss: 3.7199 - learning_rate: 0.0010\n",
            "Epoch 187/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9936 - loss: 0.0168\n",
            "Epoch 187: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 300ms/step - accuracy: 0.9936 - loss: 0.0169 - val_accuracy: 0.4500 - val_loss: 3.7273 - learning_rate: 0.0010\n",
            "Epoch 188/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9941 - loss: 0.0144\n",
            "Epoch 188: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.9941 - loss: 0.0145 - val_accuracy: 0.3950 - val_loss: 3.4923 - learning_rate: 0.0010\n",
            "Epoch 189/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9911 - loss: 0.0207\n",
            "Epoch 189: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 266ms/step - accuracy: 0.9911 - loss: 0.0210 - val_accuracy: 0.4350 - val_loss: 3.6259 - learning_rate: 0.0010\n",
            "Epoch 190/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.9929 - loss: 0.0157\n",
            "Epoch 190: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 313ms/step - accuracy: 0.9928 - loss: 0.0161 - val_accuracy: 0.4600 - val_loss: 3.5296 - learning_rate: 0.0010\n",
            "Epoch 191/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9795 - loss: 0.0598\n",
            "Epoch 191: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.9795 - loss: 0.0603 - val_accuracy: 0.4400 - val_loss: 3.9465 - learning_rate: 0.0010\n",
            "Epoch 192/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9881 - loss: 0.0351\n",
            "Epoch 192: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 298ms/step - accuracy: 0.9883 - loss: 0.0347 - val_accuracy: 0.4400 - val_loss: 4.1360 - learning_rate: 0.0010\n",
            "Epoch 193/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9901 - loss: 0.0427\n",
            "Epoch 193: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.9900 - loss: 0.0425 - val_accuracy: 0.4500 - val_loss: 3.8701 - learning_rate: 0.0010\n",
            "Epoch 194/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9884 - loss: 0.0370\n",
            "Epoch 194: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.9884 - loss: 0.0369 - val_accuracy: 0.4400 - val_loss: 3.5361 - learning_rate: 0.0010\n",
            "Epoch 195/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9938 - loss: 0.0222\n",
            "Epoch 195: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.9937 - loss: 0.0223 - val_accuracy: 0.4500 - val_loss: 3.6842 - learning_rate: 0.0010\n",
            "Epoch 196/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9836 - loss: 0.0273\n",
            "Epoch 196: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.9838 - loss: 0.0271 - val_accuracy: 0.4100 - val_loss: 4.1240 - learning_rate: 0.0010\n",
            "Epoch 197/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9943 - loss: 0.0232\n",
            "Epoch 197: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - accuracy: 0.9943 - loss: 0.0232 - val_accuracy: 0.4150 - val_loss: 3.8965 - learning_rate: 0.0010\n",
            "Epoch 198/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9953 - loss: 0.0190\n",
            "Epoch 198: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.9953 - loss: 0.0190 - val_accuracy: 0.4350 - val_loss: 3.7663 - learning_rate: 0.0010\n",
            "Epoch 199/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9960 - loss: 0.0108\n",
            "Epoch 199: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 250ms/step - accuracy: 0.9959 - loss: 0.0109 - val_accuracy: 0.4450 - val_loss: 3.4709 - learning_rate: 0.0010\n",
            "Epoch 200/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9948 - loss: 0.0145\n",
            "Epoch 200: val_accuracy did not improve from 0.52500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 257ms/step - accuracy: 0.9948 - loss: 0.0145 - val_accuracy: 0.4150 - val_loss: 3.7964 - learning_rate: 0.0010\n"
          ]
        }
      ]
    }
  ]
}